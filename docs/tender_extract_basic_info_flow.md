# æ‹›æŠ•æ ‡åº”ç”¨ - æå–åŸºæœ¬ä¿¡æ¯è¯¦ç»†æµç¨‹

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°æ‹›æŠ•æ ‡åº”ç”¨ä¸­æå–é¡¹ç›®åŸºæœ¬ä¿¡æ¯çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®æµã€æ ¸å¿ƒç»„ä»¶ã€æŠ€æœ¯å®ç°å’Œå¯ç”¨æ€§è¯„ä¼°ã€‚

**æµç¨‹ç‰ˆæœ¬**: V2 (NEW_ONLY æ¨¡å¼)
**ç”Ÿæˆæ—¥æœŸ**: 2025-12-20

---

## ä¸€ã€æ•´ä½“æµç¨‹æ¶æ„

```
ç”¨æˆ·è¯·æ±‚
   â†“
TenderService.extract_project_info()
   â†“
ExtractV2Service.extract_project_info_v2()
   â†“
ExtractionEngine.run()
   â”œâ”€â†’ RetrievalFacade.retrieve()  [æ£€ç´¢ç›¸å…³æ–‡æ¡£å—]
   â”‚    â””â”€â†’ NewRetriever.retrieve()
   â”‚         â””â”€â†’ æ•°æ®åº“æŸ¥è¯¢ (doc_segments/kb_chunks)
   â”‚         â””â”€â†’ å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ (pgvector)
   â”œâ”€â†’ build_marked_context()      [æ„å»ºæ ‡è®°çš„ä¸Šä¸‹æ–‡]
   â”œâ”€â†’ call_llm()                  [è°ƒç”¨å¤§æ¨¡å‹]
   â””â”€â†’ extract_json()              [è§£æJSONç»“æœ]
   â†“
ä¿å­˜åˆ°æ•°æ®åº“ (project_infoè¡¨)
   â†“
è¿”å›ç»“æ„åŒ–ç»“æœ
```

---

## äºŒã€è¯¦ç»†æµç¨‹è¯´æ˜

### 2.1 å…¥å£å±‚ - TenderService

**æ–‡ä»¶**: `backend/app/services/tender_service.py`

**æ–¹æ³•**: `extract_project_info(project_id, model_id, run_id, owner_id)`

**åŠŸèƒ½**:
1. æ£€æŸ¥ cutover æ¨¡å¼ï¼ˆå¿…é¡»æ˜¯ NEW_ONLYï¼‰
2. åˆ›å»º platform jobï¼ˆå¯é€‰ï¼Œç”¨äºä»»åŠ¡è¿½è¸ªï¼‰
3. è°ƒç”¨ V2 æŠ½å–æœåŠ¡
4. ä¿å­˜ç»“æœåˆ°æ—§è¡¨ï¼ˆä¿è¯å‰ç«¯å…¼å®¹ï¼‰
5. æ›´æ–°è¿è¡ŒçŠ¶æ€

**å…³é”®ä»£ç **:
```python:792:848:backend/app/services/tender_service.py
def extract_project_info(
    self,
    project_id: str,
    model_id: Optional[str],
    run_id: Optional[str] = None,
    owner_id: Optional[str] = None,
):
    """æŠ½å–é¡¹ç›®ä¿¡æ¯"""
    
    # 1. æ£€æŸ¥æ¨¡å¼
    cutover = get_cutover_config()
    extract_mode = cutover.get_mode("extract", project_id)
    if extract_mode.value != "NEW_ONLY":
        raise RuntimeError("Legacy extraction deleted. Set EXTRACT_MODE=NEW_ONLY")
    
    # 2. åˆ›å»º jobï¼ˆå¯é€‰ï¼‰
    job_id = self.jobs_service.create_job(...) if enabled
    
    # 3. è°ƒç”¨ v2 æŠ½å–
    from app.works.tender.extract_v2_service import ExtractV2Service
    pool = _get_pool()
    extract_v2 = ExtractV2Service(pool, self.llm)
    
    v2_result = asyncio.run(extract_v2.extract_project_info_v2(
        project_id=project_id,
        model_id=model_id,
        run_id=run_id
    ))
    
    # 4. ä¿å­˜åˆ°æ—§è¡¨
    self.dao.upsert_project_info(project_id, data_json=data, evidence_chunk_ids=eids)
    
    # 5. æ›´æ–°çŠ¶æ€
    if run_id:
        self.dao.update_run(run_id, "success", ...)
```

---

### 2.2 V2æŠ½å–æœåŠ¡å±‚ - ExtractV2Service

**æ–‡ä»¶**: `backend/app/works/tender/extract_v2_service.py`

**æ–¹æ³•**: `extract_project_info_v2(project_id, model_id, run_id)`

**åŠŸèƒ½**:
1. è·å– embedding provider
2. æ„å»ºæŠ½å–è§„æ ¼ï¼ˆExtractionSpecï¼‰
3. è°ƒç”¨é€šç”¨æŠ½å–å¼•æ“
4. è¿”å›ç»“æ„åŒ–ç»“æœ

**å…³é”®ä»£ç **:
```python:28:89:backend/app/works/tender/extract_v2_service.py
async def extract_project_info_v2(
    self,
    project_id: str,
    model_id: Optional[str],
    run_id: Optional[str] = None,
) -> Dict[str, Any]:
    """
    æŠ½å–é¡¹ç›®ä¿¡æ¯ (v2) - ä½¿ç”¨å¹³å° ExtractionEngine
    
    Returns:
        {
            "data": {...},
            "evidence_chunk_ids": [...],
            "evidence_spans": [...],
            "retrieval_trace": {...}
        }
    """
    
    # 1. è·å– embedding provider
    embedding_provider = get_embedding_store().get_default()
    
    # 2. æ„å»º spec
    spec = build_project_info_spec()
    
    # 3. è°ƒç”¨å¼•æ“
    result = await self.engine.run(
        spec=spec,
        retriever=self.retriever,
        llm=self.llm,
        project_id=project_id,
        model_id=model_id,
        run_id=run_id,
        embedding_provider=embedding_provider,
    )
    
    # 4. è¿”å›ç»“æœ
    return {
        "data": result.data,
        "evidence_chunk_ids": result.evidence_chunk_ids,
        "evidence_spans": result.evidence_spans,
        "retrieval_trace": result.retrieval_trace.__dict__
    }
```

---

### 2.3 æŠ½å–è§„æ ¼ - ExtractionSpec

**æ–‡ä»¶**: `backend/app/works/tender/extraction_specs/project_info_v2.py`

**æ–¹æ³•**: `build_project_info_spec()`

**åŠŸèƒ½**: æ„å»ºé¡¹ç›®ä¿¡æ¯æŠ½å–çš„é…ç½®è§„æ ¼

**é…ç½®å†…å®¹**:
```python:19:53:backend/app/works/tender/extraction_specs/project_info_v2.py
def build_project_info_spec() -> ExtractionSpec:
    """æ„å»ºé¡¹ç›®ä¿¡æ¯æŠ½å–è§„æ ¼"""
    
    # åŠ è½½ prompt æ¨¡æ¿
    prompt = _load_prompt("project_info_v2.md")
    
    # å››ä¸ªæŸ¥è¯¢ç»´åº¦
    queries = {
        "base": "æ‹›æ ‡å…¬å‘Š é¡¹ç›®åç§° é¡¹ç›®ç¼–å· é¢„ç®—é‡‘é¢ é‡‡è´­äºº ä»£ç†æœºæ„ æŠ•æ ‡æˆªæ­¢ å¼€æ ‡ æ—¶é—´ åœ°ç‚¹ è”ç³»äºº ç”µè¯",
        "technical": "æŠ€æœ¯è¦æ±‚ æŠ€æœ¯è§„èŒƒ æŠ€æœ¯å‚æ•° è®¾å¤‡å‚æ•° æ€§èƒ½æŒ‡æ ‡ åŠŸèƒ½è¦æ±‚ è§„æ ¼ å‹å· å‚æ•°è¡¨",
        "business": "å•†åŠ¡æ¡æ¬¾ åˆåŒæ¡æ¬¾ ä»˜æ¬¾æ–¹å¼ äº¤ä»˜æœŸ å·¥æœŸ è´¨ä¿ éªŒæ”¶ è¿çº¦è´£ä»» å‘ç¥¨",
        "scoring": "è¯„åˆ†æ ‡å‡† è¯„æ ‡åŠæ³• è¯„å®¡åŠæ³• è¯„åˆ†ç»†åˆ™ åˆ†å€¼ æƒé‡ åŠ åˆ†é¡¹ å¦å†³é¡¹ èµ„æ ¼å®¡æŸ¥",
    }
    
    # æ£€ç´¢å‚æ•°
    top_k_per_query = 30  # æ¯ä¸ªæŸ¥è¯¢è¿”å›30ä¸ªæ–‡æ¡£å—
    top_k_total = 120     # æ€»è®¡æœ€å¤š120ä¸ªæ–‡æ¡£å—
    
    return ExtractionSpec(
        prompt=prompt,
        queries=queries,
        topk_per_query=top_k_per_query,
        topk_total=top_k_total,
        doc_types=["tender"],
        temperature=0.0,  # ä¿è¯å¯å¤ç°
    )
```

**Promptæ¨¡æ¿** (`prompts/project_info_v2.md`):
- å®šä¹‰äº†ä¸¥æ ¼çš„ JSON è¾“å‡ºæ ¼å¼
- åŒ…å«å››ä¸ªä¸»è¦æ¿å—:
  - `base`: åŸºæœ¬ä¿¡æ¯ï¼ˆé¡¹ç›®åç§°ã€é¢„ç®—ã€è”ç³»äººç­‰ï¼‰
  - `technical_parameters`: æŠ€æœ¯å‚æ•°ï¼ˆåŠŸèƒ½è¦æ±‚ã€æ€§èƒ½æŒ‡æ ‡ç­‰ï¼‰
  - `business_terms`: å•†åŠ¡æ¡æ¬¾ï¼ˆä»˜æ¬¾ã€éªŒæ”¶ã€è´¨ä¿ç­‰ï¼‰
  - `scoring_criteria`: è¯„åˆ†æ ‡å‡†ï¼ˆè¯„æ ‡åŠæ³•ã€è¯„åˆ†ç»†åˆ™ç­‰ï¼‰

---

### 2.4 æ ¸å¿ƒå¼•æ“å±‚ - ExtractionEngine

**æ–‡ä»¶**: `backend/app/platform/extraction/engine.py`

**æ–¹æ³•**: `run(spec, retriever, llm, project_id, ...)`

**æ‰§è¡Œæ­¥éª¤**:

#### æ­¥éª¤1: æ–‡æ¡£æ£€ç´¢
```python:64:76:backend/app/platform/extraction/engine.py
# 1. æ‰§è¡Œæ£€ç´¢
retrieval_start = time.time()
all_chunks, query_trace = await self._retrieve_chunks(
    spec=spec,
    retriever=retriever,
    project_id=project_id,
    embedding_provider=embedding_provider,
    trace_enabled=trace_enabled,
    run_id=run_id,
    mode=mode,
)
retrieval_ms = int((time.time() - retrieval_start) * 1000)
logger.info(f"AFTER_RETRIEVAL count={len(all_chunks)} ms={retrieval_ms}")
```

**æ£€ç´¢è¿‡ç¨‹** (`_retrieve_chunks`):
- å¯¹æ¯ä¸ªæŸ¥è¯¢ç»´åº¦ï¼ˆbase/technical/business/scoringï¼‰ç‹¬ç«‹æ£€ç´¢
- ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æœç´¢ (pgvector)
- å»é‡åˆå¹¶ç»“æœ
- æˆªæ–­åˆ°æ€»é‡é™åˆ¶ (top_k_total=120)

#### æ­¥éª¤2: æ„å»ºä¸Šä¸‹æ–‡
```python:89:99:backend/app/platform/extraction/engine.py
# 2. æ„å»ºä¸Šä¸‹æ–‡
chunk_dicts = [
    {
        "chunk_id": c.chunk_id,
        "text": c.text,
        "meta": c.meta
    }
    for c in all_chunks
]
ctx = build_marked_context(chunk_dicts)
```

**ä¸Šä¸‹æ–‡æ ¼å¼**:
```
<chunk id="chunk_abc123">
åŸæ–‡å†…å®¹...
</chunk>

<chunk id="chunk_def456">
åŸæ–‡å†…å®¹...
</chunk>
```

#### æ­¥éª¤3: è°ƒç”¨å¤§æ¨¡å‹
```python:102:114:backend/app/platform/extraction/engine.py
# 3. è°ƒç”¨ LLM
messages = [
    {"role": "system", "content": spec.prompt.strip()},
    {"role": "user", "content": f"æ‹›æ ‡æ–‡ä»¶åŸæ–‡ç‰‡æ®µï¼š\n{ctx}"},
]

llm_start = time.time()
out_text = await call_llm(
    messages, 
    llm, 
    model_id, 
    temperature=spec.temperature, 
    max_tokens=4096
)
```

#### æ­¥éª¤4: è§£æJSONç»“æœ
```python:123:136:backend/app/platform/extraction/engine.py
# 4. è§£æ JSON
try:
    obj = extract_json(out_text)
except Exception as e:
    # å°è¯•ä¿®å¤
    try:
        obj = repair_json(out_text)
    except Exception as e2:
        obj = {}
```

#### æ­¥éª¤5: æå–æ•°æ®å’Œè¯æ®
```python:141:165:backend/app/platform/extraction/engine.py
# 5. æå–æ•°æ®å’Œè¯æ®
if isinstance(obj, dict):
    data = obj.get("data") or obj
    evidence_chunk_ids = obj.get("evidence_chunk_ids") or []

# 6. ç”Ÿæˆ evidence_spans
evidence_spans = self._generate_evidence_spans(all_chunks, evidence_chunk_ids)

# 7. æ„å»ºè¿½è¸ªä¿¡æ¯
trace = self._build_trace(query_trace, spec, len(all_chunks), trace_enabled)
```

#### æ­¥éª¤6: è¿”å›ç»“æœ
```python:180:186:backend/app/platform/extraction/engine.py
return ExtractionResult(
    data=data,
    evidence_chunk_ids=evidence_chunk_ids,
    evidence_spans=evidence_spans,
    raw_model_output=out_text,
    retrieval_trace=trace
)
```

---

### 2.5 æ£€ç´¢å±‚ - RetrievalFacade & NewRetriever

**æ–‡ä»¶**: `backend/app/platform/retrieval/facade.py`

**RetrievalFacade** è´Ÿè´£æ ¹æ® cutover æ¨¡å¼è·¯ç”±åˆ°åˆé€‚çš„æ£€ç´¢å™¨ã€‚

**NEW_ONLY æ¨¡å¼æµç¨‹**:
```python:81:95:backend/app/platform/retrieval/facade.py
if mode == CutoverMode.NEW_ONLY:
    try:
        results = await self.new_retriever.retrieve(
            query=query,
            project_id=project_id,
            doc_types=doc_types,
            embedding_provider=embedding_provider,
            top_k=top_k,
            **kwargs
        )
        return results
    except Exception as e:
        raise ValueError(f"NEW_ONLY failed: {e}")
```

**NewRetriever** æ£€ç´¢æµç¨‹:
1. ä»æ•°æ®åº“è·å–æ–‡æ¡£å— (doc_segments æˆ– kb_chunks)
2. ä½¿ç”¨ pgvector è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
3. æ ¹æ® doc_types è¿‡æ»¤ï¼ˆä¾‹å¦‚åªæ£€ç´¢ "tender" ç±»å‹ï¼‰
4. è¿”å› top_k ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£å—

---

## ä¸‰ã€æ•°æ®ç»“æ„

### 3.1 è¾“å…¥æ•°æ®

**é¡¹ç›®ID** (`project_id`): 
- å”¯ä¸€æ ‡è¯†ä¸€ä¸ªæ‹›æ ‡é¡¹ç›®

**æ–‡æ¡£æ¥æº**:
- è¡¨: `doc_segments` (æ–°è¡¨) æˆ– `kb_chunks` (æ—§è¡¨)
- ç±»å‹: `doc_type = 'tender'`
- å­—æ®µ: `segment_id`, `content`, `position`, `embedding`

### 3.2 è¾“å‡ºæ•°æ®ç»“æ„

```json
{
  "data": {
    "base": {
      "projectName": "é¡¹ç›®åç§°",
      "ownerName": "æ‹›æ ‡äºº/ä¸šä¸»",
      "agencyName": "ä»£ç†æœºæ„",
      "bidDeadline": "æŠ•æ ‡æˆªæ­¢æ—¶é—´",
      "bidOpeningTime": "å¼€æ ‡æ—¶é—´",
      "budget": "é¢„ç®—é‡‘é¢",
      "maxPrice": "æœ€é«˜é™ä»·",
      "bidBond": "æŠ•æ ‡ä¿è¯é‡‘",
      "schedule": "å·¥æœŸè¦æ±‚",
      "quality": "è´¨é‡è¦æ±‚",
      "location": "é¡¹ç›®åœ°ç‚¹/äº¤ä»˜åœ°ç‚¹",
      "contact": "è”ç³»äººä¸ç”µè¯"
    },
    "technical_parameters": [
      {
        "category": "åˆ†ç±»",
        "item": "æ¡ç›®æ ‡é¢˜",
        "requirement": "è¦æ±‚æè¿°",
        "parameters": [
          {
            "name": "å‚æ•°å",
            "value": "å‚æ•°å€¼",
            "unit": "å•ä½",
            "remark": "å¤‡æ³¨"
          }
        ],
        "evidence_chunk_ids": ["chunk_xxx"]
      }
    ],
    "business_terms": [
      {
        "term": "æ¡æ¬¾åç§°",
        "requirement": "æ¡æ¬¾å†…å®¹",
        "evidence_chunk_ids": ["chunk_xxx"]
      }
    ],
    "scoring_criteria": {
      "evaluationMethod": "è¯„æ ‡åŠæ³•",
      "items": [
        {
          "category": "è¯„åˆ†å¤§é¡¹",
          "item": "è¯„åˆ†ç»†åˆ™",
          "score": "åˆ†å€¼",
          "rule": "å¾—åˆ†è§„åˆ™",
          "evidence_chunk_ids": ["chunk_xxx"]
        }
      ]
    }
  },
  "evidence_chunk_ids": ["chunk_xxx", "chunk_yyy"],
  "evidence_spans": [
    {
      "source": "doc_version_id",
      "page_no": 5,
      "snippet": "è¯æ®ç‰‡æ®µ..."
    }
  ],
  "retrieval_trace": {
    "retrieval_provider": "new",
    "retrieval_strategy": "multi_query",
    "queries": {
      "base": {"retrieved_count": 30, "top_ids": [...]},
      "technical": {"retrieved_count": 30, ...},
      "business": {"retrieved_count": 30, ...},
      "scoring": {"retrieved_count": 30, ...}
    },
    "top_k_per_query": 30,
    "top_k_total": 120,
    "retrieved_count_total": 120,
    "doc_types": ["tender"]
  }
}
```

---

## å››ã€å…³é”®æŠ€æœ¯ç‚¹

### 4.1 å¤šæŸ¥è¯¢æ£€ç´¢ç­–ç•¥

ä½¿ç”¨4ä¸ªä¸åŒç»´åº¦çš„æŸ¥è¯¢å…³é”®è¯ï¼Œç¡®ä¿è¦†ç›–å®Œæ•´ä¿¡æ¯ï¼š
- **base**: åŸºæœ¬ä¿¡æ¯ç›¸å…³ï¼ˆé¡¹ç›®åç§°ã€é¢„ç®—ã€è”ç³»äººç­‰ï¼‰
- **technical**: æŠ€æœ¯å‚æ•°ç›¸å…³ï¼ˆæŠ€æœ¯è¦æ±‚ã€æ€§èƒ½æŒ‡æ ‡ç­‰ï¼‰
- **business**: å•†åŠ¡æ¡æ¬¾ç›¸å…³ï¼ˆä»˜æ¬¾ã€éªŒæ”¶ã€è´¨ä¿ç­‰ï¼‰
- **scoring**: è¯„åˆ†æ ‡å‡†ç›¸å…³ï¼ˆè¯„æ ‡åŠæ³•ã€è¯„åˆ†ç»†åˆ™ç­‰ï¼‰

### 4.2 å‘é‡æ£€ç´¢ (pgvector)

- ä½¿ç”¨ PostgreSQL çš„ pgvector æ‰©å±•
- åŸºäºæ–‡æ¡£å—çš„ embedding å‘é‡
- è®¡ç®—æŸ¥è¯¢å‘é‡ä¸æ–‡æ¡£å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
- è¿”å›æœ€ç›¸ä¼¼çš„ top_k ä¸ªç»“æœ

### 4.3 ä¸Šä¸‹æ–‡æ ‡è®° (Marked Context)

ä¸ºæ¯ä¸ªæ–‡æ¡£å—æ·»åŠ  `<chunk id="...">` æ ‡è®°ï¼š
- ä¾¿äº LLM ç†è§£æ–‡æ¡£ç»“æ„
- ä¾¿äºè¿½æº¯è¯æ®æ¥æº
- ä¾¿äºåç»­éªŒè¯å’Œå®¡è®¡

### 4.4 JSON è§£æä¸ä¿®å¤

- ä½¿ç”¨ `extract_json()` æå– LLM è¾“å‡ºä¸­çš„ JSON
- æ”¯æŒ ```json ... ``` ä»£ç å—æ ¼å¼
- å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨ `repair_json()` å°è¯•ä¿®å¤
- å¤„ç†å¸¸è§æ ¼å¼é—®é¢˜ï¼ˆç¼ºå°‘å¼•å·ã€é€—å·ç­‰ï¼‰

### 4.5 è¯æ®è¿½è¸ª

- **evidence_chunk_ids**: å¼•ç”¨çš„æ–‡æ¡£å—IDåˆ—è¡¨
- **evidence_spans**: åŒ…å«é¡µç å’Œæ–‡æœ¬ç‰‡æ®µçš„è¯¦ç»†è¯æ®
- **retrieval_trace**: æ£€ç´¢è¿‡ç¨‹çš„å®Œæ•´è¿½è¸ªä¿¡æ¯

---

## äº”ã€é…ç½®å‚æ•°

### 5.1 ç¯å¢ƒå˜é‡

```bash
# Cutover æ¨¡å¼æ§åˆ¶
EXTRACT_MODE=NEW_ONLY           # æŠ½å–æ¨¡å¼ï¼ˆå¿…é¡»ï¼‰
RETRIEVAL_MODE=NEW_ONLY         # æ£€ç´¢æ¨¡å¼ï¼ˆå¿…é¡»ï¼‰

# æ£€ç´¢å‚æ•°
V2_RETRIEVAL_TOPK_PER_QUERY=30  # æ¯ä¸ªæŸ¥è¯¢çš„ top-k
V2_RETRIEVAL_TOPK_TOTAL=120     # æ€»è®¡ top-k

# æŸ¥è¯¢è‡ªå®šä¹‰ï¼ˆJSONæ ¼å¼ï¼‰
V2_PROJECT_INFO_QUERIES_JSON='{"base": "...", "technical": "...", ...}'

# è¿½è¸ªæ§åˆ¶
EXTRACT_TRACE_ENABLED=true      # æ˜¯å¦å¯ç”¨è¿½è¸ªä¿¡æ¯
```

### 5.2 æ•°æ®åº“ä¾èµ–

**å¿…éœ€çš„è¡¨**:
- `documents`: æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
- `document_versions`: æ–‡æ¡£ç‰ˆæœ¬
- `doc_segments`: æ–‡æ¡£å—ï¼ˆæ–°è¡¨ï¼Œæ¨èï¼‰
- `kb_chunks`: æ–‡æ¡£å—ï¼ˆæ—§è¡¨ï¼Œå‘åå…¼å®¹ï¼‰
- `project_info`: é¡¹ç›®ä¿¡æ¯å­˜å‚¨è¡¨

**å¿…éœ€çš„æ‰©å±•**:
- `pgvector`: å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢

---

## å…­ã€å¯ç”¨æ€§è¯„ä¼°

### 6.1 åŠŸèƒ½å®Œæ•´æ€§ âœ…

| åŠŸèƒ½æ¨¡å— | çŠ¶æ€ | è¯´æ˜ |
|---------|------|------|
| åŸºæœ¬ä¿¡æ¯æŠ½å– | âœ… å¯ç”¨ | æ”¯æŒé¡¹ç›®åç§°ã€é¢„ç®—ã€è”ç³»äººç­‰12ä¸ªå­—æ®µ |
| æŠ€æœ¯å‚æ•°æŠ½å– | âœ… å¯ç”¨ | æ”¯æŒå‚æ•°åŒ–ç»“æ„ï¼ˆname/value/unit/remarkï¼‰ |
| å•†åŠ¡æ¡æ¬¾æŠ½å– | âœ… å¯ç”¨ | æ”¯æŒä»˜æ¬¾ã€éªŒæ”¶ã€è´¨ä¿ç­‰æ¡æ¬¾ |
| è¯„åˆ†æ ‡å‡†æŠ½å– | âœ… å¯ç”¨ | æ”¯æŒè¯„åˆ†å¤§é¡¹ã€ç»†åˆ™ã€åˆ†å€¼ã€è§„åˆ™ |
| è¯æ®è¿½æº¯ | âœ… å¯ç”¨ | æ”¯æŒ chunk_id å’Œ evidence_span |
| æ£€ç´¢è¿½è¸ª | âœ… å¯ç”¨ | æ”¯æŒå®Œæ•´çš„æ£€ç´¢è¿‡ç¨‹è¿½è¸ª |

### 6.2 æŠ€æœ¯æ¶æ„ âœ…

| ç»„ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| ExtractionEngine | âœ… å¯ç”¨ | é€šç”¨æŠ½å–å¼•æ“ï¼Œæ¶æ„æ¸…æ™° |
| RetrievalFacade | âœ… å¯ç”¨ | æ”¯æŒ cutover æ¨¡å¼åˆ‡æ¢ |
| NewRetriever | âœ… å¯ç”¨ | åŸºäº pgvector çš„å‘é‡æ£€ç´¢ |
| JSON è§£æ | âœ… å¯ç”¨ | æ”¯æŒæå–å’Œä¿®å¤ |
| å¤šæŸ¥è¯¢ç­–ç•¥ | âœ… å¯ç”¨ | 4ç»´åº¦æŸ¥è¯¢ï¼Œè¦†ç›–å…¨é¢ |

### 6.3 æ•°æ®å…¼å®¹æ€§ âœ…

| æ•°æ®æº | çŠ¶æ€ | è¯´æ˜ |
|--------|------|------|
| doc_segments (æ–°è¡¨) | âœ… ä¼˜å…ˆ | æ¨èä½¿ç”¨ï¼Œç»“æ„æ›´æ¸…æ™° |
| kb_chunks (æ—§è¡¨) | âœ… å…¼å®¹ | å‘åå…¼å®¹ï¼Œè‡ªåŠ¨å›é€€ |
| æ—§è¡¨å†™å…¥ | âœ… å¯ç”¨ | ä¿è¯å‰ç«¯å…¼å®¹æ€§ |

### 6.4 è¿ç»´ç›‘æ§ âœ…

| åŠŸèƒ½ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| æ—¥å¿—è¿½è¸ª | âœ… å¯ç”¨ | è¯¦ç»†çš„ç»“æ„åŒ–æ—¥å¿— |
| æ—¶é—´ç»Ÿè®¡ | âœ… å¯ç”¨ | å„é˜¶æ®µè€—æ—¶ç»Ÿè®¡ |
| é”™è¯¯å¤„ç† | âœ… å¯ç”¨ | åˆ†çº§é”™è¯¯å¤„ç†å’Œå›é€€ |
| Job è¿½è¸ª | âœ… å¯é€‰ | æ”¯æŒ platform job è¿½è¸ª |

---

## ä¸ƒã€å·²çŸ¥é™åˆ¶

### 7.1 æ¨¡å¼é™åˆ¶

- âŒ ä»…æ”¯æŒ NEW_ONLY æ¨¡å¼ï¼Œä¸æ”¯æŒæ—§ç‰ˆæŠ½å–
- âŒ å¦‚æœ `EXTRACT_MODE != NEW_ONLY`ï¼Œä¼šç›´æ¥æŠ›å‡ºå¼‚å¸¸

### 7.2 æ€§èƒ½é™åˆ¶

- âš ï¸ æ¯æ¬¡æŠ½å–æœ€å¤šæ£€ç´¢ 120 ä¸ªæ–‡æ¡£å— (top_k_total)
- âš ï¸ LLM è°ƒç”¨æœ‰ max_tokens=4096 é™åˆ¶
- âš ï¸ å¤§å‹æ‹›æ ‡æ–‡æ¡£å¯èƒ½éœ€è¦å¤šæ¬¡è¿­ä»£

### 7.3 æ•°æ®è´¨é‡ä¾èµ–

- âš ï¸ ä¾èµ–æ–‡æ¡£åˆ†å—è´¨é‡ï¼ˆchunk åˆ‡åˆ†åˆç†æ€§ï¼‰
- âš ï¸ ä¾èµ– embedding è´¨é‡ï¼ˆå‘é‡è¡¨ç¤ºå‡†ç¡®æ€§ï¼‰
- âš ï¸ ä¾èµ– LLM èƒ½åŠ›ï¼ˆç†è§£å’ŒæŠ½å–èƒ½åŠ›ï¼‰

---

## å…«ã€ä½¿ç”¨ç¤ºä¾‹

### 8.1 Python è°ƒç”¨ç¤ºä¾‹

```python
from app.services.tender_service import TenderService

# åˆå§‹åŒ–æœåŠ¡
service = TenderService(pool=db_pool, llm=llm_orchestrator)

# è°ƒç”¨æŠ½å–
result = service.extract_project_info(
    project_id="proj_123",
    model_id="gpt-4",
    run_id="run_456",
    owner_id="user_789"
)

# ç»“æœåŒ…å«åœ¨ run çš„ result_json ä¸­
```

### 8.2 API è°ƒç”¨ç¤ºä¾‹ (å‡è®¾)

```bash
POST /api/v1/tender/projects/{project_id}/extract-info
Content-Type: application/json

{
  "model_id": "gpt-4",
  "run_id": "run_456"
}
```

---

## ä¹ã€æ•…éšœæ’æŸ¥

### 9.1 å¸¸è§é”™è¯¯

#### é”™è¯¯1: "Legacy extraction deleted"
```
RuntimeError: Legacy extraction deleted. Set EXTRACT_MODE=NEW_ONLY
```
**åŸå› **: ç¯å¢ƒå˜é‡ `EXTRACT_MODE` ä¸æ˜¯ NEW_ONLY  
**è§£å†³**: è®¾ç½® `export EXTRACT_MODE=NEW_ONLY`

#### é”™è¯¯2: "No embedding provider configured"
```
ValueError: No embedding provider configured
```
**åŸå› **: embedding provider æœªé…ç½®  
**è§£å†³**: æ£€æŸ¥ embedding_provider_store é…ç½®

#### é”™è¯¯3: "No chunks found"
```
WARNING: No chunks found for project {project_id}
```
**åŸå› **: é¡¹ç›®æ²¡æœ‰ä¸Šä¼ æ‹›æ ‡æ–‡æ¡£ï¼Œæˆ–æ–‡æ¡£æœªåˆ†å—  
**è§£å†³**: æ£€æŸ¥ doc_segments æˆ– kb_chunks è¡¨ä¸­æ˜¯å¦æœ‰æ•°æ®

#### é”™è¯¯4: JSON è§£æå¤±è´¥
```
ERROR: JSONè§£æå¤±è´¥: Expecting value: line 1 column 1
```
**åŸå› **: LLM è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®  
**è§£å†³**: 
- æ£€æŸ¥ prompt æ¨¡æ¿
- å°è¯•ä¸åŒçš„ model_id
- æŸ¥çœ‹ raw_model_output æ—¥å¿—

### 9.2 è°ƒè¯•å»ºè®®

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**:
   ```python
   import logging
   logging.getLogger("app.platform.extraction").setLevel(logging.DEBUG)
   ```

2. **å¯ç”¨è¿½è¸ª**:
   ```bash
   export EXTRACT_TRACE_ENABLED=true
   ```

3. **æŸ¥çœ‹æ£€ç´¢ç»“æœ**:
   - æ£€æŸ¥ `retrieval_trace` ä¸­çš„ `retrieved_count`
   - æ£€æŸ¥ `queries` å„ç»´åº¦çš„æ£€ç´¢æ•°é‡

4. **æŸ¥çœ‹ LLM è¾“å‡º**:
   - æ£€æŸ¥ `raw_model_output` å­—æ®µ
   - æŸ¥çœ‹æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„ JSON

---

## åã€æ€»ç»“

### âœ… å¯ç”¨æ€§ç»“è®º

**æ‹›æŠ•æ ‡åº”ç”¨çš„æå–åŸºæœ¬ä¿¡æ¯åŠŸèƒ½æ˜¯å¯ç”¨çš„**ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š

1. **æ¶æ„æ¸…æ™°**: åˆ†å±‚è®¾è®¡ï¼ŒèŒè´£æ˜ç¡®
2. **åŠŸèƒ½å®Œæ•´**: æ”¯æŒå››å¤§æ¿å—ä¿¡æ¯æŠ½å–
3. **è¯æ®å¯è¿½æº¯**: å®Œæ•´çš„è¯æ®é“¾å’Œè¿½è¸ªä¿¡æ¯
4. **æ€§èƒ½å¯æ§**: åˆ†é˜¶æ®µæ‰§è¡Œï¼Œæœ‰æ—¶é—´ç»Ÿè®¡
5. **é”™è¯¯å¤„ç†å®Œå–„**: å¤šçº§å›é€€å’Œé”™è¯¯å¤„ç†
6. **å‘åå…¼å®¹**: æ”¯æŒæ–°æ—§æ•°æ®è¡¨

### âš ï¸ æ³¨æ„äº‹é¡¹

1. å¿…é¡»è®¾ç½® `EXTRACT_MODE=NEW_ONLY`
2. å¿…é¡»é…ç½® embedding provider
3. å¿…é¡»æœ‰æ‹›æ ‡æ–‡æ¡£æ•°æ®ï¼ˆdoc_segments æˆ– kb_chunksï¼‰
4. LLM èƒ½åŠ›å½±å“æŠ½å–è´¨é‡

### ğŸš€ æ¨èé…ç½®

```bash
# ç¯å¢ƒå˜é‡
export EXTRACT_MODE=NEW_ONLY
export RETRIEVAL_MODE=NEW_ONLY
export V2_RETRIEVAL_TOPK_PER_QUERY=30
export V2_RETRIEVAL_TOPK_TOTAL=120
export EXTRACT_TRACE_ENABLED=true

# LLM æ¨¡å‹
æ¨èä½¿ç”¨: gpt-4, gpt-4-turbo, claude-3-opus ç­‰é«˜èƒ½åŠ›æ¨¡å‹

# æ•°æ®åº“
ç¡®ä¿å®‰è£…: pgvector æ‰©å±•
ç¡®ä¿æœ‰æ•°æ®: doc_segments æˆ– kb_chunks è¡¨
```

---

## é™„å½•

### A. ç›¸å…³æ–‡ä»¶æ¸…å•

```
backend/app/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ tender_service.py               # å…¥å£æœåŠ¡
â”‚   â””â”€â”€ dao/
â”‚       â””â”€â”€ tender_dao.py                # æ•°æ®è®¿é—®å±‚
â”œâ”€â”€ works/tender/
â”‚   â”œâ”€â”€ extract_v2_service.py           # V2 æŠ½å–æœåŠ¡
â”‚   â”œâ”€â”€ extraction_specs/
â”‚   â”‚   â”œâ”€â”€ project_info_v2.py          # é¡¹ç›®ä¿¡æ¯è§„æ ¼
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ prompts/
â”‚       â””â”€â”€ project_info_v2.md          # Prompt æ¨¡æ¿
â””â”€â”€ platform/
    â”œâ”€â”€ extraction/
    â”‚   â”œâ”€â”€ engine.py                   # æ ¸å¿ƒå¼•æ“
    â”‚   â”œâ”€â”€ types.py                    # ç±»å‹å®šä¹‰
    â”‚   â”œâ”€â”€ context.py                  # ä¸Šä¸‹æ–‡æ„å»º
    â”‚   â”œâ”€â”€ json_utils.py               # JSON å·¥å…·
    â”‚   â””â”€â”€ llm_adapter.py              # LLM é€‚é…å™¨
    â””â”€â”€ retrieval/
        â”œâ”€â”€ facade.py                   # æ£€ç´¢é—¨é¢
        â””â”€â”€ new_retriever.py            # æ–°æ£€ç´¢å™¨
```

### B. æ•°æ®åº“è¡¨ç»“æ„

```sql
-- æ–‡æ¡£è¡¨
CREATE TABLE documents (
    document_id VARCHAR PRIMARY KEY,
    project_id VARCHAR NOT NULL,
    doc_type VARCHAR NOT NULL,
    ...
);

-- æ–‡æ¡£ç‰ˆæœ¬è¡¨
CREATE TABLE document_versions (
    doc_version_id VARCHAR PRIMARY KEY,
    document_id VARCHAR NOT NULL,
    is_current BOOLEAN DEFAULT TRUE,
    ...
);

-- æ–‡æ¡£å—è¡¨ï¼ˆæ–°ï¼‰
CREATE TABLE doc_segments (
    segment_id VARCHAR PRIMARY KEY,
    doc_version_id VARCHAR NOT NULL,
    content TEXT NOT NULL,
    position INTEGER,
    embedding VECTOR(1536),
    ...
);

-- é¡¹ç›®ä¿¡æ¯è¡¨
CREATE TABLE project_info (
    project_id VARCHAR PRIMARY KEY,
    data_json JSONB,
    evidence_chunk_ids TEXT[],
    updated_at TIMESTAMP,
    ...
);
```

### C. ç‰ˆæœ¬å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | è¯´æ˜ |
|------|------|------|
| v2 | 2025-12 | åŸºäº ExtractionEngine çš„æ–°æ¶æ„ |
| v1 | 2024-xx | æ—§ç‰ˆæŠ½å–ï¼ˆå·²åˆ é™¤ï¼‰ |

---

**æ–‡æ¡£ç”Ÿæˆ**: AI Assistant  
**æœ€åæ›´æ–°**: 2025-12-20  
**çŠ¶æ€**: å¯ç”¨ âœ…

