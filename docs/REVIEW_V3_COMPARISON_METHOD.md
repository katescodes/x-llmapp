# V3å®¡æ ¸æ¯”å¯¹æ–¹å¼è¯¦è§£ï¼šè¯­ä¹‰ vs å¤§æ¨¡å‹

## ğŸ¯ æ ¸å¿ƒç­”æ¡ˆ

**å½“å‰V3çš„æ¯”å¯¹æ–¹å¼æ˜¯ï¼šåŸºäºç»´åº¦ï¼ˆdimensionï¼‰çš„ç²—åŒ¹é… + ç®€å•è§„åˆ™ï¼ŒNOTçœŸæ­£çš„è¯­ä¹‰æˆ–å¤§æ¨¡å‹æ¯”å¯¹**

è®©æˆ‘è¯¦ç»†è§£é‡Šï¼š

## ä¸€ã€å½“å‰å®é™…å®ç°ï¼ˆå·²ä¸Šçº¿ï¼‰

### 1. åŸºç¡€è¯„ä¼°å™¨ï¼ˆBasicRequirementEvaluatorï¼‰âŒ ä¸ç”¨å¤§æ¨¡å‹

```python
# å½“å‰å®ç°ï¼šæŒ‰ç»´åº¦åŒ¹é…
def _evaluate_single_requirement(requirement, response_by_dimension):
    dimension = requirement.dimension  # ä¾‹å¦‚: "technical"
    
    # 1. æŸ¥æ‰¾è¯¥ç»´åº¦ä¸‹çš„æ‰€æœ‰å“åº”
    responses = response_by_dimension.get(dimension, [])
    
    # 2. ç®€å•åˆ¤æ–­ï¼šæœ‰å“åº” vs æ— å“åº”
    if len(responses) == 0:
        return "FAIL" if requirement.is_hard else "WARN"
    else:
        # åªæ£€æŸ¥å“åº”é•¿åº¦
        if total_length < 10:
            return "WARN"  # å¤ªçŸ­
        else:
            return "PASS"
```

**é—®é¢˜ï¼š**
- âŒ **ä¸æ˜¯è¯­ä¹‰åŒ¹é…**ï¼
- âŒ **åªçœ‹ç»´åº¦ç›¸åŒï¼Œä¸çœ‹å†…å®¹æ˜¯å¦åŒ¹é…**
- âŒ ä¾‹å¦‚ï¼šrequirement="æ”¯æŒé—­ç¯ç›‘æ§"ï¼Œresponse="æ”¯æŒæ•°æ®é‡‡é›†"ï¼Œå³ä½¿ä¸åŒ¹é…ä¹Ÿä¼šPASS

**ç¤ºä¾‹ï¼š**
```
æ‹›æ ‡è¦æ±‚A (dimension=technical):
  "ç³»ç»Ÿå¿…é¡»æ”¯æŒç«¯åˆ°ç«¯é—­ç¯ç›‘æ§"

æ‹›æ ‡è¦æ±‚B (dimension=technical):
  "ç³»ç»Ÿå¿…é¡»æ”¯æŒæ•°æ®å®æ—¶åˆ†æ"

æŠ•æ ‡å“åº” (dimension=technical):
  "æˆ‘ä»¬çš„ç³»ç»Ÿå…·å¤‡å®Œå–„çš„æ•°æ®é‡‡é›†åŠŸèƒ½"

å½“å‰åˆ¤æ–­ï¼š
  âœ“ è¦æ±‚A: PASS (å› ä¸ºtechnicalç»´åº¦æœ‰å“åº”)
  âœ“ è¦æ±‚B: PASS (å› ä¸ºtechnicalç»´åº¦æœ‰å“åº”)
  
å®é™…æƒ…å†µï¼š
  âŒ è¦æ±‚A: å“åº”å¹¶æœªæåˆ°"é—­ç¯ç›‘æ§"
  âŒ è¦æ±‚B: å“åº”å¹¶æœªæåˆ°"å®æ—¶åˆ†æ"
```

### 2. ç¡®å®šæ€§è§„åˆ™å¼•æ“ï¼ˆDeterministicRuleEngineï¼‰âŒ ä¸ç”¨å¤§æ¨¡å‹

```python
# åŸºäºæ¡ä»¶è¡¨è¾¾å¼ï¼Œä¸æ˜¯è¯­ä¹‰ç†è§£
rule_type = condition.get("type")

if rule_type == "check_value_threshold":
    # æ£€æŸ¥æ•°å€¼ï¼šä»·æ ¼ >= 100ä¸‡
    value = extract_number(response_text)
    if value >= threshold:
        return "PASS"

elif rule_type == "check_keyword":
    # æ£€æŸ¥å…³é”®è¯ï¼šå“åº”ä¸­æ˜¯å¦åŒ…å«"è¥ä¸šæ‰§ç…§"
    if "è¥ä¸šæ‰§ç…§" in response_text:
        return "PASS"
```

**ç‰¹ç‚¹ï¼š**
- âœ… å¿«é€Ÿã€ç¡®å®š
- âŒ ä¸ç†è§£è¯­ä¹‰
- âŒ å®¹æ˜“è¢«è¡¨è¿°æ–¹å¼æ¬ºéª—

### 3. è¯­ä¹‰LLMè§„åˆ™å¼•æ“ï¼ˆSemanticLLMRuleEngineï¼‰âœ… åº”è¯¥ç”¨å¤§æ¨¡å‹ï¼Œä½†å½“å‰æ˜¯ç©ºå®ç°

```python
# ç†è®ºè®¾è®¡ï¼šä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰åˆ¤æ–­
async def _evaluate_single_rule(...):
    # æ„å»ºprompt
    prompt = f"""
    æ‹›æ ‡è¦æ±‚ï¼š{requirement_text}
    æŠ•æ ‡å“åº”ï¼š{response_text}
    
    è¯·åˆ¤æ–­å“åº”æ˜¯å¦æ»¡è¶³è¦æ±‚ï¼š
    1. å†…å®¹æ˜¯å¦ç›¸å…³
    2. æ˜¯å¦å®Œæ•´å›ç­”
    3. è´¨é‡æ˜¯å¦åˆæ ¼
    """
    
    # è°ƒç”¨LLM
    llm_response = await self.llm.chat(prompt, model_id)
    
    # è§£æLLMçš„åˆ¤æ–­
    return parse_llm_judgment(llm_response)

# ä½†å½“å‰å®ç°ï¼š
# TODO: å®é™…è°ƒç”¨LLM
# æš‚æ—¶è¿”å›ç©ºç»“æœï¼ˆå¾…é›†æˆå®é™…LLMè°ƒç”¨ï¼‰
logger.info("Would call LLM for rule ...")
return []  # â† è¿”å›ç©ºï¼
```

**ç°çŠ¶ï¼š**
- âŒ **æœªå®ç°ï¼ä»£ç ä¸­æ˜¯TODOçŠ¶æ€**
- âŒ å³ä½¿æœ‰semantic_llmç±»å‹çš„è§„åˆ™ï¼Œä¹Ÿä¸ä¼šæ‰§è¡Œ
- âŒ åªæ˜¯æ‰“å°æ—¥å¿—è¯´"åº”è¯¥è°ƒç”¨LLM"ï¼Œç„¶åè¿”å›ç©º

## äºŒã€ç†æƒ³çš„è¯­ä¹‰/å¤§æ¨¡å‹æ¯”å¯¹

### æ–¹æ¡ˆAï¼šé€é¡¹è¯­ä¹‰åŒ¹é…ï¼ˆç»†ç²’åº¦ï¼‰

```python
for requirement in requirements:
    # æ‰¾åŒç»´åº¦çš„æ‰€æœ‰å“åº”
    candidate_responses = find_by_dimension(requirement.dimension)
    
    # ä½¿ç”¨LLMåˆ¤æ–­æ¯ä¸ªå“åº”æ˜¯å¦åŒ¹é…è¯¥è¦æ±‚
    matched_responses = []
    for response in candidate_responses:
        prompt = f"""
        æ‹›æ ‡è¦æ±‚ï¼š{requirement.text}
        æŠ•æ ‡å“åº”ï¼š{response.text}
        
        è¯·åˆ¤æ–­è¯¥å“åº”æ˜¯å¦æ»¡è¶³è¯¥è¦æ±‚ï¼Ÿ
        å›ç­”æ ¼å¼ï¼š
        - åŒ¹é…åº¦ï¼š0-100
        - åˆ¤æ–­ï¼šPASS/WARN/FAIL
        - ç†ç”±ï¼š...
        """
        
        llm_result = await llm.chat(prompt)
        if llm_result.match_score >= 80:
            matched_responses.append(response)
    
    # åŸºäºåŒ¹é…ç»“æœåˆ¤æ–­
    if len(matched_responses) == 0:
        result = "FAIL"
    elif match_quality < threshold:
        result = "WARN"
    else:
        result = "PASS"
```

**ä¼˜ç‚¹ï¼š**
- âœ… çœŸæ­£çš„è¯­ä¹‰ç†è§£
- âœ… å‡†ç¡®åº¦é«˜
- âœ… å¯ä»¥ç»™å‡ºè¯¦ç»†ç†ç”±

**ç¼ºç‚¹ï¼š**
- âš ï¸ æ…¢ï¼ˆ69ä¸ªè¦æ±‚ Ã— 12ä¸ªå“åº” = 828æ¬¡LLMè°ƒç”¨ï¼‰
- âš ï¸ è´µï¼ˆå¤§é‡tokenæ¶ˆè€—ï¼‰
- âš ï¸ ä¸ç¨³å®šï¼ˆLLMå¯èƒ½ç»™å‡ºä¸ä¸€è‡´çš„åˆ¤æ–­ï¼‰

### æ–¹æ¡ˆBï¼šæ‰¹é‡è¯­ä¹‰åŒ¹é…ï¼ˆç²—ç²’åº¦ï¼‰

```python
# æŒ‰ç»´åº¦æ‰¹é‡åˆ¤æ–­
for dimension in dimensions:
    reqs = requirements_by_dimension[dimension]
    resps = responses_by_dimension[dimension]
    
    prompt = f"""
    è¯¥ç»´åº¦çš„æ‹›æ ‡è¦æ±‚ï¼ˆ{len(reqs)}æ¡ï¼‰ï¼š
    1. {reqs[0].text}
    2. {reqs[1].text}
    ...
    
    è¯¥ç»´åº¦çš„æŠ•æ ‡å“åº”ï¼ˆ{len(resps)}æ¡ï¼‰ï¼š
    A. {resps[0].text}
    B. {resps[1].text}
    ...
    
    è¯·åˆ¤æ–­ï¼š
    - æ¯ä¸ªè¦æ±‚æ˜¯å¦è¢«å“åº”æ»¡è¶³
    - ç»™å‡ºåŒ¹é…å…³ç³»çŸ©é˜µ
    - è¯„ä¼°æ•´ä½“è´¨é‡
    """
    
    llm_result = await llm.chat(prompt)
    # è§£ææ‰¹é‡åˆ¤æ–­ç»“æœ
```

**ä¼˜ç‚¹ï¼š**
- âœ… è¾ƒå¿«ï¼ˆ5ä¸ªç»´åº¦ = 5æ¬¡LLMè°ƒç”¨ï¼‰
- âœ… æˆæœ¬å¯æ§
- âœ… æœ‰å…¨å±€è§†è§’

**ç¼ºç‚¹ï¼š**
- âš ï¸ å•ä¸ªpromptè¿‡é•¿ï¼ˆå¯èƒ½è¶…tokené™åˆ¶ï¼‰
- âš ï¸ å‡†ç¡®åº¦å¯èƒ½é™ä½

### æ–¹æ¡ˆCï¼šå‘é‡è¯­ä¹‰åŒ¹é…ï¼ˆæŠ€æœ¯æ–¹æ¡ˆï¼‰

```python
# 1. ä¸ºæ‰€æœ‰è¦æ±‚å’Œå“åº”ç”Ÿæˆembedding
req_embeddings = []
for req in requirements:
    emb = embedding_model.embed(req.text)
    req_embeddings.append(emb)

resp_embeddings = []
for resp in responses:
    emb = embedding_model.embed(resp.text)
    resp_embeddings.append(emb)

# 2. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
similarity_matrix = cosine_similarity(req_embeddings, resp_embeddings)

# 3. ä¸ºæ¯ä¸ªè¦æ±‚æ‰¾æœ€åŒ¹é…çš„å“åº”
for i, req in enumerate(requirements):
    best_match_idx = np.argmax(similarity_matrix[i])
    best_score = similarity_matrix[i][best_match_idx]
    
    if best_score >= 0.85:
        result = "PASS"
    elif best_score >= 0.70:
        # è°ƒç”¨LLMè¿›ä¸€æ­¥åˆ¤æ–­
        result = await llm_verify(req, responses[best_match_idx])
    else:
        result = "FAIL"
```

**ä¼˜ç‚¹ï¼š**
- âœ… å¿«é€Ÿï¼ˆembeddingé¢„è®¡ç®—ï¼‰
- âœ… æˆæœ¬ä½
- âœ… å¯æ‰©å±•

**ç¼ºç‚¹ï¼š**
- âš ï¸ è¯­ä¹‰ç†è§£æ·±åº¦æœ‰é™
- âš ï¸ éœ€è¦è®­ç»ƒå¥½çš„embeddingæ¨¡å‹

## ä¸‰ã€ä¸‰ç§æ–¹å¼å¯¹æ¯”

| æ¯”å¯¹æ–¹å¼ | å½“å‰å®ç°ï¼Ÿ | å‡†ç¡®æ€§ | é€Ÿåº¦ | æˆæœ¬ | å¯è§£é‡Šæ€§ |
|---------|-----------|--------|------|------|---------|
| **ç»´åº¦åŒ¹é…** | âœ… æ˜¯ | â­â­ | â­â­â­â­â­ | ğŸ’° | â­â­ |
| **å…³é”®è¯/è§„åˆ™** | âœ… æ˜¯ | â­â­â­ | â­â­â­â­â­ | ğŸ’° | â­â­â­â­ |
| **LLMé€é¡¹åˆ¤æ–­** | âŒ å¦ | â­â­â­â­â­ | â­ | ğŸ’°ğŸ’°ğŸ’°ğŸ’°ğŸ’° | â­â­â­â­â­ |
| **LLMæ‰¹é‡åˆ¤æ–­** | âŒ å¦ | â­â­â­â­ | â­â­â­ | ğŸ’°ğŸ’°ğŸ’° | â­â­â­â­ |
| **å‘é‡ç›¸ä¼¼åº¦** | âŒ å¦ | â­â­â­â­ | â­â­â­â­ | ğŸ’°ğŸ’° | â­â­â­ |

## å››ã€æµ‹è¯•2é¡¹ç›®çš„å®é™…æƒ…å†µ

```
æ‹›æ ‡è¦æ±‚ï¼š69æ¡
æŠ•æ ‡å“åº”ï¼š12æ¡
å½“å‰æ¯”å¯¹æ–¹å¼ï¼šç»´åº¦åŒ¹é…

ç»´åº¦åˆ†å¸ƒï¼š
  technical: 30ä¸ªè¦æ±‚ â† â†’ 10æ¡å“åº”
  business:  20ä¸ªè¦æ±‚ â† â†’ 2æ¡å“åº”
  qualification: 10ä¸ªè¦æ±‚ â† â†’ 0æ¡å“åº”
  commercial: 9ä¸ªè¦æ±‚ â† â†’ 0æ¡å“åº”

å½“å‰åˆ¤æ–­ï¼ˆåŸºäºç»´åº¦ï¼‰ï¼š
  âœ“ technicalç»´åº¦ï¼š30ä¸ªè¦æ±‚éƒ½PASSï¼ˆå› ä¸ºæœ‰10æ¡å“åº”ï¼‰
  âš ï¸ businessç»´åº¦ï¼š20ä¸ªè¦æ±‚éƒ¨åˆ†WARNï¼ˆåªæœ‰2æ¡å“åº”ï¼‰
  âœ— qualificationç»´åº¦ï¼š10ä¸ªè¦æ±‚éƒ½FAILï¼ˆæ— å“åº”ï¼‰
  âœ— commercialç»´åº¦ï¼š9ä¸ªè¦æ±‚éƒ½FAILï¼ˆæ— å“åº”ï¼‰

é—®é¢˜ï¼š
  âŒ technicalçš„30ä¸ªè¦æ±‚çœŸçš„éƒ½è¢«10æ¡å“åº”æ»¡è¶³äº†å—ï¼Ÿ
  âŒ æ²¡æœ‰æ£€æŸ¥ï¼åªæ˜¯å› ä¸ºç»´åº¦ç›¸åŒå°±è®¤ä¸ºæ»¡è¶³äº†
```

## äº”ã€æ”¹è¿›å»ºè®®

### çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰ï¼šå¢åŠ å‘é‡ç›¸ä¼¼åº¦åŒ¹é…

```python
class ImprovedBasicEvaluator:
    def __init__(self, embedding_model):
        self.embedding_model = embedding_model
    
    def evaluate_requirements(self, requirements, responses):
        # 1. æŒ‰ç»´åº¦ç²—åŒ¹é…ï¼ˆä¿ç•™ï¼‰
        dimension_matched = dimension_match(requirements, responses)
        
        # 2. ç›¸ä¼¼åº¦ç²¾åŒ¹é…ï¼ˆæ–°å¢ï¼‰
        for req in requirements:
            candidates = dimension_matched[req.dimension]
            
            # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
            req_emb = self.embedding_model.embed(req.text)
            best_match = None
            best_score = 0
            
            for resp in candidates:
                resp_emb = self.embedding_model.embed(resp.text)
                score = cosine_similarity(req_emb, resp_emb)
                if score > best_score:
                    best_score = score
                    best_match = resp
            
            # åˆ¤æ–­
            if best_score >= 0.85:
                result = "PASS"
            elif best_score >= 0.70:
                result = "WARN"
            else:
                result = "FAIL"
```

### ä¸­æœŸï¼ˆ1-2æœˆï¼‰ï¼šé›†æˆLLMè¯­ä¹‰åˆ¤æ–­

```python
# å®Œå–„SemanticLLMRuleEngineçš„å®ç°
async def _evaluate_single_rule(self, rule, reqs, resps, model_id):
    # æ„å»ºprompt
    prompt = self._build_semantic_prompt(rule, reqs, resps)
    
    # å®é™…è°ƒç”¨LLMï¼ˆä¸å†æ˜¯TODOï¼‰
    llm_response = await self.llm.chat(
        messages=[{"role": "user", "content": prompt}],
        model_id=model_id,
        temperature=0.0
    )
    
    # è§£æLLMçš„ç»“æ„åŒ–è¾“å‡º
    result = parse_llm_judgment(llm_response)
    return result
```

### é•¿æœŸï¼ˆ3-6æœˆï¼‰ï¼šæ··åˆæ™ºèƒ½å®¡æ ¸

```python
class HybridReviewEngine:
    """æ··åˆå®¡æ ¸å¼•æ“ï¼šè§„åˆ™ + å‘é‡ + LLM"""
    
    def review(self, requirements, responses):
        results = []
        
        for req in requirements:
            # ç¬¬1å±‚ï¼šç»´åº¦è¿‡æ»¤
            candidates = filter_by_dimension(req.dimension, responses)
            
            # ç¬¬2å±‚ï¼šå‘é‡åŒ¹é…
            best_matches = vector_match(req, candidates, top_k=3)
            
            # ç¬¬3å±‚ï¼šè§„åˆ™æ£€æŸ¥
            rule_checked = apply_rules(req, best_matches)
            
            # ç¬¬4å±‚ï¼šLLMæœ€ç»ˆåˆ¤æ–­ï¼ˆä»…å¯¹ä¸ç¡®å®šçš„ï¼‰
            if rule_checked.confidence < 0.8:
                final_result = await llm_judge(req, best_matches)
            else:
                final_result = rule_checked
            
            results.append(final_result)
        
        return results
```

## å…­ã€æ€»ç»“

### å½“å‰çŠ¶æ€
```
V3å®¡æ ¸ = ç»´åº¦ç²—åŒ¹é… + ç®€å•è§„åˆ™
        â‰  è¯­ä¹‰ç†è§£
        â‰  å¤§æ¨¡å‹åˆ¤æ–­
```

### ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

**ä¼˜ç‚¹ï¼š**
1. âœ… **å¿«é€Ÿ**ï¼šä¸ä¾èµ–LLMï¼Œç§’çº§å“åº”
2. âœ… **ç¨³å®š**ï¼šä¸å—LLM APIæ³¢åŠ¨å½±å“
3. âœ… **ä¾¿å®œ**ï¼šé›¶LLM tokenæˆæœ¬
4. âœ… **å¯æ§**ï¼šè§„åˆ™é€»è¾‘æ˜ç¡®

**ç¼ºç‚¹ï¼š**
1. âŒ **å‡†ç¡®æ€§æœ‰é™**ï¼šæ— æ³•çœŸæ­£ç†è§£è¯­ä¹‰
2. âŒ **è¦†ç›–ä¸å…¨**ï¼šåªè¦ç»´åº¦æœ‰å“åº”å°±è®¤ä¸ºæ»¡è¶³
3. âŒ **ä¸å¤Ÿæ™ºèƒ½**ï¼šæ— æ³•å¤„ç†å¤æ‚çš„è¯­ä¹‰å…³ç³»

### å»ºè®®çš„æ¼”è¿›è·¯å¾„

```
é˜¶æ®µ1ï¼ˆå½“å‰ï¼‰ï¼šç»´åº¦åŒ¹é… + è§„åˆ™
   â†“
é˜¶æ®µ2ï¼ˆ1ä¸ªæœˆå†…ï¼‰ï¼š+ å‘é‡ç›¸ä¼¼åº¦
   â†“
é˜¶æ®µ3ï¼ˆ3ä¸ªæœˆå†…ï¼‰ï¼š+ LLMè¯­ä¹‰åˆ¤æ–­
   â†“
é˜¶æ®µ4ï¼ˆ6ä¸ªæœˆå†…ï¼‰ï¼šæ··åˆæ™ºèƒ½å®¡æ ¸
```

**æ ¸å¿ƒæƒè¡¡ï¼šå‡†ç¡®æ€§ vs é€Ÿåº¦/æˆæœ¬**

- å¿«é€Ÿåˆå®¡ï¼šç”¨ç»´åº¦åŒ¹é…ï¼ˆå½“å‰æ–¹å¼ï¼‰
- æ­£å¼å®¡æ ¸ï¼šç”¨LLMè¯­ä¹‰åˆ¤æ–­ï¼ˆæœªæ¥æ–¹å‘ï¼‰
- æ··åˆæ–¹æ¡ˆï¼šè§„åˆ™ç­›é€‰ + LLMç¡®è®¤ï¼ˆæœ€ä½³å¹³è¡¡ï¼‰

