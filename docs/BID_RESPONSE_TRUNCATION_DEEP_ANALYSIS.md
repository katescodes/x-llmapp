# 投标响应抽取截断问题 - 深度分析与解决方案

## 问题根源

经过系统性排查，发现问题的根本原因是：

### LLM的"自然停止"行为

**关键发现**：
```
finish_reason: stop  （不是 "length"）
completion_tokens: 2768 （固定值）
```

**这意味着**：
- LLM并非因为达到max_tokens限制而停止
- 而是LLM自己"认为"任务已完成，主动停止生成
- 无论prompt如何强调"提取所有内容"，LLM始终在生成3条响应后停止

### 为什么会这样？

1. **示例效应**：Prompt中的示例只有3-4条响应，LLM学习了这个模式
2. **模型训练偏好**：该LLM模型可能在训练时被优化为"简洁回答"
3. **上下文理解**：LLM可能将任务理解为"提供代表性样例"而非"穷尽式提取"

## 已尝试的解决方案

### ✅ 方案1：增加max_tokens
- 从8192 → 16384 → 64000
- **结果**：无效，completion_tokens始终为2768

### ✅ 方案2：优化Prompt
- 添加"工作流程"说明
- 强调"20-50条"目标
- 多处重复"提取所有内容"
- **结果**：无效，LLM行为未改变

### ✅ 方案3：检查数据源
- 文档分段：70个
- 检索结果：56个chunks
- 上下文长度：69535字符
- **结果**：数据完整，不是数据问题

## 可行的解决方案

### 方案A：更换LLM模型（推荐）

**优点**：
- 从根本上解决问题
- 无需修改代码架构

**实施**：
选用以下模型之一：
- GPT-4 / GPT-4-Turbo（OpenAI）
- Claude 3 Opus/Sonnet（Anthropic）
- Qwen-72B / Qwen-110B（阿里云）
- DeepSeek-V2（国产，性价比高）

**预期效果**：
这些模型对"完整提取"类任务的理解更好，通常能输出20+条结果。

### 方案B：分批提取策略

**原理**：
将检索到的56个chunks分成多批，每批调用LLM，最后合并去重。

**实施难点**：
1. ExtractionEngine不支持直接传入chunks
2. 需要修改spec的retrieval_config
3. 去重逻辑需要精心设计

**预期效果**：
- 4批 × 3条 = 12条（去重后约10条）
- 仍然低于目标20-30条

### 方案C：改变提取粒度

**原理**：
不要求LLM一次输出完整JSON，而是：
1. 第一次调用：提取所有response_id和简要信息
2. 后续调用：针对每个response_id提取详细内容

**优点**：
- 绕过了LLM的"完整JSON"生成限制
- 可以提取更多条目

**缺点**：
- API调用次数激增（50+ calls）
- 总耗时大幅增加

### 方案D：接受现状+人工补充

**现实方案**：
1. 保持当前3条自动提取
2. 提供前端界面，允许用户：
   - 查看所有56个文档片段
   - 手动添加遗漏的响应要素
   - 系统辅助（提示可能的响应点）

**优点**：
- 开发成本低
- 保证完整性

**缺点**：
- 需要人工介入

## 推荐实施路径

###阶段1（立即）：接受现状并优化体验
1. 保持当前3条输出
2. 在前端明确标注"自动提取了3条，可能不完整"
3. 提供"补充提取"按钮，允许用户触发额外提取

### 阶段2（1周内）：更换LLM模型
1. 接入更强大的LLM（如Qwen-72B或Claude 3）
2. 对比测试输出质量
3. 如果新模型能输出20+条，则替换默认模型

### 阶段3（长期）：实施分批提取作为兜底
1. 实现完整的分批提取策略
2. 作为任何模型的兜底方案
3. 确保即使模型切换也能稳定工作

## 技术债务记录

**当前限制**：
- `gpt-oss-120b` 模型对结构化提取任务的completion_tokens固定在2768左右
- 无论max_tokens设置多大，finish_reason始终为"stop"
- Prompt工程无法改变这一行为

**建议**：
与LLM服务提供商沟通，了解：
1. 该模型是否有输出长度的隐式限制
2. 是否有参数可以调整（如`presence_penalty`、`frequency_penalty`）
3. 是否有更适合"完整提取"任务的模型版本

## 结论

这是一个**LLM模型行为特性导致的问题**，不是代码bug。短期内最有效的解决方案是**更换LLM模型**，而不是继续在当前模型上进行prompt工程或架构调整。

