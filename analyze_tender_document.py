#!/usr/bin/env python3
"""
åˆ†ææ‹›æ ‡æ–‡æ¡£å†…å®¹ï¼Œè¯„ä¼°æå–è¦æ±‚çš„å…¨é¢æ€§
"""
import sys
from docx import Document
import re

def analyze_document(docx_path):
    """åˆ†ædocxæ–‡æ¡£"""
    print(f"\n{'='*100}")
    print(f"ğŸ“„ æ‹›æ ‡æ–‡æ¡£åˆ†æ")
    print(f"{'='*100}")
    print(f"æ–‡æ¡£è·¯å¾„: {docx_path}\n")
    
    # è¯»å–æ–‡æ¡£
    doc = Document(docx_path)
    
    # æå–æ‰€æœ‰æ®µè½
    paragraphs = []
    for para in doc.paragraphs:
        text = para.text.strip()
        if text:
            paragraphs.append(text)
    
    print(f"æ–‡æ¡£æ€»æ®µè½æ•°ï¼š{len(paragraphs)}")
    
    # æå–æ‰€æœ‰è¡¨æ ¼
    tables = []
    for table in doc.tables:
        table_data = []
        for row in table.rows:
            row_data = []
            for cell in row.cells:
                row_data.append(cell.text.strip())
            table_data.append(row_data)
        tables.append(table_data)
    
    print(f"æ–‡æ¡£æ€»è¡¨æ ¼æ•°ï¼š{len(tables)}")
    
    # ç»Ÿè®¡è¡¨æ ¼æ€»è¡Œæ•°
    total_table_rows = sum(len(table) for table in tables)
    print(f"è¡¨æ ¼æ€»è¡Œæ•°ï¼š{total_table_rows}")
    
    # å…³é”®è¯ç»Ÿè®¡
    full_text = '\n'.join(paragraphs)
    
    keywords_stats = {
        'åºŸæ ‡': len(re.findall(r'åºŸæ ‡', full_text)),
        'å¦å†³': len(re.findall(r'å¦å†³', full_text)),
        'æ— æ•ˆ': len(re.findall(r'æ— æ•ˆ', full_text)),
        'å–æ¶ˆèµ„æ ¼': len(re.findall(r'å–æ¶ˆèµ„æ ¼', full_text)),
        'ä¸å¾—': len(re.findall(r'ä¸å¾—', full_text)),
        'ç¦æ­¢': len(re.findall(r'ç¦æ­¢', full_text)),
        'å¿…é¡»': len(re.findall(r'å¿…é¡»', full_text)),
        'åº”å½“': len(re.findall(r'åº”å½“', full_text)),
        'æŠ•æ ‡äººé¡»çŸ¥': len(re.findall(r'æŠ•æ ‡äººé¡»çŸ¥', full_text)),
        'è¯„å®¡åŠæ³•': len(re.findall(r'è¯„å®¡åŠæ³•', full_text)),
        'è¯„åˆ†æ ‡å‡†': len(re.findall(r'è¯„åˆ†æ ‡å‡†', full_text)),
        'èµ„æ ¼æ¡ä»¶': len(re.findall(r'èµ„æ ¼æ¡ä»¶', full_text)),
        'æŠ€æœ¯è¦æ±‚': len(re.findall(r'æŠ€æœ¯è¦æ±‚', full_text)),
        'é‡‡è´­éœ€æ±‚': len(re.findall(r'é‡‡è´­éœ€æ±‚', full_text)),
        'â–²': len(re.findall(r'â–²', full_text)),
        'â˜…': len(re.findall(r'â˜…', full_text)),
        '*': full_text.count('*'),
        'æŠ•æ ‡ä¿è¯é‡‘': len(re.findall(r'æŠ•æ ‡ä¿è¯é‡‘', full_text)),
        'æœ€é«˜é™ä»·': len(re.findall(r'æœ€é«˜é™ä»·', full_text)),
        'æ§åˆ¶ä»·': len(re.findall(r'æ§åˆ¶ä»·', full_text)),
    }
    
    print(f"\nğŸ” å…³é”®è¯é¢‘æ¬¡ç»Ÿè®¡ï¼š")
    for keyword, count in sorted(keywords_stats.items(), key=lambda x: x[1], reverse=True):
        if count > 0:
            print(f"  - '{keyword}': {count} æ¬¡")
    
    # æŸ¥æ‰¾ä¸»è¦ç« èŠ‚
    print(f"\nğŸ“š ä¸»è¦ç« èŠ‚ç»“æ„ï¼š")
    chapter_pattern = r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« |^ç¬¬[0-9]+ç« |^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€|^[0-9]+\.'
    chapters = []
    
    for i, para in enumerate(paragraphs):
        if re.match(chapter_pattern, para) or any(key in para for key in ['æŠ•æ ‡äººé¡»çŸ¥', 'è¯„å®¡åŠæ³•', 'åˆåŒæ¡æ¬¾', 'æŠ€æœ¯è¦æ±‚', 'é‡‡è´­éœ€æ±‚', 'è¯„åˆ†æ ‡å‡†']):
            chapters.append((i, para[:60]))  # åªä¿ç•™å‰60å­—ç¬¦
    
    for idx, (para_idx, chapter) in enumerate(chapters[:30], 1):  # æ˜¾ç¤ºå‰30ä¸ªç« èŠ‚
        print(f"  {idx:2d}. [Para {para_idx:4d}] {chapter}")
    
    if len(chapters) > 30:
        print(f"  ... è¿˜æœ‰ {len(chapters) - 30} ä¸ªç« èŠ‚æœªæ˜¾ç¤º")
    
    # åˆ†æè¡¨æ ¼
    print(f"\nğŸ“‹ è¡¨æ ¼åˆ†æï¼š")
    
    if len(tables) > 0:
        print(f"\nè¡¨æ ¼è¯¦æƒ…ï¼ˆå‰5ä¸ªï¼‰ï¼š")
        for i, table in enumerate(tables[:5], 1):
            print(f"\nè¡¨æ ¼ {i}:")
            print(f"  - è¡Œæ•°ï¼š{len(table)}")
            print(f"  - åˆ—æ•°ï¼š{len(table[0]) if table else 0}")
            
            # æ˜¾ç¤ºè¡¨å¤´ï¼ˆç¬¬ä¸€è¡Œï¼‰
            if table:
                header = table[0]
                print(f"  - è¡¨å¤´ï¼š{' | '.join(header[:5])}")  # åªæ˜¾ç¤ºå‰5åˆ—
                
                # åˆ¤æ–­è¡¨æ ¼ç±»å‹
                header_text = ' '.join(header).lower()
                if 'è¯„åˆ†' in header_text or 'åˆ†å€¼' in header_text:
                    print(f"  - ç±»å‹ï¼šâ­ è¯„åˆ†æ ‡å‡†è¡¨")
                elif 'å‚æ•°' in header_text or 'æŠ€æœ¯' in header_text:
                    print(f"  - ç±»å‹ï¼šâš™ï¸ æŠ€æœ¯å‚æ•°è¡¨")
                elif 'èµ„æ ¼' in header_text or 'æ¡ä»¶' in header_text:
                    print(f"  - ç±»å‹ï¼šğŸ“œ èµ„æ ¼æ¡ä»¶è¡¨")
                elif 'å•†åŠ¡' in header_text:
                    print(f"  - ç±»å‹ï¼šğŸ’¼ å•†åŠ¡è¦æ±‚è¡¨")
                else:
                    print(f"  - ç±»å‹ï¼šğŸ“„ å…¶ä»–è¡¨æ ¼")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹æ®Šæ ‡è®°
                table_text = '\n'.join([' '.join(row) for row in table])
                special_marks = {'â–²': 0, 'â˜…': 0, '*': 0}
                for mark in special_marks:
                    special_marks[mark] = table_text.count(mark)
                
                if any(special_marks.values()):
                    print(f"  - ç‰¹æ®Šæ ‡è®°ï¼š", end='')
                    for mark, count in special_marks.items():
                        if count > 0:
                            print(f"{mark}:{count}æ¬¡ ", end='')
                    print()
                
                # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹ï¼ˆå‰3è¡Œï¼‰
                print(f"  - å†…å®¹ç¤ºä¾‹ï¼ˆå‰3è¡Œï¼‰ï¼š")
                for row_idx, row in enumerate(table[1:4], 1):  # è·³è¿‡è¡¨å¤´
                    print(f"    è¡Œ{row_idx}: {' | '.join(str(cell)[:30] for cell in row[:3])}")  # åªæ˜¾ç¤ºå‰3åˆ—ï¼Œæ¯åˆ—æœ€å¤š30å­—ç¬¦
    
    # ä¼°ç®—åº”æå–çš„è¦æ±‚æ•°é‡
    print(f"\n{'='*100}")
    print(f"ğŸ“Š æå–æ•°é‡ä¼°ç®—")
    print(f"{'='*100}\n")
    
    # åŸºäºå…³é”®è¯å’Œè¡¨æ ¼ä¼°ç®—
    estimated_veto = keywords_stats['åºŸæ ‡'] + keywords_stats['å¦å†³'] + keywords_stats['å–æ¶ˆèµ„æ ¼']
    estimated_veto = max(20, min(estimated_veto * 2, 50))  # ä¼°ç®—åºŸæ ‡é¡¹æ•°é‡
    
    estimated_scoring = max(30, min(total_table_rows * 0.3, 80))  # ä¼°ç®—è¯„åˆ†é¡¹æ•°é‡ï¼ˆå‡è®¾30%çš„è¡¨æ ¼è¡Œæ˜¯è¯„åˆ†é¡¹ï¼‰
    
    estimated_tech = keywords_stats['â–²'] + keywords_stats['â˜…'] + max(20, min(total_table_rows * 0.2, 60))  # ä¼°ç®—æŠ€æœ¯è¦æ±‚
    
    estimated_total = estimated_veto + estimated_scoring + estimated_tech + 40  # åŠ ä¸Šå…¶ä»–è¦æ±‚
    
    print(f"åŸºäºæ–‡æ¡£å†…å®¹ä¼°ç®—ï¼š")
    print(f"  - åºŸæ ‡é¡¹ï¼šçº¦ {int(estimated_veto)} æ¡")
    print(f"  - è¯„åˆ†é¡¹ï¼šçº¦ {int(estimated_scoring)} æ¡ï¼ˆå«ç»†åˆ†é¡¹ï¼‰")
    print(f"  - æŠ€æœ¯è¦æ±‚ï¼šçº¦ {int(estimated_tech)} æ¡")
    print(f"  - å…¶ä»–è¦æ±‚ï¼šçº¦ 40 æ¡")
    print(f"  - **é¢„ä¼°æ€»è®¡ï¼šçº¦ {int(estimated_total)} æ¡**")
    
    print(f"\nè¯´æ˜ï¼š")
    print(f"  - å¦‚æœå®é™…æå–æ•°é‡è¿œä½äºé¢„ä¼°ï¼Œè¯´æ˜æœ‰å¤§é‡é—æ¼")
    print(f"  - ç‰¹åˆ«æ³¨æ„è¡¨æ ¼å†…å®¹ï¼Œ{total_table_rows}è¡Œè¡¨æ ¼æ•°æ®åº”é€è¡Œæå–")
    print(f"  - æ³¨æ„â–²/â˜…æ ‡è®°çš„æ¡æ¬¾ï¼ˆæ–‡æ¡£ä¸­å…±{keywords_stats['â–²'] + keywords_stats['â˜…']}å¤„ï¼‰")
    
    # æå–éƒ¨åˆ†å…³é”®å†…å®¹ç¤ºä¾‹
    print(f"\n{'='*100}")
    print(f"ğŸ“ å…³é”®å†…å®¹ç¤ºä¾‹")
    print(f"{'='*100}\n")
    
    # æŸ¥æ‰¾åŒ…å«"åºŸæ ‡"æˆ–"å¦å†³"çš„æ®µè½
    veto_paragraphs = []
    for i, para in enumerate(paragraphs):
        if 'åºŸæ ‡' in para or 'å¦å†³' in para:
            veto_paragraphs.append((i, para))
    
    if veto_paragraphs:
        print(f"åŒ…å«'åºŸæ ‡'/'å¦å†³'çš„æ®µè½ï¼ˆå‰5ä¸ªï¼‰ï¼š")
        for idx, (para_idx, para) in enumerate(veto_paragraphs[:5], 1):
            print(f"\n  {idx}. [æ®µè½ {para_idx}]")
            print(f"     {para[:200]}..." if len(para) > 200 else f"     {para}")
    
    # æŸ¥æ‰¾åŒ…å«"è¯„åˆ†"çš„æ®µè½
    scoring_paragraphs = []
    for i, para in enumerate(paragraphs):
        if 'è¯„åˆ†' in para and len(para) > 20:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„æ®µè½
            scoring_paragraphs.append((i, para))
    
    if scoring_paragraphs:
        print(f"\n\nåŒ…å«'è¯„åˆ†'çš„æ®µè½ï¼ˆå‰5ä¸ªï¼‰ï¼š")
        for idx, (para_idx, para) in enumerate(scoring_paragraphs[:5], 1):
            print(f"\n  {idx}. [æ®µè½ {para_idx}]")
            print(f"     {para[:200]}..." if len(para) > 200 else f"     {para}")
    
    return {
        'paragraphs_count': len(paragraphs),
        'tables_count': len(tables),
        'table_rows_count': total_table_rows,
        'keywords_stats': keywords_stats,
        'estimated_total': int(estimated_total),
        'estimated_veto': int(estimated_veto),
        'estimated_scoring': int(estimated_scoring),
    }


if __name__ == "__main__":
    docx_path = "/aidata/x-llmapp1/data/tender_assets/tp_f379d279606a4ff89a6aa2cfabc0a6c5/tender_a6320484adca479caaa83b71ff1de9de_ã€GC1818TPã€‘ å‚¨èƒ½æŠ€æœ¯å…¬å¸é‡‘å›ã€åˆ˜åº„å‚¨æ°”åº“æ§åˆ¶ç³»ç»Ÿå›½äº§åŒ–å‡çº§æ”¹é€ å·¥ç¨‹æ–½å·¥é¡¹ç›®20260104.docx"
    
    try:
        result = analyze_document(docx_path)
        
        print(f"\n{'='*100}")
        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"{'='*100}\n")
        
        print(f"ã€é‡è¦æç¤ºã€‘")
        print(f"  å¦‚æœV3.4ç‰ˆæœ¬æå–ç»“æœå°‘äº {result['estimated_total']} æ¡ï¼Œ")
        print(f"  è¯´æ˜è¿˜æœ‰å¾ˆå¤§çš„ä¼˜åŒ–ç©ºé—´ï¼")
        print(f"  ç‰¹åˆ«è¦æ£€æŸ¥ï¼š")
        print(f"    1. è¡¨æ ¼æ˜¯å¦é€è¡Œæå–ï¼ˆæ–‡æ¡£ä¸­æœ‰{result['table_rows_count']}è¡Œè¡¨æ ¼ï¼‰")
        print(f"    2. åºŸæ ‡é¡¹æ˜¯å¦å…¨éƒ¨æå–ï¼ˆæ–‡æ¡£ä¸­'åºŸæ ‡'/'å¦å†³'å…±{result['keywords_stats']['åºŸæ ‡'] + result['keywords_stats']['å¦å†³']}æ¬¡ï¼‰")
        print(f"    3. è¯„åˆ†é¡¹æ˜¯å¦ç»†åŒ–ï¼ˆä¼°ç®—çº¦{result['estimated_scoring']}æ¡ï¼‰")
        print(f"    4. â–²/â˜…æ ‡è®°çš„æ¡æ¬¾æ˜¯å¦å…¨éƒ¨æå–ï¼ˆå…±{result['keywords_stats']['â–²'] + result['keywords_stats']['â˜…']}å¤„ï¼‰")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

