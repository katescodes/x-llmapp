#!/usr/bin/env python3
"""
kb_documents æ•°æ®è¿ç§»è„šæœ¬

åŠŸèƒ½ï¼š
1. å°† kb_documents çš„æ•°æ®æ˜ å°„è¡¥å……åˆ° documents è¡¨
2. éªŒè¯è¿ç§»ç»“æœ
3. å¯é€‰ï¼šåˆ é™¤æ—§è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
python backend/scripts/migrate_kb_documents.py --mode=analyze  # åˆ†ææ¨¡å¼
python backend/scripts/migrate_kb_documents.py --mode=migrate  # æ‰§è¡Œè¿ç§»
python backend/scripts/migrate_kb_documents.py --mode=verify   # éªŒè¯è¿ç§»
python backend/scripts/migrate_kb_documents.py --mode=cleanup  # æ¸…ç†æ—§è¡¨ï¼ˆè°¨æ…ï¼ï¼‰
"""

import argparse
import json
import sys
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/aidata/x-llmapp1/backend')

from app.services.db.postgres import _get_pool


class KBDocumentsMigration:
    """kb_documents è¿ç§»å·¥å…·"""
    
    def __init__(self):
        self.pool = _get_pool()
        self.stats = {
            "kb_documents_count": 0,
            "documents_to_update": 0,
            "documents_updated": 0,
            "errors": [],
        }
    
    def analyze(self) -> Dict[str, Any]:
        """åˆ†æç°æœ‰æ•°æ®"""
        print("\n" + "=" * 60)
        print("æ­¥éª¤ 1: æ•°æ®åˆ†æ")
        print("=" * 60)
        
        with self.pool.connection() as conn:
            with conn.cursor() as cur:
                # ç»Ÿè®¡ kb_documents
                cur.execute("SELECT COUNT(*) FROM kb_documents")
                self.stats["kb_documents_count"] = cur.fetchone()[0]
                
                # åˆ†æ kb_documents çš„ doc_version_id
                cur.execute("""
                    SELECT 
                        kd.id as kb_doc_id,
                        kd.kb_id,
                        kd.filename,
                        kd.meta_json->>'doc_version_id' as doc_version_id,
                        dv.id as actual_version_id,
                        dv.document_id
                    FROM kb_documents kd
                    LEFT JOIN document_versions dv ON (kd.meta_json->>'doc_version_id')::text = dv.id
                    ORDER BY kd.created_at DESC
                """)
                rows = cur.fetchall()
                
                print(f"\nâœ… kb_documents è®°å½•æ•°ï¼š{self.stats['kb_documents_count']}")
                print(f"\nè¯¦ç»†ä¿¡æ¯ï¼š")
                
                valid_count = 0
                invalid_count = 0
                
                for row in rows:
                    kb_doc_id, kb_id, filename, doc_version_id, actual_version_id, document_id = row
                    
                    if document_id:
                        valid_count += 1
                        print(f"  âœ… {filename[:40]:40s} | kb_id: {kb_id[:8]} | doc_version: {doc_version_id[:8]} â†’ document: {document_id[:8]}")
                    else:
                        invalid_count += 1
                        print(f"  âŒ {filename[:40]:40s} | kb_id: {kb_id[:8]} | doc_version: {doc_version_id} (NOT FOUND)")
                
                self.stats["documents_to_update"] = valid_count
                
                print(f"\nç»Ÿè®¡ï¼š")
                print(f"  æœ‰æ•ˆè®°å½•ï¼ˆå¯è¿ç§»ï¼‰ï¼š{valid_count}")
                print(f"  æ— æ•ˆè®°å½•ï¼ˆéœ€ä¿®å¤ï¼‰ï¼š{invalid_count}")
                
                # æ£€æŸ¥ documents è¡¨å½“å‰çŠ¶æ€
                cur.execute("""
                    SELECT 
                        COUNT(*) as total,
                        COUNT(meta_json->>'kb_id') as with_kb_id
                    FROM documents
                    WHERE namespace = 'tender'
                """)
                doc_row = cur.fetchone()
                
                print(f"\nğŸ“Š documents è¡¨çŠ¶æ€ï¼š")
                print(f"  æ€»æ–‡æ¡£æ•°ï¼š{doc_row[0]}")
                print(f"  å·²æœ‰ kb_idï¼š{doc_row[1]}")
                print(f"  éœ€è¦è¡¥å……ï¼š{doc_row[0] - doc_row[1]}")
        
        return self.stats
    
    def migrate(self) -> Dict[str, Any]:
        """æ‰§è¡Œè¿ç§»"""
        print("\n" + "=" * 60)
        print("æ­¥éª¤ 2: æ‰§è¡Œæ•°æ®è¿ç§»")
        print("=" * 60)
        
        with self.pool.connection() as conn:
            with conn.cursor() as cur:
                # è·å–æ‰€æœ‰éœ€è¦è¿ç§»çš„è®°å½•
                cur.execute("""
                    SELECT 
                        kd.id as kb_doc_id,
                        kd.kb_id,
                        kd.kb_category,
                        kd.meta_json,
                        dv.document_id
                    FROM kb_documents kd
                    JOIN document_versions dv ON (kd.meta_json->>'doc_version_id')::text = dv.id
                    WHERE dv.document_id IS NOT NULL
                """)
                rows = cur.fetchall()
                
                print(f"\nå¼€å§‹è¿ç§» {len(rows)} æ¡è®°å½•...")
                
                updated_count = 0
                for row in rows:
                    kb_doc_id, kb_id, kb_category, meta_json, document_id = row
                    
                    try:
                        # è§£æ meta_json
                        if isinstance(meta_json, str):
                            meta_json = json.loads(meta_json)
                        
                        # è¡¥å…… kb_id å’Œ kb_category åˆ° documents.meta_json
                        cur.execute("""
                            UPDATE documents
                            SET meta_json = meta_json || jsonb_build_object(
                                'kb_id', %s::text,
                                'kb_category', %s::text,
                                'kb_doc_id', %s::text,
                                'migrated_from_kb_documents', true,
                                'migration_time', %s::text
                            )
                            WHERE id = %s
                        """, (kb_id, kb_category or 'tender_doc', kb_doc_id, datetime.now().isoformat(), document_id))
                        
                        if cur.rowcount > 0:
                            updated_count += 1
                            print(f"  âœ… æ›´æ–° document {document_id[:12]} (kb_id: {kb_id[:8]})")
                        else:
                            self.stats["errors"].append(f"Failed to update document {document_id}")
                            print(f"  âŒ æ›´æ–°å¤±è´¥ï¼šdocument {document_id}")
                    
                    except Exception as e:
                        self.stats["errors"].append(f"Error migrating {kb_doc_id}: {str(e)}")
                        print(f"  âŒ é”™è¯¯ï¼š{e}")
                
                conn.commit()
                
                self.stats["documents_updated"] = updated_count
                
                print(f"\nâœ… è¿ç§»å®Œæˆï¼")
                print(f"  æˆåŠŸæ›´æ–°ï¼š{updated_count}/{len(rows)}")
                print(f"  å¤±è´¥ï¼š{len(rows) - updated_count}")
        
        return self.stats
    
    def verify(self) -> Dict[str, Any]:
        """éªŒè¯è¿ç§»ç»“æœ"""
        print("\n" + "=" * 60)
        print("æ­¥éª¤ 3: éªŒè¯è¿ç§»ç»“æœ")
        print("=" * 60)
        
        with self.pool.connection() as conn:
            with conn.cursor() as cur:
                # æ£€æŸ¥è¿ç§»ç»“æœ
                cur.execute("""
                    SELECT 
                        d.id,
                        d.namespace,
                        d.doc_type,
                        d.meta_json->>'kb_id' as kb_id,
                        d.meta_json->>'kb_category' as kb_category,
                        d.meta_json->>'migrated_from_kb_documents' as migrated
                    FROM documents d
                    WHERE d.meta_json->>'migrated_from_kb_documents' = 'true'
                    ORDER BY d.created_at DESC
                """)
                rows = cur.fetchall()
                
                print(f"\nâœ… å·²è¿ç§»çš„æ–‡æ¡£ï¼š{len(rows)}")
                
                for row in rows:
                    doc_id, namespace, doc_type, kb_id, kb_category, migrated = row
                    print(f"  ğŸ“„ {doc_id[:12]} | ns: {namespace:10s} | type: {doc_type:10s} | kb: {kb_id[:8] if kb_id else 'N/A':8s} | cat: {kb_category or 'N/A'}")
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªè¿ç§»çš„
                cur.execute("""
                    SELECT 
                        kd.id,
                        kd.filename,
                        dv.document_id
                    FROM kb_documents kd
                    JOIN document_versions dv ON (kd.meta_json->>'doc_version_id')::text = dv.id
                    JOIN documents d ON dv.document_id = d.id
                    WHERE d.meta_json->>'kb_id' IS NULL
                       OR d.meta_json->>'migrated_from_kb_documents' IS NULL
                """)
                unmigrated = cur.fetchall()
                
                if unmigrated:
                    print(f"\nâš ï¸  è­¦å‘Šï¼šè¿˜æœ‰ {len(unmigrated)} æ¡è®°å½•æœªè¿ç§»ï¼š")
                    for row in unmigrated[:5]:  # åªæ˜¾ç¤ºå‰5æ¡
                        print(f"  âŒ {row[1][:40]} (doc_id: {row[2][:12]})")
                    if len(unmigrated) > 5:
                        print(f"  ... è¿˜æœ‰ {len(unmigrated) - 5} æ¡")
                else:
                    print(f"\nâœ… æ‰€æœ‰è®°å½•å·²æˆåŠŸè¿ç§»ï¼")
                
                # éªŒè¯æ£€ç´¢åŠŸèƒ½
                print(f"\néªŒè¯æ£€ç´¢åŠŸèƒ½...")
                
                # æµ‹è¯•ï¼šé€šè¿‡ kb_id æŸ¥è¯¢ documents
                cur.execute("""
                    SELECT 
                        d.id,
                        d.meta_json->>'kb_id' as kb_id,
                        dv.id as version_id
                    FROM documents d
                    JOIN document_versions dv ON d.id = dv.document_id
                    WHERE d.meta_json->>'kb_id' IS NOT NULL
                    LIMIT 3
                """)
                test_rows = cur.fetchall()
                
                if test_rows:
                    print(f"  âœ… æ£€ç´¢æµ‹è¯•é€šè¿‡ï¼ˆæ‰¾åˆ° {len(test_rows)} æ¡è®°å½•ï¼‰")
                    for row in test_rows:
                        print(f"     doc: {row[0][:12]} | kb: {row[1][:8]} | version: {row[2][:12]}")
                else:
                    print(f"  âŒ æ£€ç´¢æµ‹è¯•å¤±è´¥ï¼šæœªæ‰¾åˆ°è®°å½•")
        
        return {"status": "verified", "migrated_count": len(rows), "unmigrated_count": len(unmigrated)}
    
    def cleanup(self, confirm: bool = False) -> Dict[str, Any]:
        """æ¸…ç†æ—§è¡¨ï¼ˆè°¨æ…æ“ä½œï¼ï¼‰"""
        print("\n" + "=" * 60)
        print("æ­¥éª¤ 4: æ¸…ç†æ—§è¡¨ï¼ˆDANGER ZONE âš ï¸ï¼‰")
        print("=" * 60)
        
        if not confirm:
            print("\nâš ï¸  è­¦å‘Šï¼šæ­¤æ“ä½œå°†åˆ é™¤ kb_documents å’Œ kb_chunks è¡¨ï¼")
            print("è¯·å…ˆè¿è¡Œ --mode=verify ç¡®è®¤è¿ç§»æˆåŠŸ")
            print("å¦‚æœç¡®å®šè¦åˆ é™¤ï¼Œè¯·ä½¿ç”¨ --confirm å‚æ•°")
            return {"status": "cancelled"}
        
        print("\nâš ï¸  å¼€å§‹æ¸…ç†æ—§è¡¨...")
        
        with self.pool.connection() as conn:
            with conn.cursor() as cur:
                try:
                    # ç»Ÿè®¡æ•°æ®
                    cur.execute("SELECT COUNT(*) FROM kb_documents")
                    kb_docs_count = cur.fetchone()[0]
                    
                    cur.execute("SELECT COUNT(*) FROM kb_chunks")
                    kb_chunks_count = cur.fetchone()[0]
                    
                    print(f"\nå‡†å¤‡åˆ é™¤ï¼š")
                    print(f"  kb_documents: {kb_docs_count} æ¡")
                    print(f"  kb_chunks: {kb_chunks_count} æ¡")
                    
                    # åˆ é™¤è¡¨
                    cur.execute("DROP TABLE IF EXISTS kb_chunks CASCADE")
                    print(f"  âœ… å·²åˆ é™¤ kb_chunks è¡¨")
                    
                    cur.execute("DROP TABLE IF EXISTS kb_documents CASCADE")
                    print(f"  âœ… å·²åˆ é™¤ kb_documents è¡¨")
                    
                    conn.commit()
                    
                    print(f"\nâœ… æ¸…ç†å®Œæˆï¼")
                    
                    return {"status": "success", "deleted_tables": ["kb_documents", "kb_chunks"]}
                
                except Exception as e:
                    conn.rollback()
                    print(f"\nâŒ æ¸…ç†å¤±è´¥ï¼š{e}")
                    return {"status": "error", "message": str(e)}


def main():
    parser = argparse.ArgumentParser(description='kb_documents æ•°æ®è¿ç§»å·¥å…·')
    parser.add_argument('--mode', choices=['analyze', 'migrate', 'verify', 'cleanup', 'all'], 
                       default='analyze', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--confirm', action='store_true', help='ç¡®è®¤æ¸…ç†æ“ä½œ')
    
    args = parser.parse_args()
    
    migration = KBDocumentsMigration()
    
    print(f"\n{'='*60}")
    print(f"kb_documents æ•°æ®è¿ç§»å·¥å…·")
    print(f"æ¨¡å¼ï¼š{args.mode}")
    print(f"æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}")
    
    try:
        if args.mode == 'analyze' or args.mode == 'all':
            migration.analyze()
        
        if args.mode == 'migrate' or args.mode == 'all':
            migration.migrate()
        
        if args.mode == 'verify' or args.mode == 'all':
            migration.verify()
        
        if args.mode == 'cleanup':
            migration.cleanup(confirm=args.confirm)
        
        print(f"\n{'='*60}")
        print(f"æ‰§è¡Œå®Œæˆï¼")
        print(f"{'='*60}\n")
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

