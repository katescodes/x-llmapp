"""
ç›®å½•å¢å¼ºæœåŠ¡ (v1) - ä»æ‹›æ ‡ä¹¦"æ ¼å¼ç« èŠ‚"ç²¾ç¡®æå–ç›®å½•

âœ… é‡è¦å˜æ›´ï¼ˆ2026-01ï¼‰ï¼š
- ä¸å†ä½¿ç”¨å›ºå®šçš„"å•†åŠ¡æ ‡/æŠ€æœ¯æ ‡/ä»·æ ¼æ ‡"åˆ’åˆ†
- å®Œå…¨ä¾èµ–æ‹›æ ‡ä¹¦ä¸­"æŠ•æ ‡æ–‡ä»¶æ ¼å¼/å“åº”æ–‡ä»¶æ ¼å¼"ç« èŠ‚çš„å®é™…è¦æ±‚
- å¦‚æœæ‹›æ ‡ä¹¦è¦æ±‚åˆ’åˆ†å·å†Œï¼Œåˆ™æŒ‰æ‹›æ ‡ä¹¦çš„åˆ’åˆ†æ–¹å¼å’Œåç§°
- å¦‚æœæ‹›æ ‡ä¹¦æ²¡æœ‰è¦æ±‚åˆ’åˆ†ï¼Œåˆ™ä¸è¿›è¡Œåˆ’åˆ†

ç­–ç•¥ï¼š
1. å®šä½"æŠ•æ ‡æ–‡ä»¶æ ¼å¼/å“åº”æ–‡ä»¶æ ¼å¼/ç£‹å•†å“åº”æ–‡ä»¶æ ¼å¼"ç« èŠ‚
2. ç”¨è§„åˆ™æ–¹æ³•æå–ç›®å½•ç»“æ„ï¼ˆç¼–å·+æ ‡é¢˜+å±‚çº§ï¼‰
3. ä¿æŒåŸæ ·ï¼Œä¸éœ€è¦LLMç†è§£å’Œå‘æŒ¥
4. æ”¯æŒçš„ç¼–å·æ ¼å¼ï¼šç¬¬Xå†Œã€ä¸€/äºŒ/ä¸‰ã€(ä¸€)(äºŒ)ã€1./2.ã€1.1/1.2ç­‰
"""
import logging
import re
import uuid
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


def augment_directory_from_tender_info_v3(
    project_id: str,
    pool: Any,
    tender_info: Dict[str, Any] = None,
) -> Dict[str, Any]:
    """
    ä»æ‹›æ ‡ä¹¦"æ ¼å¼ç« èŠ‚"ç²¾ç¡®æå–ç›®å½•ç»“æ„
    
    å®Œæ•´æµç¨‹ï¼š
    1. åŠ è½½æ‹›æ ‡ä¹¦æ–‡æ¡£
    2. å®šä½"æŠ•æ ‡æ–‡ä»¶æ ¼å¼"ç« èŠ‚ï¼ˆç»„åˆåŒ¹é…ï¼‰
    3. æå–ç« èŠ‚å†…çš„ç›®å½•ç»“æ„ï¼ˆè§„åˆ™ä¼˜å…ˆï¼‰
    4. å…¥åº“ï¼ˆä¿ç•™ç¼–å·ã€æ ‡é¢˜ã€å±‚çº§ï¼‰
    
    Args:
        project_id: é¡¹ç›®ID
        pool: æ•°æ®åº“è¿æ¥æ± 
        tender_info: tender_info_v3 æ•°æ®ï¼ˆå…¼å®¹æ—§è°ƒç”¨ï¼Œå¯é€‰ï¼‰
    
    Returns:
        å¢å¼ºç»Ÿè®¡ä¿¡æ¯
    """
    logger.info(f"[ç›®å½•å¢å¼º] å¼€å§‹ä»æ ¼å¼ç« èŠ‚æå–ç›®å½•: project_id={project_id}")
    
    # ğŸ” DEBUG: å†™å…¥è°ƒè¯•æ—¥å¿—
    import sys
    debug_log = open("/tmp/augment_debug.log", "a")
    debug_log.write(f"\n=== augment_directory_from_tender_info_v3 START ===\n")
    debug_log.write(f"project_id: {project_id}\n")
    debug_log.flush()
    
    print(f"[ç›®å½•å¢å¼º-DEBUG] å¼€å§‹æå–: project_id={project_id}", file=sys.stderr)
    
    # 1. è¯»å–ç°æœ‰ç›®å½•èŠ‚ç‚¹
    existing_nodes = _get_existing_directory_nodes(pool, project_id)
    existing_titles = {node["title"] for node in existing_nodes}
    
    logger.info(f"[ç›®å½•å¢å¼º] ç°æœ‰ç›®å½•èŠ‚ç‚¹æ•°: {len(existing_nodes)}")
    debug_log.write(f"ç°æœ‰èŠ‚ç‚¹æ•°: {len(existing_nodes)}, æ ‡é¢˜: {list(existing_titles)[:5]}\n")
    debug_log.flush()
    print(f"[ç›®å½•å¢å¼º-DEBUG] ç°æœ‰èŠ‚ç‚¹æ•°: {len(existing_nodes)}, æ ‡é¢˜: {list(existing_titles)[:5]}", file=sys.stderr)
    
    # 2. åŠ è½½æ‹›æ ‡ä¹¦æ–‡æ¡£
    try:
        doc_path = _get_tender_document_path(pool, project_id)
        if not doc_path:
            logger.warning(f"[ç›®å½•å¢å¼º] æœªæ‰¾åˆ°æ‹›æ ‡ä¹¦æ–‡æ¡£ï¼Œè·³è¿‡å¢å¼º")
            return _empty_result(len(existing_nodes))
    except Exception as e:
        import traceback
        logger.warning(f"[ç›®å½•å¢å¼º] è·å–æ‹›æ ‡ä¹¦æ–‡æ¡£å¤±è´¥: {e}")
        logger.warning(f"[ç›®å½•å¢å¼º] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return _empty_result(len(existing_nodes))
    
    # 3. æå–æ–‡æ¡£blocks
    try:
        from app.works.tender.snippet.doc_blocks import extract_blocks
        blocks = extract_blocks(doc_path)
        logger.info(f"[ç›®å½•å¢å¼º] æ–‡æ¡£blocksæå–å®Œæˆ: {len(blocks)} ä¸ª")
    except Exception as e:
        logger.error(f"[ç›®å½•å¢å¼º] æ–‡æ¡£blocksæå–å¤±è´¥: {e}")
        return _empty_result(len(existing_nodes))
    
    if not blocks:
        logger.warning(f"[ç›®å½•å¢å¼º] æ–‡æ¡£ä¸ºç©ºï¼Œè·³è¿‡å¢å¼º")
        return _empty_result(len(existing_nodes))
    
    # 4. å®šä½"æ ¼å¼ç« èŠ‚"
    try:
        from app.works.tender.snippet.snippet_locator import locate_format_chapter
        format_blocks = locate_format_chapter(blocks)
        logger.info(f"[ç›®å½•å¢å¼º] æ ¼å¼ç« èŠ‚å®šä½å®Œæˆ: {len(format_blocks)} ä¸ªblocks")
        debug_log.write(f"æ ¼å¼ç« èŠ‚blocksæ•°: {len(format_blocks)}\n")
        debug_log.flush()
        
        print(f"[ç›®å½•å¢å¼º-DEBUG] æ ¼å¼ç« èŠ‚blocksæ•°: {len(format_blocks)}", file=sys.stderr)
        if format_blocks:
            debug_log.write(f"å‰5ä¸ªformat_blocks:\n")
            for i, b in enumerate(format_blocks[:5]):
                if b['type'] == 'p':
                    text = b.get('text', '')[:80]
                    debug_log.write(f"  {i}: {text}\n")
            debug_log.flush()
        
        # ğŸ”¥ 4.1 é¢„å¤„ç†ï¼šå°†ç›®å½•è¡¨æ ¼è½¬æ¢ä¸ºæ–‡æœ¬å—
        format_blocks = _preprocess_tables_to_text(format_blocks)
        logger.info(f"[ç›®å½•å¢å¼º] è¡¨æ ¼é¢„å¤„ç†å®Œæˆï¼Œå½“å‰blocksæ•°: {len(format_blocks)}")
        debug_log.write(f"è¡¨æ ¼é¢„å¤„ç†åblocksæ•°: {len(format_blocks)}\n")
        debug_log.flush()
        
    except Exception as e:
        logger.error(f"[ç›®å½•å¢å¼º] æ ¼å¼ç« èŠ‚å®šä½å¤±è´¥: {e}")
        debug_log.write(f"æ ¼å¼ç« èŠ‚å®šä½å¤±è´¥: {e}\n")
        debug_log.close()
        return _empty_result(len(existing_nodes))
    
    if not format_blocks:
        logger.warning(f"[ç›®å½•å¢å¼º] æœªå®šä½åˆ°æ ¼å¼ç« èŠ‚ï¼Œè·³è¿‡å¢å¼º")
        return _empty_result(len(existing_nodes))
    
    # 5. æå–ç›®å½•ç»“æ„ï¼ˆè§„åˆ™æ–¹æ³•ï¼‰
    try:
        directory_nodes = _extract_directory_from_blocks(format_blocks, existing_titles)
        logger.info(f"[ç›®å½•å¢å¼º] æå–åˆ° {len(directory_nodes)} ä¸ªç›®å½•èŠ‚ç‚¹")
        debug_log.write(f"æå–åˆ° {len(directory_nodes)} ä¸ªç›®å½•èŠ‚ç‚¹\n")
        debug_log.flush()
        
        # ğŸ” DEBUG: è¾“å‡ºæå–åˆ°çš„èŠ‚ç‚¹è¯¦æƒ…
        if directory_nodes:
            logger.info(f"[ç›®å½•å¢å¼º-DEBUG] æå–èŠ‚ç‚¹è¯¦æƒ…:")
            debug_log.write(f"æå–èŠ‚ç‚¹è¯¦æƒ…ï¼ˆå‰10ä¸ªï¼‰:\n")
            for i, node in enumerate(directory_nodes[:10]):
                info = f"  èŠ‚ç‚¹{i+1}: block_index={node.get('block_index')}, {node.get('numbering')} {node['title']}"
                logger.info(info)
                debug_log.write(info + "\n")
            debug_log.flush()
        
        # å¦‚æœè§„åˆ™æ–¹æ³•æå–ä¸åˆ°èŠ‚ç‚¹ï¼Œå°è¯•ç”¨LLMæå–
        if len(directory_nodes) == 0:
            logger.info(f"[ç›®å½•å¢å¼º] è§„åˆ™æå–æ— ç»“æœï¼Œå°è¯•LLMæå–...")
            debug_log.write(f"è§„åˆ™æå–æ— ç»“æœï¼Œå°è¯•LLMæå–...\n")
            debug_log.flush()
            directory_nodes = _extract_directory_with_llm(format_blocks, existing_titles, project_id, pool)
            logger.info(f"[ç›®å½•å¢å¼º] LLMæå–åˆ° {len(directory_nodes)} ä¸ªç›®å½•èŠ‚ç‚¹")
            debug_log.write(f"LLMæå–åˆ° {len(directory_nodes)} ä¸ªç›®å½•èŠ‚ç‚¹\n")
            debug_log.flush()
            
    except Exception as e:
        logger.error(f"[ç›®å½•å¢å¼º] ç›®å½•æå–å¤±è´¥: {e}")
        return _empty_result(len(existing_nodes))
    
    # 6. å…¥åº“
    added_count = 0
    if directory_nodes:
        logger.info(f"[ç›®å½•å¢å¼º] å‡†å¤‡æ’å…¥ {len(directory_nodes)} ä¸ªèŠ‚ç‚¹ (æŒ‰æå–é¡ºåº):")
        debug_log.write(f"å‡†å¤‡æ’å…¥ {len(directory_nodes)} ä¸ªèŠ‚ç‚¹:\n")
        for i, node in enumerate(directory_nodes):
            info = f"  èŠ‚ç‚¹{i+1}: block_idx={node.get('block_index')} {node.get('numbering', '')} {node['title']} (level={node['level']}, source={node.get('source', 'N/A')})"
            logger.info(info)
            debug_log.write(info + "\n")
        debug_log.flush()
        
        try:
            added_count = _insert_directory_nodes(pool, project_id, directory_nodes)
            logger.info(f"[ç›®å½•å¢å¼º] æˆåŠŸæ’å…¥ {added_count} ä¸ªç›®å½•èŠ‚ç‚¹")
            debug_log.write(f"æˆåŠŸæ’å…¥ {added_count} ä¸ªç›®å½•èŠ‚ç‚¹\n")
            debug_log.close()
        except Exception as e:
            import traceback
            logger.error(f"[ç›®å½•å¢å¼º] ç›®å½•èŠ‚ç‚¹å…¥åº“å¤±è´¥: {e}")
            logger.error(f"[ç›®å½•å¢å¼º] é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
            debug_log.write(f"å…¥åº“å¤±è´¥: {e}\n")
            debug_log.write(f"é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}\n")
            debug_log.close()
            return {
                "existing_nodes_count": len(existing_nodes),
                "identified_required_count": len(directory_nodes),
                "added_count": 0,
                "enhanced_titles": [],
                "error": str(e)
            }
    else:
        debug_log.write(f"æ²¡æœ‰èŠ‚ç‚¹éœ€è¦æ’å…¥\n")
        debug_log.close()
    
    return {
        "existing_nodes_count": len(existing_nodes),
        "identified_required_count": len(directory_nodes),
        "added_count": added_count,
        "enhanced_titles": [n["title"] for n in directory_nodes[:20]]  # æœ€å¤šæ˜¾ç¤º20ä¸ª
    }


def _empty_result(existing_count: int) -> Dict[str, Any]:
    """è¿”å›ç©ºç»“æœ"""
    return {
        "existing_nodes_count": existing_count,
        "identified_required_count": 0,
        "added_count": 0,
        "enhanced_titles": []
    }


def _get_tender_document_path(pool: Any, project_id: str) -> Optional[str]:
    """
    è·å–æ‹›æ ‡ä¹¦æ–‡æ¡£è·¯å¾„
    
    ä»tender_project_assetsè¡¨ä¸­æŸ¥æ‰¾æ‹›æ ‡ä¹¦æ–‡æ¡£
    """
    from psycopg.rows import dict_row
    
    with pool.connection() as conn:
        conn.row_factory = dict_row
        with conn.cursor() as cur:
            # ä»assetsè¡¨æŸ¥æ‰¾æ‹›æ ‡ä¹¦ï¼ˆä¼˜å…ˆdocxï¼Œå› ä¸ºæ›´å®¹æ˜“è§£æï¼‰
            cur.execute("""
                SELECT storage_path, filename
                FROM tender_project_assets
                WHERE project_id = %s 
                AND kind = 'tender'
                AND storage_path IS NOT NULL
                ORDER BY 
                    CASE 
                        WHEN filename LIKE %s THEN 1
                        WHEN filename LIKE %s THEN 2
                        WHEN filename LIKE %s THEN 3
                        ELSE 4
                    END,
                    created_at DESC
                LIMIT 1
            """, (project_id, '%.docx', '%.doc', '%.pdf'))
            row = cur.fetchone()
            
            if row and row['storage_path']:
                # storage_pathæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦åŠ ä¸Š/app/å‰ç¼€
                storage_path = row['storage_path']
                if not storage_path.startswith('/'):
                    storage_path = f"/app/{storage_path}"
                return storage_path
            
            logger.warning(f"[ç›®å½•å¢å¼º] é¡¹ç›®æ— æ‹›æ ‡ä¹¦æ–‡æ¡£: {project_id}")
            return None


def _preprocess_tables_to_text(blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    é¢„å¤„ç†ï¼šå°†ç›®å½•è¡¨æ ¼è½¬æ¢ä¸ºæ–‡æœ¬å—
    
    ç­–ç•¥ï¼šè¡¨æ ¼å·²ç»è¢«extract_blocksè§£æä¸ºç»“æ„åŒ–çš„rowsæ•°ç»„ï¼Œ
    æˆ‘ä»¬åªéœ€è¦åˆ¤æ–­å“ªäº›è¡¨æ ¼æ˜¯æŠ•æ ‡æ–‡ä»¶ç›®å½•ï¼Œç„¶åè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ã€‚
    åŒæ—¶ï¼Œåœ¨è¡¨æ ¼å‰æŸ¥æ‰¾L1æ ‡é¢˜ï¼ˆå¦‚"æŠ€æœ¯èµ„ä¿¡æ ‡"ã€"ï¼ˆ2ï¼‰å•†åŠ¡æ ‡"ï¼‰ã€‚
    
    Args:
        blocks: åŒ…å«è¡¨æ ¼å’Œæ–‡æœ¬çš„blocksåˆ—è¡¨
        
    Returns:
        å¤„ç†åçš„blocksåˆ—è¡¨ï¼ˆè¡¨æ ¼è½¬æ¢ä¸ºæ–‡æœ¬ï¼Œå¯èƒ½æ’å…¥L1æ ‡é¢˜ï¼‰
    """
    import sys
    processed_blocks = []
    table_converted_count = 0
    
    print(f"[è¡¨æ ¼é¢„å¤„ç†] å¼€å§‹å¤„ç† {len(blocks)} ä¸ªblocks", file=sys.stderr)
    
    for i, block in enumerate(blocks):
        if block['type'] == 'table':
            rows = block.get('rows', [])
            print(f"[è¡¨æ ¼é¢„å¤„ç†] å‘ç°è¡¨æ ¼ at block {i}, rowsæ•°: {len(rows)}", file=sys.stderr)
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯æŠ•æ ‡æ–‡ä»¶ç›®å½•è¡¨æ ¼
            if _is_directory_table(rows):
                print(f"[è¡¨æ ¼é¢„å¤„ç†] âœ“ æ˜¯ç›®å½•è¡¨æ ¼ï¼Œå¼€å§‹è½¬æ¢", file=sys.stderr)
                logger.info(f"[è¡¨æ ¼é¢„å¤„ç†] å‘ç°ç›®å½•è¡¨æ ¼ at block {i}, è½¬æ¢ä¸ºæ–‡æœ¬")
                
                # ğŸ”¥ æŸ¥æ‰¾è¡¨æ ¼å‰çš„L1æ ‡é¢˜
                l1_title_text = _find_l1_title_before_table(blocks, i)
                l1_title_pure = None  # æå–çº¯æ ‡é¢˜ï¼ˆå»é™¤ç¼–å·ï¼‰
                
                if l1_title_text:
                    print(f"[è¡¨æ ¼é¢„å¤„ç†] æ‰¾åˆ°L1æ ‡é¢˜: {l1_title_text}", file=sys.stderr)
                    # æå–çº¯æ ‡é¢˜ï¼šå»é™¤"ï¼ˆ1ï¼‰"ã€"ï¼ˆ2ï¼‰"ç­‰ç¼–å·
                    import re
                    match = re.match(r'^[ï¼ˆ\(]\d+[ï¼‰\)]\s*(.+)$', l1_title_text)
                    if match:
                        l1_title_pure = match.group(1).strip()
                    else:
                        l1_title_pure = l1_title_text.strip()
                    
                    processed_blocks.append({
                        "type": "p",
                        "text": l1_title_text,
                        "blockId": f"table{i}_l1_title",
                        "from_table": True,  # æ ‡è®°ä¸ºfrom_table
                        "suggested_level": 1  # ğŸ”¥ æ˜ç¡®æ ‡è®°ä¸ºL1
                    })
                
                # ğŸ”¥ è½¬æ¢ä¸ºæ–‡æœ¬å—ï¼Œå¹¶ä¼ å…¥L1çº¯æ ‡é¢˜ç”¨äºå»ºç«‹çˆ¶å­å…³ç³»
                text_blocks = _convert_table_rows_to_text_blocks(rows, i, l1_title_pure)
                print(f"[è¡¨æ ¼é¢„å¤„ç†] è½¬æ¢å¾—åˆ° {len(text_blocks)} ä¸ªæ–‡æœ¬å—", file=sys.stderr)
                processed_blocks.extend(text_blocks)
                table_converted_count += 1
            else:
                print(f"[è¡¨æ ¼é¢„å¤„ç†] âœ— ä¸æ˜¯ç›®å½•è¡¨æ ¼", file=sys.stderr)
                processed_blocks.append(block)
        else:
            processed_blocks.append(block)
    
    print(f"[è¡¨æ ¼é¢„å¤„ç†] å®Œæˆï¼Œå…±è½¬æ¢ {table_converted_count} ä¸ªè¡¨æ ¼", file=sys.stderr)
    if table_converted_count > 0:
        logger.info(f"[è¡¨æ ¼é¢„å¤„ç†] å…±è½¬æ¢ {table_converted_count} ä¸ªç›®å½•è¡¨æ ¼")
    
    return processed_blocks


def _find_l1_title_before_table(blocks: List[Dict[str, Any]], table_index: int) -> str:
    """
    åœ¨è¡¨æ ¼å‰æŸ¥æ‰¾L1æ ‡é¢˜
    
    å‘å‰æœç´¢æœ€è¿‘5ä¸ªblocksï¼ŒæŸ¥æ‰¾ï¼š
    - åŒ…å«å…³é”®è¯ï¼š"æŠ€æœ¯èµ„ä¿¡æ ‡"ã€"å•†åŠ¡æ ‡"ã€"ä»·æ ¼æ ‡"ç­‰
    - æ–‡æœ¬è¾ƒçŸ­ï¼ˆ<20å­—ç¬¦ï¼‰
    - å¦‚æœå·²æœ‰"ï¼ˆ1ï¼‰"ã€"ï¼ˆ2ï¼‰"ç­‰ç¼–å·ï¼Œç›´æ¥ä½¿ç”¨
    - å¦åˆ™ï¼Œæ ¹æ®è¡¨æ ¼é¡ºåºæ¨æ–­ç¼–å·
    
    Returns:
        L1æ ‡é¢˜æ–‡æœ¬ï¼Œå¦‚"ï¼ˆ1ï¼‰æŠ€æœ¯èµ„ä¿¡æ ‡"ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    keywords = ["æŠ€æœ¯èµ„ä¿¡æ ‡", "å•†åŠ¡æ ‡", "èµ„ä¿¡æ ‡", "ä»·æ ¼æ ‡", "æŠ¥ä»·æ ‡"]
    table_count = 0  # å½“å‰æ˜¯ç¬¬å‡ ä¸ªè¡¨æ ¼
    
    # ç»Ÿè®¡table_indexä¹‹å‰æœ‰å¤šå°‘ä¸ªç›®å½•è¡¨æ ¼
    for j in range(table_index):
        if blocks[j]['type'] == 'table':
            rows = blocks[j].get('rows', [])
            if _is_directory_table(rows):
                table_count += 1
    
    # å‘å‰æœç´¢
    for j in range(max(0, table_index - 5), table_index):
        if blocks[j]['type'] != 'p':
            continue
        text = blocks[j].get('text', '').strip()
        if not text or len(text) > 30:  # æ ‡é¢˜é€šå¸¸è¾ƒçŸ­
            continue
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
        for kw in keywords:
            if kw in text:
                # å¦‚æœå·²ç»æœ‰"ï¼ˆ1ï¼‰"ã€"ï¼ˆ2ï¼‰"ç­‰ç¼–å·ï¼Œç›´æ¥è¿”å›
                if re.match(r'^[ï¼ˆ\(]\d+[ï¼‰\)]', text):
                    return text
                # å¦‚æœæ˜¯çº¯æ ‡é¢˜ï¼ˆå¦‚"æŠ€æœ¯èµ„ä¿¡æ ‡"ã€"å•†åŠ¡æ ‡"ï¼‰ï¼Œæ·»åŠ ç¼–å·
                if text in keywords:
                    return f"ï¼ˆ{table_count + 1}ï¼‰{text}"
                # å…¶ä»–æƒ…å†µï¼ˆå¦‚"3ï¼‰å•†åŠ¡æ ‡"ï¼‰ï¼Œæå–å…³é”®è¯å¹¶æ·»åŠ ç¼–å·
                return f"ï¼ˆ{table_count + 1}ï¼‰{kw}"
    
    return None


def _is_directory_table(rows: List[List]) -> bool:
    """
    åˆ¤æ–­è¡¨æ ¼æ˜¯å¦æ˜¯æŠ•æ ‡æ–‡ä»¶ç›®å½•è¡¨æ ¼
    
    ç‰¹å¾ï¼š
    - è¡¨å¤´åŒæ—¶åŒ…å«"åºå·"å’Œ"å†…å®¹/åç§°"ç­‰å…³é”®è¯
    - æ’é™¤æŠ€æœ¯è§„æ ¼è¡¨ï¼ˆåŒ…å«"è§„æ ¼"ã€"å‚æ•°"ã€"å‹å·"ã€"å•ä½"ã€"æ•°é‡"ç­‰ï¼‰
    - è‡³å°‘æœ‰2è¡Œï¼ˆè¡¨å¤´+å†…å®¹ï¼‰
    """
    if not rows or len(rows) < 2:
        return False
    
    # æ£€æŸ¥è¡¨å¤´
    header = [str(cell).lower().strip() for cell in rows[0]]
    header_text = ''.join(header)
    
    # ç›®å½•è¡¨æ ¼çš„ç‰¹å¾å…³é”®è¯
    content_keywords = ['å†…å®¹', 'åç§°', 'æ–‡ä»¶', 'ææ–™', 'èµ„æ–™']
    number_keywords = ['åºå·', 'ç¼–å·', 'no']
    
    # æŠ€æœ¯è§„æ ¼è¡¨çš„æ’é™¤å…³é”®è¯
    spec_keywords = ['è§„æ ¼', 'å‚æ•°', 'å‹å·', 'å•ä½', 'æ•°é‡', 'ä»·æ ¼', 'é‡‘é¢', 'å•ä»·', 'æ€»ä»·', 'å“ç‰Œ', 'å‚å®¶', 'åˆ¶é€ å•†']
    
    has_content = any(kw in header_text for kw in content_keywords)
    has_number = any(kw in header_text for kw in number_keywords)
    has_spec = any(kw in header_text for kw in spec_keywords)
    
    # å¿…é¡»åŒæ—¶æœ‰"åºå·"å’Œ"å†…å®¹/åç§°"ï¼Œä¸”ä¸æ˜¯æŠ€æœ¯è§„æ ¼è¡¨
    return has_content and has_number and not has_spec


def _convert_table_rows_to_text_blocks(rows: List[List], table_index: int, l1_title: str = None) -> List[Dict[str, Any]]:
    """
    å°†è¡¨æ ¼è¡Œè½¬æ¢ä¸ºæ–‡æœ¬å—ï¼Œå¹¶å»ºç«‹å±‚çº§å…³ç³»
    
    ç­–ç•¥ï¼š
    - ä½¿ç”¨æ ˆç»´æŠ¤å½“å‰æ¯ä¸ªå±‚çº§çš„çˆ¶èŠ‚ç‚¹æ ‡é¢˜
    - ä¸ºæ¯ä¸ªèŠ‚ç‚¹è®¾ç½®parent_titleï¼Œåç»­å¯ç›´æ¥ä½¿ç”¨
    
    Args:
        rows: è¡¨æ ¼è¡Œæ•°æ®
        table_index: è¡¨æ ¼ç´¢å¼•
        l1_title: L1æ ‡é¢˜ï¼ˆå¦‚"æŠ€æœ¯èµ„ä¿¡æ ‡"ï¼‰ï¼Œç”¨äºè®¾ç½®L2èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹
        
    Returns:
        åŒ…å«parent_titleçš„æ–‡æœ¬å—åˆ—è¡¨
    """
    import sys
    if len(rows) < 2:
        return []
    
    # æ‰¾åˆ°"å†…å®¹"åˆ—çš„ç´¢å¼•
    header = [str(cell).strip() for cell in rows[0]]
    content_col_idx = _find_content_column_index(header)
    number_col_idx = 0  # åºå·é€šå¸¸åœ¨ç¬¬ä¸€åˆ—
    
    print(f"[è¡¨æ ¼è½¬æ¢] è¡¨å¤´: {header}, å†…å®¹åˆ—: {content_col_idx}", file=sys.stderr)
    
    # ğŸ”¥ ç»´æŠ¤å±‚çº§æ ˆï¼š{level: title}
    parent_stack = {1: l1_title} if l1_title else {}
    
    text_blocks = []
    for row_idx, row in enumerate(rows[1:], 1):  # è·³è¿‡è¡¨å¤´
        if not row or len(row) <= content_col_idx:
            continue
        
        # æå–ç¼–å·å’Œå†…å®¹
        numbering = str(row[number_col_idx]).strip() if len(row) > number_col_idx else ""
        content = str(row[content_col_idx]).strip() if len(row) > content_col_idx else ""
        
        # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚â–²è¡¨ç¤ºé‡è¦æ€§ï¼‰
        numbering = numbering.replace('â–²', '').strip()
        content = content.replace('â–²', '').strip()
        
        if not content:
            continue
        
        # ç»„åˆæˆæ–‡æœ¬
        if numbering:
            text = f"{numbering} {content}"
        else:
            text = content
        
        # ğŸ”¥ æ ¹æ®ç¼–å·æ ¼å¼æ¨æ–­å±‚çº§
        suggested_level = _infer_level_from_numbering(numbering)
        
        # ğŸ”¥ ç¡®å®šçˆ¶èŠ‚ç‚¹ï¼šæŸ¥æ‰¾æ ˆä¸­ä¸Šä¸€å±‚çš„æ ‡é¢˜
        parent_title = None
        if suggested_level > 1:
            # å‘ä¸ŠæŸ¥æ‰¾çˆ¶å±‚çº§
            for parent_level in range(suggested_level - 1, 0, -1):
                if parent_level in parent_stack:
                    parent_title = parent_stack[parent_level]
                    break
        
        # ğŸ”¥ æ›´æ–°æ ˆï¼šå½“å‰å±‚çº§çš„æ ‡é¢˜
        parent_stack[suggested_level] = content
        # æ¸…é™¤æ¯”å½“å‰å±‚çº§æ›´æ·±çš„å±‚çº§
        for lv in list(parent_stack.keys()):
            if lv > suggested_level:
                del parent_stack[lv]
        
        print(f"[è¡¨æ ¼è½¬æ¢] ç¬¬{row_idx}è¡Œ: {text} [L{suggested_level}, çˆ¶:{parent_title or 'ROOT'}]", file=sys.stderr)
        
        text_blocks.append({
            "type": "p",
            "text": text,
            "blockId": f"table{table_index}_row{row_idx}",
            "from_table": True,
            "suggested_level": suggested_level,
            "parent_title": parent_title  # ğŸ”¥ è®°å½•çˆ¶èŠ‚ç‚¹æ ‡é¢˜
        })
    
    logger.info(f"[è¡¨æ ¼è½¬æ¢] ä»è¡¨æ ¼æå– {len(text_blocks)} ä¸ªæ–‡æœ¬é¡¹")
    print(f"[è¡¨æ ¼è½¬æ¢] å®Œæˆï¼Œå…± {len(text_blocks)} ä¸ªæ–‡æœ¬é¡¹", file=sys.stderr)
    return text_blocks


def _infer_level_from_numbering(numbering: str) -> int:
    """
    æ ¹æ®ç¼–å·æ ¼å¼æ¨æ–­å±‚çº§
    
    è§„åˆ™ï¼š
    - ç©ºæˆ–æ— ç¼–å· â†’ L2ï¼ˆé»˜è®¤ï¼‰
    - æ•°å­—ç¼–å·ï¼ˆ1ã€2ã€3ã€1ï¼‰ã€2ï¼‰ï¼‰ â†’ L2
    - å­—æ¯ç¼–å·ï¼ˆaã€bã€Aï¼‰ã€Bï¼‰ï¼‰ â†’ L3
    - ç½—é©¬æ•°å­—ï¼ˆiã€iiã€iiiï¼‰ â†’ L3
    """
    if not numbering:
        return 2
    
    # æå–ç¼–å·ä¸»ä½“ï¼ˆå»é™¤æ‹¬å·å’Œæ ‡ç‚¹ï¼‰
    core = re.sub(r'[\)ï¼‰\.\ã€\s]', '', numbering)
    
    # å­—æ¯ç¼–å·
    if re.match(r'^[a-zA-Z]$', core):
        return 3
    
    # ç½—é©¬æ•°å­—ï¼ˆå°å†™ï¼‰
    if re.match(r'^[ivxlcdm]+$', core.lower()) and len(core) <= 4:
        return 3
    
    # æ•°å­—ç¼–å·
    if re.match(r'^\d+$', core):
        return 2
    
    # é»˜è®¤L2
    return 2


def _find_content_column_index(header: List[str]) -> int:
    """
    æ‰¾åˆ°"å†…å®¹"åˆ—çš„ç´¢å¼•
    
    ä¼˜å…ˆçº§ï¼šå†…å®¹ > é¡¹ç›® > åç§° > æ–‡ä»¶ > é»˜è®¤ç¬¬äºŒåˆ—
    """
    keywords = ['å†…å®¹', 'é¡¹ç›®', 'åç§°', 'æ–‡ä»¶', 'ææ–™']
    
    for i, col in enumerate(header):
        col_lower = col.lower()
        if any(kw in col_lower for kw in keywords):
            return i
    
    # é»˜è®¤ç¬¬äºŒåˆ—ï¼ˆç¬¬ä¸€åˆ—é€šå¸¸æ˜¯åºå·ï¼‰
    return 1 if len(header) > 1 else 0


def _extract_directory_from_blocks(
    blocks: List[Dict[str, Any]], 
    existing_titles: set
) -> List[Dict[str, Any]]:
    """
    ä»blocksä¸­æå–ç›®å½•ç»“æ„ï¼ˆè§„åˆ™æ–¹æ³•ï¼‰
    
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆæå–è¡¨æ ¼è½¬æ¢çš„ç›®å½•é¡¹ï¼ˆæ ‡è®°ä¸ºfrom_table=Trueçš„å—ï¼‰
    2. å¦‚æœæ²¡æœ‰è¡¨æ ¼è½¬æ¢çš„é¡¹ï¼Œåˆ™æå–æ‰€æœ‰ç¼–å·çš„æ–‡æœ¬
    3. æ¨æ–­å±‚çº§å…³ç³»
    4. è¿‡æ»¤å·²å­˜åœ¨çš„èŠ‚ç‚¹
    
    Args:
        blocks: æ ¼å¼ç« èŠ‚çš„blocksï¼ˆå¯èƒ½åŒ…å«è¡¨æ ¼è½¬æ¢åçš„æ–‡æœ¬å—ï¼‰
        existing_titles: å·²å­˜åœ¨çš„æ ‡é¢˜é›†åˆ
        
    Returns:
        ç›®å½•èŠ‚ç‚¹åˆ—è¡¨
    """
    # 1. æ£€æŸ¥æ˜¯å¦æœ‰è¡¨æ ¼è½¬æ¢çš„ç›®å½•é¡¹
    has_table_items = any(b.get('from_table', False) for b in blocks if b.get('type') == 'p')
    
    if has_table_items:
        logger.info("[ç›®å½•æå–] å‘ç°è¡¨æ ¼è½¬æ¢çš„ç›®å½•é¡¹ï¼Œæå–è¡¨æ ¼é¡¹åŠå…¶å‰åçš„L1æ ‡é¢˜")
    else:
        logger.info("[ç›®å½•æå–] æœªå‘ç°è¡¨æ ¼ç›®å½•ï¼Œæå–æ‰€æœ‰ç¼–å·çš„æ–‡æœ¬é¡¹")
    
    # 2. è¯†åˆ«æ ‡é¢˜è¡Œ
    title_candidates = []
    seen_titles = set()  # ç”¨äºå»é‡
    first_l1_titles = set()  # è®°å½•ç¬¬ä¸€è½®å‡ºç°çš„L1æ ‡é¢˜
    
    for i, block in enumerate(blocks):
        if block["type"] != "p":
            continue
        
        text = block.get("text", "").strip()
        if not text:
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜ï¼ˆç¼–å·æ¨¡å¼ï¼‰
        numbering, title, level = _parse_title_line(text)
        
        if not numbering or not title:
            continue
        
        # ğŸ”¥ å¦‚æœblockæœ‰suggested_levelï¼ˆæ¥è‡ªè¡¨æ ¼è½¬æ¢ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨
        if block.get('suggested_level'):
            level = block['suggested_level']
            logger.debug(f"[ç›®å½•æå–] ä½¿ç”¨è¡¨æ ¼å»ºè®®å±‚çº§: {title} â†’ L{level}")
        
        # ğŸ”¥ å¼ºåˆ¶ä¿ç•™æ‰€æœ‰from_tableçš„å—ï¼ˆè¡¨æ ¼è½¬æ¢çš„ç›®å½•é¡¹ï¼‰
        is_from_table = block.get('from_table', False)
        
        # ğŸ”¥ å¦‚æœæœ‰è¡¨æ ¼è½¬æ¢çš„é¡¹ï¼Œ**åª**æå–from_table=Trueçš„å—
        if has_table_items:
            if not is_from_table:
                continue
        
        # è¿‡æ»¤ï¼šè·³è¿‡å¤ªé•¿çš„æ–‡æœ¬
        if len(text) > 100:
            continue
        
        # è¿‡æ»¤ï¼šè·³è¿‡å·²å­˜åœ¨çš„æ ‡é¢˜
        if title in existing_titles:
            continue
        
        # L1èŠ‚ç‚¹å»é‡æ£€æŸ¥
        if level == 1:
            if title in first_l1_titles:
                logger.info(f"[ç›®å½•æå–] é‡åˆ°é‡å¤L1æ ‡é¢˜ã€Œ{title}ã€ï¼Œåœæ­¢æå–")
                break
            first_l1_titles.add(title)
        
        # å…¨å±€å»é‡
        if title in seen_titles:
            continue
        
        seen_titles.add(title)
        
        title_candidates.append({
            "block_index": i,
            "numbering": numbering,
            "title": title,
            "level": level,
            "original_text": text,
            "block_id": block.get("blockId", f"b{i}"),
            "parent_title": block.get("parent_title")  # ğŸ”¥ ä¼ é€’parent_title
        })
        logger.debug(f"[ç›®å½•æå–] æ·»åŠ å€™é€‰: L{level} {numbering} {title[:30]}, çˆ¶:{block.get('parent_title', 'ROOT')}")
    
    logger.info(f"[ç›®å½•æå–] è¯†åˆ«åˆ° {len(title_candidates)} ä¸ªæ ‡é¢˜å€™é€‰")
    
    # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°å€™é€‰èŠ‚ç‚¹çš„numbering
    import sys
    if title_candidates:
        print(f"[ç›®å½•æå–-DEBUG] å‰5ä¸ªå€™é€‰èŠ‚ç‚¹çš„numbering:", file=sys.stderr)
        for i, cand in enumerate(title_candidates[:5]):
            print(f"  {i+1}. L{cand['level']} {cand['numbering']} - {cand['title'][:30]}", file=sys.stderr)
    
    # 2. æ¨æ–­çˆ¶å­å…³ç³»
    directory_nodes = _infer_parent_child_relations(title_candidates)
    
    # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°æ¨æ–­åçš„numbering
    if directory_nodes:
        print(f"[ç›®å½•æå–-DEBUG] æ¨æ–­åå‰5ä¸ªèŠ‚ç‚¹çš„numbering:", file=sys.stderr)
        for i, node in enumerate(directory_nodes[:5]):
            print(f"  {i+1}. L{node['level']} {node['numbering']} - {node['title'][:30]}", file=sys.stderr)
    
    return directory_nodes


def _parse_title_line(text: str) -> tuple:
    """
    è§£ææ ‡é¢˜è¡Œï¼Œæå–ç¼–å·ã€æ ‡é¢˜ã€å±‚çº§
    
    æ”¯æŒçš„ç¼–å·æ ¼å¼ï¼š
    - ä¸€çº§ï¼šç¬¬ä¸€å†Œã€ç¬¬äºŒå†Œã€ä¸€ã€äºŒã€(ä¸€)ã€(äºŒ)
    - äºŒçº§ï¼š1.ã€2.ã€(1)ã€(2)ã€â‘ ã€â‘¡
    - ä¸‰çº§ï¼š1.1ã€1.2ã€a)ã€b)
    
    Args:
        text: æ ‡é¢˜æ–‡æœ¬
        
    Returns:
        (ç¼–å·, æ ‡é¢˜, å±‚çº§) æˆ– (None, None, 0)
    """
    text = text.strip()
    
    # è¿‡æ»¤1ï¼šå¤ªé•¿çš„ä¸æ˜¯æ ‡é¢˜ï¼ˆè¶…è¿‡60å­—ç¬¦ï¼‰
    if len(text) > 60:
        return None, None, 0
    
    # è¿‡æ»¤2ï¼šåŒ…å«å¥å·çš„é€šå¸¸æ˜¯æ­£æ–‡
    if 'ã€‚' in text:
        return None, None, 0
    
    # è¿‡æ»¤3ï¼šåŒ…å«å†’å·+é•¿æ–‡æœ¬çš„é€šå¸¸æ˜¯æ­£æ–‡ï¼ˆå¦‚"é¡¹ç›®åç§°ï¼šXXX"ï¼‰
    # ä½†å¦‚æœæ–‡æœ¬ä»¥ç¼–å·å¼€å¤´ï¼ˆå¦‚"2ï¼‰XXXï¼š"ï¼‰ï¼Œåˆ™ä¸è¿‡æ»¤
    if ('ï¼š' in text or ':' in text) and len(text) > 20:
        # æ£€æŸ¥æ˜¯å¦ä»¥ç¼–å·å¼€å¤´
        if not re.match(r'^([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+|[0-9]{1,2}|[a-zA-Z])[\)ï¼‰\.\ã€]', text):
            return None, None, 0
    
    # è¿‡æ»¤4ï¼šæ ‡ç‚¹å¯†é›†çš„æ˜¯æ­£æ–‡
    punct_count = text.count('ï¼Œ') + text.count('ã€‚') + text.count('ï¼›') + text.count('ã€')
    if punct_count > 2:
        return None, None, 0
    
    # è¿‡æ»¤5ï¼šä»¥åŠ¨è¯å¼€å¤´çš„å¯èƒ½æ˜¯æ­£æ–‡ï¼ˆåœ¨ã€æˆ‘ã€æŒ‰ã€æœ¬ç­‰ï¼‰
    if text.startswith(('åœ¨æ”¶åˆ°', 'åœ¨ç­¾è®¢', 'åœ¨åˆåŒ', 'åœ¨æŠ•æ ‡', 'æŒ‰ç…§', 'æˆ‘å•ä½', 'æœ¬åè®®', 'è”åˆä½“å„', 'è”åˆä½“ç‰µå¤´')):
        return None, None, 0
    
    # è¿‡æ»¤6ï¼šåŒ…å«"é¡»"ã€"åº”"ã€"å¿…é¡»"ç­‰è¦æ±‚æ€§è¯æ±‡ä¸”è¾ƒé•¿çš„æ˜¯æ­£æ–‡
    if any(word in text for word in ['å¿…é¡»', 'åº”å½“', 'é¡»']) and len(text) > 30:
        return None, None, 0
    
    # æ¨¡å¼1: "ç¬¬Xå†Œ/ç¬¬Xéƒ¨åˆ†/ç¬¬Xç« " - 1çº§
    match = re.match(r'^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+(?:å†Œ|éƒ¨åˆ†|ç« |èŠ‚))\s+(.+)$', text)
    if match:
        return match.group(1), match.group(2).strip(), 1
    
    # æ¨¡å¼2: "ä¸€ã€äºŒã€ä¸‰ã€" - 1çº§ï¼ˆå¿…é¡»æœ‰é¡¿å·æˆ–ç©ºæ ¼ï¼‰
    match = re.match(r'^([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)[ã€\s](.+)$', text)
    if match and len(match.group(1)) <= 3:
        return match.group(1), match.group(2).strip(), 1
    
    # æ¨¡å¼3: "(ä¸€)(äºŒ)(ä¸‰)" - 1çº§
    match = re.match(r'^[\(ï¼ˆ]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)[\)ï¼‰][ã€\sï¼š:]*(.+)$', text)
    if match:
        return f"({match.group(1)})", match.group(2).strip(), 1
    
    # æ¨¡å¼4: "1.1 1.2" - 3çº§ï¼ˆå¿…é¡»å…ˆåŒ¹é…ï¼Œä¼˜å…ˆçº§é«˜ï¼‰
    match = re.match(r'^(\d{1,2}\.\d{1,2})\s+(.+)$', text)
    if match:
        return match.group(1), match.group(2).strip(), 3
    
    # æ¨¡å¼5: "1. 2. 3." - 2çº§ï¼ˆåé¢å¿…é¡»æœ‰ç‚¹å·æˆ–é¡¿å·ï¼‰
    match = re.match(r'^(\d{1,2})[\.\ã€]\s*(.+)$', text)
    if match:
        return match.group(1), match.group(2).strip(), 2
    
    # æ¨¡å¼5b: "1ï¼‰2ï¼‰3ï¼‰" - 2çº§ï¼ˆå¸¸è§äºè¡¨æ ¼å¯¼å‡ºçš„ç›®å½•ï¼‰
    match = re.match(r'^(\d{1,2})[\)ï¼‰]\s*(.+)$', text)
    if match:
        return match.group(1) + ")", match.group(2).strip(), 2
    
    # æ¨¡å¼6: "(1)(2)(3)" - 2çº§ï¼ˆåŠè§’æ‹¬å·ï¼‰
    match = re.match(r'^[\(](\d{1,2})[\)][ã€\sï¼š:]*(.+)$', text)
    if match:
        return f"({match.group(1)})", match.group(2).strip(), 2
    
    # æ¨¡å¼7: "ï¼ˆ1ï¼‰ï¼ˆ2ï¼‰ï¼ˆ3ï¼‰" - 1çº§ï¼ˆå…¨è§’æ‹¬å·ï¼Œå¸¸è§äºå¤§æ ‡é¢˜ï¼‰
    match = re.match(r'^[ï¼ˆ](\d{1,2})[ï¼‰]\s*(.+)$', text)
    if match:
        return f"ï¼ˆ{match.group(1)}ï¼‰", match.group(2).strip(), 1
    
    # æ¨¡å¼8: "â‘ â‘¡â‘¢" - 2çº§
    match = re.match(r'^([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©])\s*(.+)$', text)
    if match:
        return match.group(1), match.group(2).strip(), 2
    
    # æ¨¡å¼9: "a) b) c)" æˆ– "A) B) C)" - 3çº§ï¼ˆæ”¯æŒå¤§å°å†™ï¼‰
    match = re.match(r'^([a-zA-Z])[\)ï¼‰\.][\sï¼š:]*(.+)$', text)
    if match:
        return match.group(1) + ")", match.group(2).strip(), 3
    
    # æœªåŒ¹é…åˆ°ç¼–å·æ¨¡å¼
    return None, None, 0


def _infer_parent_child_relations(
    title_candidates: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    æ¨æ–­çˆ¶å­å…³ç³»ï¼Œæ„å»ºå±‚çº§ç»“æ„ï¼Œå¹¶æŒ‰ç…§æ ‘çš„æ·±åº¦ä¼˜å…ˆéå†é¡ºåºè¿”å›
    
    ä¼˜å…ˆä½¿ç”¨parent_titleï¼ˆè¡¨æ ¼è½¬æ¢æ—¶å·²å»ºç«‹çš„å…³ç³»ï¼‰ï¼Œ
    å¦åˆ™ä½¿ç”¨æ ˆæ¥è·Ÿè¸ªçˆ¶èŠ‚ç‚¹
    """
    if not title_candidates:
        return []
    
    title_to_node = {}  # title -> node_dict
    title_to_children = {}  # title -> [child_nodes]
    stack = []  # [(level, node_dict)]
    roots = []  # æ ¹èŠ‚ç‚¹åˆ—è¡¨
    
    for candidate in title_candidates:
        level = candidate["level"]
        title = candidate["title"]
        parent_title = candidate.get("parent_title")
        
        # åˆ›å»ºèŠ‚ç‚¹
        node = {
            "numbering": candidate["numbering"],
            "title": title,
            "level": level,
            "parent_id": None,
            "parent_ref": None,
            "is_required": True,
            "source": "format_chapter_extracted",
            "evidence_chunk_ids": [candidate["block_id"]],
            "meta_json": {
                "original_text": candidate["original_text"],
                "block_index": candidate["block_index"]
            }
        }
        
        # ğŸ”¥ ä½¿ç”¨parent_titleå»ºç«‹å…³ç³»
        if parent_title and parent_title in title_to_node:
            node["parent_ref"] = parent_title
            # å°†å½“å‰èŠ‚ç‚¹æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹çš„childrenåˆ—è¡¨
            title_to_children.setdefault(parent_title, []).append(node)
        else:
            # fallbackï¼šä½¿ç”¨æ ˆæ¨æ–­
            while stack and stack[-1][0] >= level:
                stack.pop()
            if stack:
                parent_node = stack[-1][1]
                node["parent_ref"] = parent_node["title"]
                title_to_children.setdefault(parent_node["title"], []).append(node)
            else:
                # æ— çˆ¶èŠ‚ç‚¹ï¼Œæ˜¯æ ¹èŠ‚ç‚¹
                roots.append(node)
        
        title_to_node[title] = node
        stack.append((level, node))
    
    # ğŸ”¥ æŒ‰ç…§æ·±åº¦ä¼˜å…ˆéå†é¡ºåºè¿”å›
    result = []
    def dfs(node):
        result.append(node)
        children = title_to_children.get(node["title"], [])
        for child in children:
            dfs(child)
    
    for root in roots:
        dfs(root)
    
    return result


def _insert_directory_nodes(
    pool: Any, 
    project_id: str, 
    nodes: List[Dict[str, Any]]
) -> int:
    """
    æ’å…¥ç›®å½•èŠ‚ç‚¹åˆ°æ•°æ®åº“
    
    Returns:
        æˆåŠŸæ’å…¥çš„èŠ‚ç‚¹æ•°
    """
    if not nodes:
        return 0
    
    # ğŸ”¥ æ­¥éª¤1ï¼šå…ˆä¸ºæ‰€æœ‰èŠ‚ç‚¹ç”Ÿæˆid
    for node in nodes:
        if "id" not in node:
            node["id"] = str(uuid.uuid4())
    
    # ğŸ”¥ æ­¥éª¤2ï¼šåˆ›å»ºtitle -> nodeçš„æ˜ å°„
    title_to_node = {n["title"]: n for n in nodes}
    
    # ğŸ”¥ æ­¥éª¤3ï¼šä¸ºæ¯ä¸ªèŠ‚ç‚¹è®¾ç½®parent_id
    import sys
    parent_set_count = 0
    for node in nodes:
        parent_ref = node.get("parent_ref")
        print(f"[ç›®å½•ä¿å­˜] èŠ‚ç‚¹: {node['title'][:30]}, parent_ref={parent_ref[:20] if parent_ref else 'None'}", file=sys.stderr)
        if parent_ref and parent_ref in title_to_node:
            parent_node = title_to_node[parent_ref]
            node["parent_id"] = parent_node["id"]
            parent_set_count += 1
            print(f"[ç›®å½•ä¿å­˜] âœ“ è®¾ç½®çˆ¶èŠ‚ç‚¹: {node['title'][:20]} -> {parent_ref[:20]}", file=sys.stderr)
        elif parent_ref:
            print(f"[ç›®å½•ä¿å­˜] âœ— çˆ¶èŠ‚ç‚¹'{parent_ref}'æœªæ‰¾åˆ°ï¼ŒèŠ‚ç‚¹: {node['title'][:30]}", file=sys.stderr)
    
    print(f"[ç›®å½•ä¿å­˜] æˆåŠŸè®¾ç½®{parent_set_count}/{len(nodes)}ä¸ªèŠ‚ç‚¹çš„parent_id", file=sys.stderr)
    
    added_count = 0
    
    with pool.connection() as conn:
        with conn.cursor() as cur:
            # è·å–æœ€å¤§ order_noï¼ˆä¸ä½¿ç”¨dict_rowï¼Œç›´æ¥å–tupleï¼‰
            cur.execute(
                "SELECT COALESCE(MAX(order_no), 0) FROM tender_directory_nodes WHERE project_id = %s",
                (project_id,)
            )
            result = cur.fetchone()
            # resultå¯èƒ½æ˜¯tupleæˆ–dictï¼Œéœ€è¦åˆ¤æ–­
            logger.info(f"[ç›®å½•å¢å¼º-DEBUG] fetchone result: {result}, type={type(result)}")
            
            if isinstance(result, dict):
                # å¦‚æœæ˜¯dictï¼Œå–å­—å…¸çš„ç¬¬ä¸€ä¸ªå€¼
                max_order = list(result.values())[0] if result else 0
            elif isinstance(result, (tuple, list)):
                # å¦‚æœæ˜¯tupleæˆ–listï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                max_order = result[0] if result and len(result) > 0 else 0
            else:
                # å…¶ä»–æƒ…å†µï¼Œé»˜è®¤0
                max_order = 0
            
            for i, node in enumerate(nodes):
                # ğŸ”¥ ä½¿ç”¨nodeå·²æœ‰çš„idï¼Œå¦‚æœæ²¡æœ‰æ‰ç”Ÿæˆï¼ˆä½†å‰é¢å·²ç»ç¡®ä¿æœ‰äº†ï¼‰
                node_id = node.get("id") or str(uuid.uuid4())
                order_no = max_order + i + 1
                
                try:
                    import json
                    cur.execute("""
                        INSERT INTO tender_directory_nodes (
                            id, project_id, parent_id, order_no, level,
                            numbering, title, is_required, source,
                            evidence_chunk_ids, meta_json
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """, (
                        node_id,
                        project_id,
                        node.get("parent_id"),  # ğŸ”¥ ä½¿ç”¨å·²è®¾ç½®çš„parent_id
                        order_no,
                        node.get("level", 2),
                        node.get("numbering", ""),
                        node["title"],
                        node.get("is_required", True),
                        node.get("source", "format_chapter_extracted"),
                        node.get("evidence_chunk_ids", []),  # ç›´æ¥ä¼ listï¼ŒPostgreSQLä¼šè½¬ä¸ºarray
                        json.dumps(node.get("meta_json", {}))  # jsonbç”¨json.dumps
                    ))
                    added_count += 1
                except Exception as e:
                    import traceback
                    logger.error(f"[ç›®å½•å¢å¼º] æ’å…¥èŠ‚ç‚¹å¤±è´¥: {node['title']}, é”™è¯¯: {e}")
                    logger.error(f"[ç›®å½•å¢å¼º] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                    continue
        
        conn.commit()
    
    return added_count


def _extract_directory_with_llm(
    blocks: List[Dict[str, Any]],
    existing_titles: set,
    project_id: str,
    pool: Any
) -> List[Dict[str, Any]]:
    """
    ç”¨LLMä»æ ¼å¼ç« èŠ‚æå–ç›®å½•ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
    
    å½“è§„åˆ™æ–¹æ³•æ— æ³•æå–æ—¶ï¼Œä½¿ç”¨LLMç†è§£æ–‡æœ¬å†…å®¹
    """
    # å°†blocksè½¬æ¢ä¸ºæ–‡æœ¬
    text_content = []
    for block in blocks[:50]:  # é™åˆ¶å‰50ä¸ªblocks
        if block["type"] == "p":
            text = block.get("text", "").strip()
            if text:
                text_content.append(text)
    
    if not text_content:
        return []
    
    full_text = "\n".join(text_content)
    
    # æ„å»ºLLMæç¤º
    prompt = f"""è¯·ä»ä»¥ä¸‹æ‹›æ ‡æ–‡ä»¶å†…å®¹ä¸­æå–æŠ•æ ‡æ–‡ä»¶ç›®å½•ç»“æ„ã€‚

è¦æ±‚ï¼š
1. åªæå–ç›®å½•é¡¹ï¼Œä¸è¦æå–è¯´æ˜æ€§æ–‡å­—
2. ä¿æŒåŸå§‹ç¼–å·å’Œæ ‡é¢˜
3. è¯†åˆ«å±‚çº§å…³ç³»ï¼ˆ1çº§ã€2çº§ã€3çº§ï¼‰
4. è¾“å‡ºJSONæ ¼å¼

å†…å®¹ï¼š
{full_text[:2000]}

è¯·è¾“å‡ºJSONæ•°ç»„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {{"numbering": "ä¸€", "title": "èµ„æ ¼è¯æ˜æ–‡ä»¶", "level": 1}},
  {{"numbering": "1", "title": "è¥ä¸šæ‰§ç…§", "level": 2}},
  ...
]
"""
    
    try:
        # è°ƒç”¨LLMï¼ˆæ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥LLMå®ä¾‹ï¼Œæš‚æ—¶è·³è¿‡ï¼‰
        # TODO: éœ€è¦ä»å¤–å±‚ä¼ å…¥llmå®ä¾‹
        logger.info(f"[ç›®å½•å¢å¼º] LLMæå–åŠŸèƒ½éœ€è¦LLMå®ä¾‹æ”¯æŒï¼Œæš‚æ—¶è·³è¿‡")
        return []
        
        # ä»¥ä¸‹ä»£ç å¾…å¯ç”¨
        # from app.llm.orchestrator import LLMOrchestrator
        # llm = LLMOrchestrator()
        # 
        # response = llm.complete(
        #     prompt=prompt,
        #     model_id="gpt-4",
        #     temperature=0.1
        # )
        
        # è§£æJSON
        import json
        import re
        
        # æå–JSONéƒ¨åˆ†
        json_match = re.search(r'\[[\s\S]*\]', response)
        if json_match:
            nodes_data = json.loads(json_match.group(0))
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            result = []
            for node in nodes_data:
                if node.get("title") and node["title"] not in existing_titles:
                    result.append({
                        "numbering": node.get("numbering", ""),
                        "title": node["title"],
                        "level": node.get("level", 2),
                        "is_required": True,
                        "source": "format_chapter_llm_extracted",
                        "evidence_chunk_ids": [],
                        "meta_json": {"extraction_method": "llm"}
                    })
            
            return result
        
    except Exception as e:
        logger.warning(f"[ç›®å½•å¢å¼º] LLMæå–å¤±è´¥: {e}")
    
    return []


def _get_existing_directory_nodes(pool: Any, project_id: str) -> List[Dict[str, Any]]:
    """è·å–ç°æœ‰ç›®å½•èŠ‚ç‚¹"""
    from psycopg.rows import dict_row
    
    with pool.connection() as conn:
        conn.row_factory = dict_row
        with conn.cursor() as cur:
            cur.execute("""
                SELECT id, title, level, order_no, is_required, source
                FROM tender_directory_nodes
                WHERE project_id = %s
                ORDER BY order_no
            """, (project_id,))
            
            rows = cur.fetchall()
            return [
                {
                    "id": row['id'],
                    "title": row['title'],
                    "level": row['level'],
                    "order_no": row['order_no'],
                    "is_required": row['is_required'],
                    "source": row['source']
                }
                for row in rows
            ]

