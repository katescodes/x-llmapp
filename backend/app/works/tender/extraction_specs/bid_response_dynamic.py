"""
åŠ¨æ€æŠ•æ ‡å“åº”æå–Specæ„å»ºå™¨
åŸºäºæ‹›æ ‡è¦æ±‚ï¼ˆrequirementsï¼‰åŠ¨æ€ç”Ÿæˆæå–Specï¼Œå®ç°éœ€æ±‚é©±åŠ¨çš„æå–
"""
import logging
from typing import Dict, List, Optional, Any
from psycopg_pool import ConnectionPool

from app.platform.extraction.types import ExtractionSpec
from app.works.tender.requirement_postprocessor import generate_dynamic_prompt_supplement

logger = logging.getLogger(__name__)


async def build_bid_response_spec_from_requirements(
    pool: ConnectionPool,
    project_id: str
) -> ExtractionSpec:
    """
    åŸºäºæ‹›æ ‡è¦æ±‚åŠ¨æ€æ„å»ºæŠ•æ ‡å“åº”æå–spec
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. ä»æ•°æ®åº“åŠ è½½æ‹›æ ‡è¦æ±‚ï¼ˆrequirementsï¼‰
    2. ä»meta_jsonåŠ è½½æå–æŒ‡å—ï¼ˆextraction_guideï¼‰
    3. ç”ŸæˆåŠ¨æ€promptï¼ˆåŸºç¡€prompt + æŒ‡å—è¡¥å……ï¼‰
    4. ç”Ÿæˆé’ˆå¯¹æ€§æ£€ç´¢æŸ¥è¯¢ï¼ˆåªé’ˆå¯¹è¦æ±‚çš„ç»´åº¦ï¼‰
    5. æ„å»ºExtractionSpec
    
    Args:
        pool: æ•°æ®åº“è¿æ¥æ± 
        project_id: é¡¹ç›®ID
    
    Returns:
        åŠ¨æ€ç”Ÿæˆçš„ExtractionSpec
    """
    logger.info(f"Building dynamic bid response spec for project_id={project_id}")
    
    # 1. åŠ è½½æ‹›æ ‡è¦æ±‚
    requirements = await _load_requirements(pool, project_id)
    logger.info(f"Loaded {len(requirements)} requirements")
    
    # 2. åŠ è½½æå–æŒ‡å—
    extraction_guide = await _load_extraction_guide(pool, project_id)
    
    if not extraction_guide:
        logger.warning(
            f"No extraction guide found for project_id={project_id}, "
            "generating on-the-fly"
        )
        # å¦‚æœæ²¡æœ‰æå–æŒ‡å—ï¼Œä¸´æ—¶ç”Ÿæˆä¸€ä¸ª
        from app.works.tender.requirement_postprocessor import generate_bid_response_extraction_guide
        extraction_guide = generate_bid_response_extraction_guide(requirements)
    
    logger.info(
        f"Loaded extraction guide: "
        f"must_extract={len(extraction_guide.get('must_extract_norm_keys', []))}, "
        f"dimensions={len(extraction_guide.get('dimension_focus', {}))}"
    )
    
    # 3. åŠ è½½åŸºç¡€promptï¼ˆä»æ•°æ®åº“æˆ–æ–‡ä»¶ï¼‰
    base_prompt = await _load_base_prompt(pool)
    
    # 4. ç”ŸæˆåŠ¨æ€promptè¡¥å……ï¼ˆåŒ…å«æ‹›æ ‡è¦æ±‚åˆ—è¡¨ï¼‰
    prompt_supplement = generate_dynamic_prompt_supplement(extraction_guide, requirements)
    
    # 5. ç»„åˆå®Œæ•´prompt
    full_prompt = base_prompt + "\n\n" + prompt_supplement
    
    # 6. ç”Ÿæˆé’ˆå¯¹æ€§æ£€ç´¢æŸ¥è¯¢
    queries = _generate_targeted_queries(requirements, extraction_guide)
    
    # 7. æ„å»ºspec
    spec = ExtractionSpec(
        prompt=full_prompt,
        queries=queries,
        topk_per_query=25,  # é’ˆå¯¹æ€§æ£€ç´¢ï¼Œæ¯ä¸ªæŸ¥è¯¢å‡å°‘æ•°é‡
        topk_total=100,     # æ€»é‡ä¹Ÿå‡å°‘ï¼ˆå› ä¸ºæ›´ç²¾ç¡®ï¼‰
        doc_types=["bid"],  # åªæ£€ç´¢æŠ•æ ‡æ–‡æ¡£
        temperature=0.0,
    )
    
    logger.info(
        f"Built dynamic spec: queries={len(queries)}, "
        f"topk_per_query={spec.topk_per_query}, topk_total={spec.topk_total}"
    )
    
    return spec


async def _load_requirements(pool: ConnectionPool, project_id: str) -> List[Dict[str, Any]]:
    """ä»æ•°æ®åº“åŠ è½½æ‹›æ ‡è¦æ±‚"""
    with pool.connection() as conn:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT 
                    requirement_id,
                    dimension,
                    req_type,
                    requirement_text,
                    is_hard,
                    value_schema_json,
                    evidence_chunk_ids
                FROM tender_requirements
                WHERE project_id = %s
                ORDER BY dimension, requirement_id
            """, (project_id,))
            
            rows = cur.fetchall()
            requirements = []
            for row in rows:
                # å…¼å®¹dict_rowå’Œtuple
                if isinstance(row, dict):
                    requirements.append({
                        "requirement_id": row.get("requirement_id"),
                        "dimension": row.get("dimension"),
                        "req_type": row.get("req_type"),
                        "requirement_text": row.get("requirement_text"),
                        "is_hard": row.get("is_hard"),
                        "value_schema_json": row.get("value_schema_json"),
                        "evidence_chunk_ids": row.get("evidence_chunk_ids") or [],
                    })
                else:
                    requirements.append({
                        "requirement_id": row[0],
                        "dimension": row[1],
                        "req_type": row[2],
                        "requirement_text": row[3],
                        "is_hard": row[4],
                        "value_schema_json": row[5],
                        "evidence_chunk_ids": row[6] or [],
                    })
            
            return requirements


async def _load_extraction_guide(pool: ConnectionPool, project_id: str) -> Optional[Dict[str, Any]]:
    """ä»meta_jsonåŠ è½½æå–æŒ‡å—ï¼ˆç»Ÿä¸€ä½¿ç”¨ extraction_guide é”®ï¼Œå…¼å®¹æ—§é”®ï¼‰"""
    with pool.connection() as conn:
        with conn.cursor() as cur:
            # ä¼˜å…ˆè¯»å–æ–°é”® extraction_guideï¼Œå…¼å®¹æ—§é”® bid_response_extraction_guide
            cur.execute("""
                SELECT 
                    COALESCE(
                        meta_json->'extraction_guide',
                        meta_json->'bid_response_extraction_guide'
                    ) as guide
                FROM tender_projects
                WHERE id = %s
            """, (project_id,))
            
            result = cur.fetchone()
            if result:
                # å…¼å®¹dict_rowå’Œtuple
                guide = result.get("guide") if isinstance(result, dict) else result[0]
                return guide if guide else None
            return None


async def _load_base_prompt(pool: ConnectionPool) -> str:
    """
    åŠ è½½åŸºç¡€æŠ•æ ‡å“åº”æå–prompt
    
    ä¼˜å…ˆä»æ•°æ®åº“åŠ è½½ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤prompt
    """
    # 1. å°è¯•ä»æ•°æ®åº“åŠ è½½
    try:
        with pool.connection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT content 
                    FROM prompt_templates 
                    WHERE name = %s AND is_active = true 
                    ORDER BY version DESC 
                    LIMIT 1
                """, ("bid_response_extraction_v5",))
                
                result = cur.fetchone()
                if result:
                    # å…¼å®¹dict_rowå’Œtuple
                    content = result.get("content") if isinstance(result, dict) else result[0]
                    if content:
                        logger.info("Loaded base prompt from database: bid_response_extraction_v5")
                        return content
    except Exception as e:
        logger.warning(f"Failed to load prompt from database: {e}")
    
    # 2. ä½¿ç”¨é»˜è®¤prompt
    logger.info("Using default base prompt")
    return _get_default_base_prompt()


def _get_default_base_prompt() -> str:
    """è·å–é»˜è®¤çš„åŸºç¡€prompt"""
    return """# è§’è‰²ä¸ä»»åŠ¡

ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•æ ‡æ–‡ä»¶å®¡æ ¸ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

**ğŸ“‹ æ ¸å¿ƒç›®æ ‡**ï¼šé’ˆå¯¹ä¸‹æ–¹æä¾›çš„æ‹›æ ‡è¦æ±‚åˆ—è¡¨ï¼Œé€æ¡ä»æŠ•æ ‡æ–‡æ¡£ä¸­æå–å¯¹åº”çš„å“åº”å†…å®¹ã€‚

**âš ï¸ å…³é”®åŸåˆ™**ï¼š
1. **éœ€æ±‚é©±åŠ¨**ï¼šåªæå–æ‹›æ ‡è¦æ±‚ä¸­æ˜ç¡®éœ€è¦çš„å†…å®¹ï¼Œé¿å…è¿‡åº¦æå–
2. **ä¸€ä¸€å¯¹åº”**ï¼šæ¯æ¡å“åº”åº”å¯¹åº”ä¸€ä¸ªæ‹›æ ‡è¦æ±‚ï¼Œç¡®ä¿å®Œæ•´è¦†ç›–
3. **ç²¾å‡†åŒ¹é…**ï¼šå“åº”çš„ç»´åº¦(dimension)å’Œnorm_keyå¿…é¡»ä¸æ‹›æ ‡è¦æ±‚ä¸€è‡´

## æå–æµç¨‹

### Step 1: é˜…è¯»æ‹›æ ‡è¦æ±‚
- ä»”ç»†é˜…è¯»ä¸‹æ–¹çš„"æ‹›æ ‡è¦æ±‚æ¸…å•"
- ç†è§£æ¯æ¡è¦æ±‚çš„ç»´åº¦(dimension)å’Œnorm_key
- è¯†åˆ«ç¡¬æ€§è¦æ±‚ï¼ˆå¸¦â–²æ ‡è¯†ï¼‰

### Step 2: æ£€ç´¢æŠ•æ ‡æ–‡æ¡£
- é’ˆå¯¹æ¯æ¡æ‹›æ ‡è¦æ±‚ï¼Œåœ¨æŠ•æ ‡æ–‡æ¡£ä¸­æœç´¢å¯¹åº”çš„å“åº”å†…å®¹
- æ³¨æ„ï¼šå“åº”å¯èƒ½åœ¨ä¸åŒç« èŠ‚ã€ä¸åŒä½ç½®
- ç‰¹åˆ«å…³æ³¨å¸¦â–²â˜…â—â€»ç¬¦å·çš„æŠ•æ ‡æ–‡æ¡£å†…å®¹

### Step 3: æå–å“åº”
- **ä¸€ä¸€å¯¹åº”**ï¼šæ¯æ¡æ‹›æ ‡è¦æ±‚å¯¹åº”ä¸€æ¡å“åº”
- **ç»´åº¦åŒ¹é…**ï¼šå“åº”çš„dimensionå¿…é¡»ä¸æ‹›æ ‡è¦æ±‚ä¸€è‡´
- **norm_keyåŒ¹é…**ï¼šå¦‚æœæ‹›æ ‡è¦æ±‚æœ‰norm_keyï¼Œå“åº”çš„_norm_keyå¿…é¡»ç›¸åŒ
- **ä¿ç•™ç¬¦å·**ï¼šæŠ•æ ‡æ–‡æ¡£ä¸­çš„â–²â˜…â—â€»ç¬¦å·å¿…é¡»ä¿ç•™åœ¨response_textä¸­

### Step 4: è´¨é‡æ£€æŸ¥
- å“åº”æ•°é‡æ˜¯å¦è¦†ç›–å¤§éƒ¨åˆ†æ‹›æ ‡è¦æ±‚ï¼ˆ80%-120%ï¼‰
- æ¯æ¡å“åº”æ˜¯å¦æœ‰evidence_segment_ids
- æ¯æ¡å“åº”æ˜¯å¦æœ‰_norm_keyå­—æ®µï¼ˆå³ä½¿ä¸ºnullï¼‰
- dimensionåˆ†ç±»æ˜¯å¦æ­£ç¡®

## æ ¸å¿ƒåŸåˆ™

### 1. éœ€æ±‚é©±åŠ¨ï¼ˆæœ€é‡è¦ï¼‰
- âœ… **åªæå–æ‹›æ ‡è¦æ±‚ä¸­æ˜ç¡®éœ€è¦çš„å†…å®¹**
- âœ… **æ‹›æ ‡è¦æ±‚æ²¡æåˆ°çš„ï¼Œä¸è¦ä¸»åŠ¨æå–**ï¼ˆå¦‚ï¼šæ³¨å†Œèµ„æœ¬ã€å…¬å¸åœ°å€ï¼‰
- âœ… **æŒ‰æ‹›æ ‡è¦æ±‚çš„ç»´åº¦å’Œnorm_keyç»„ç»‡å“åº”**

### 2. å®Œæ•´æ€§ä¸ç²¾å‡†æ€§å¹³è¡¡
- **ä¿ç•™å…³é”®ä¿¡æ¯**ï¼šè¯ä¹¦å·ã€æœ‰æ•ˆæœŸã€é¡µç ã€é‡‘é¢ã€æ—¶é—´ç­‰
- **é¿å…å†—ä½™**ï¼šåŒä¸€å†…å®¹ä¸è¦é‡å¤æå–
- **æ–‡æœ¬é•¿åº¦é€‚ä¸­**ï¼šç®€å•è¯ä»¶10-30å­—ï¼Œæ•°å€¼20-50å­—ï¼Œæ–¹æ¡ˆ80-150å­—

### 3. ç‰¹åˆ«å…³æ³¨ç¬¦å·æ ‡è¯† âš ï¸
- **â–² ä¸‰è§’å½¢**ï¼šå®è´¨æ€§æ‰¿è¯ºã€å…³é”®æŒ‡æ ‡ã€é‡è¦è¯æ˜
- **â˜… æ˜Ÿå·**ï¼šé‡ç‚¹å“åº”ã€æ ¸å¿ƒä¼˜åŠ¿
- **â— åœ†ç‚¹**ï¼šå…·ä½“æ‰¿è¯ºæ¡æ¬¾
- **â€» ç‰¹æ®Šç¬¦å·**ï¼šç‰¹åˆ«è¯´æ˜å†…å®¹
- å¸¦ç¬¦å·å†…å®¹å¿…é¡»å®Œæ•´æå–å¹¶ä¿ç•™ç¬¦å·

### 4. ç»´åº¦åŒ¹é…
- **qualificationï¼ˆèµ„æ ¼ï¼‰**ï¼šè¯ç…§ã€èµ„è´¨ã€ä¸šç»©ã€äººå‘˜
- **technicalï¼ˆæŠ€æœ¯ï¼‰**ï¼šå‚æ•°ã€è§„æ ¼ã€æ–¹æ¡ˆ
- **businessï¼ˆå•†åŠ¡ï¼‰**ï¼šè´¨ä¿ã€å”®åã€åŸ¹è®­ã€ä»˜æ¬¾
- **priceï¼ˆä»·æ ¼ï¼‰**ï¼šæ€»ä»·ã€å•ä»·ã€æŠ¥ä»·æ˜ç»†
- **doc_structureï¼ˆæ–‡æ¡£ï¼‰**ï¼šè£…è®¢ã€ç­¾ç« ã€ä»½æ•°
- **schedule_qualityï¼ˆå·¥æœŸï¼‰**ï¼šå·¥æœŸã€è¿›åº¦ã€è´¨é‡
- **otherï¼ˆå…¶ä»–ï¼‰**ï¼šä»…å½“æ— æ³•åˆ†ç±»æ—¶ä½¿ç”¨

## è¾“å‡ºæ ¼å¼

è¿”å›JSONå¯¹è±¡ï¼š
```json
{
  "responses": [
    {
      "response_id": "resp_001",
      "requirement_id": "å¯¹åº”çš„æ‹›æ ‡è¦æ±‚IDï¼ˆä»ä¸Šæ–¹æ¸…å•ä¸­å¤åˆ¶ï¼‰",
      "dimension": "ä¸æ‹›æ ‡è¦æ±‚çš„dimensionä¸€è‡´",
      "response_type": "direct_answer|table_extract|document_ref|promise|missing",
      "response_text": "å“åº”å†…å®¹ï¼ˆä¿ç•™å®Œæ•´ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç¬¦å·æ ‡è¯†ã€è¯ä¹¦å·ã€æœ‰æ•ˆæœŸã€é‡‘é¢ã€æ—¶é—´ã€é¡µç ç­‰ï¼‰",
      "extracted_value_json": {
        "value": "å…·ä½“å€¼",
        "unit": "å•ä½",
        "status": "ç¬¦åˆ|ä¸ç¬¦åˆ|æœªæä¾›|åç¦»"
      },
      "normalized_fields_json": {
        "_norm_key": "ä¸æ‹›æ ‡è¦æ±‚çš„norm_keyä¸€è‡´ï¼ˆå¦‚ï¼štotal_price_cnyã€duration_daysç­‰ï¼‰",
        "total_price_cny": 1560000,
        "duration_days": 90
      },
      "evidence_segment_ids": ["seg_xxx", "seg_yyy"]
    }
  ]
}
```

**âš ï¸ å…³é”®å­—æ®µè¯´æ˜**ï¼š
- `requirement_id`ï¼š**å¿…å¡«**ï¼Œæ ‡è¯†è¯¥å“åº”å¯¹åº”å“ªæ¡æ‹›æ ‡è¦æ±‚
- `dimension`ï¼š**å¿…é¡»ä¸æ‹›æ ‡è¦æ±‚çš„dimensionä¸€è‡´**
- `_norm_key`ï¼š**å¿…é¡»ä¸æ‹›æ ‡è¦æ±‚çš„norm_keyä¸€è‡´**ï¼ˆå¦‚æœæ‹›æ ‡è¦æ±‚æœ‰norm_keyï¼‰
- `evidence_segment_ids`ï¼š**å¿…å¡«**ï¼Œæ ‡è¯†å“åº”å†…å®¹çš„æ¥æºæ®µè½

## ç¤ºä¾‹ï¼ˆå‚è€ƒç†è§£æ–¹å¼ï¼‰

**ç¤ºä¾‹1ï¼šèµ„æ ¼å“åº”ï¼ˆå¯¹åº”æ‹›æ ‡è¦æ±‚ï¼‰**
å‡è®¾æ‹›æ ‡è¦æ±‚ä¸ºï¼š"æŠ•æ ‡äººé¡»å…·å¤‡å»ºç­‘å·¥ç¨‹æ–½å·¥æ€»æ‰¿åŒ…äºŒçº§åŠä»¥ä¸Šèµ„è´¨"
```json
{
  "response_id": "resp_001",
  "requirement_id": "checklist_qualification_003",
  "dimension": "qualification",
  "response_type": "document_ref",
  "response_text": "â–²å»ºç­‘å·¥ç¨‹æ–½å·¥æ€»æ‰¿åŒ…äºŒçº§èµ„è´¨ï¼Œè¯ä¹¦ç¼–å·ï¼šD233012345678ï¼Œæœ‰æ•ˆæœŸè‡³2026å¹´12æœˆ31æ—¥ï¼Œè§é™„ä»¶2èµ„è´¨è¯ä¹¦å¤å°ä»¶ï¼ˆåŠ ç›–å…¬ç« ï¼‰",
  "normalized_fields_json": {
    "_norm_key": "doc_qualification_present",
    "doc_qualification_present": true
  },
  "evidence_segment_ids": ["seg_012", "seg_013"]
}
```

**ç¤ºä¾‹2ï¼šå·¥æœŸå“åº”ï¼ˆåŒ¹é…norm_keyï¼‰**
å‡è®¾æ‹›æ ‡è¦æ±‚ä¸ºï¼š"å·¥æœŸä¸è¶…è¿‡90å¤©"ï¼Œnorm_keyä¸º`duration_days`
```json
{
  "response_id": "resp_002",
  "requirement_id": "checklist_schedule_001",
  "dimension": "schedule_quality",
  "response_type": "direct_answer",
  "response_text": "æ‰¿è¯ºå·¥æœŸ90ä¸ªæ—¥å†å¤©ï¼Œè‡ªåˆåŒç­¾è®¢ä¹‹æ—¥èµ·è®¡ç®—ï¼Œè§æŠ¥ä»·æ–‡ä»¶ç¬¬3é¡µ",
  "normalized_fields_json": {
    "_norm_key": "duration_days",
    "duration_days": 90
  },
  "evidence_segment_ids": ["seg_045"]
}
```

**ç¤ºä¾‹3ï¼šä»·æ ¼å“åº”ï¼ˆåŒ¹é…norm_keyï¼‰**
å‡è®¾æ‹›æ ‡è¦æ±‚ä¸ºï¼š"æŠ•æ ‡æŠ¥ä»·"ï¼Œnorm_keyä¸º`total_price_cny`
```json
{
  "response_id": "resp_003",
  "requirement_id": "checklist_price_001",
  "dimension": "price",
  "response_type": "direct_answer",
  "response_text": "æŠ•æ ‡æ€»ä»·ï¼šäººæ°‘å¸36,799,949.77å…ƒï¼ˆå¤§å†™ï¼šåä»Ÿé™†ä½°æŸ’æ‹¾ç–ä¸‡ç–ä»Ÿç–ä½°è‚†æ‹¾ç–å…ƒæŸ’è§’æŸ’åˆ†ï¼‰ï¼Œè§å¼€æ ‡ä¸€è§ˆè¡¨",
  "normalized_fields_json": {
    "_norm_key": "total_price_cny",
    "total_price_cny": 36799949.77
  },
  "evidence_segment_ids": ["seg_089"]
}
```

## æœ€ç»ˆæ£€æŸ¥

æå–å®Œæˆåï¼Œè¯·è‡ªæ£€ï¼š
1. âœ… **æ¯æ¡å“åº”æ˜¯å¦éƒ½æœ‰requirement_id**ï¼Ÿï¼ˆæ ‡è¯†å¯¹åº”çš„æ‹›æ ‡è¦æ±‚ï¼‰
2. âœ… **å“åº”æ•°é‡æ˜¯å¦ä¸æ‹›æ ‡è¦æ±‚æ•°é‡æ¥è¿‘**ï¼Ÿï¼ˆ80%-120%è¦†ç›–ç‡ï¼‰
3. âœ… **dimensionå’Œnorm_keyæ˜¯å¦ä¸æ‹›æ ‡è¦æ±‚ä¸€è‡´**ï¼Ÿ
4. âœ… æ‰€æœ‰å¸¦ç‰¹æ®Šç¬¦å·ï¼ˆâ–²â˜…â—â€»ç­‰ï¼‰çš„æ‹›æ ‡è¦æ±‚éƒ½æœ‰å“åº”å—ï¼Ÿ
5. âœ… response_textæ˜¯å¦åŒ…å«è¶³å¤Ÿä¿¡æ¯ï¼ˆè¯ä¹¦å·ã€æœ‰æ•ˆæœŸã€é¡µç ã€é‡‘é¢ã€æ—¶é—´ç­‰ï¼‰ï¼Ÿ
6. âœ… æ¯æ¡å“åº”æ˜¯å¦éƒ½æœ‰evidence_segment_idsï¼Ÿ
7. âœ… æ˜¯å¦é¿å…äº†æå–æ‹›æ ‡æ–‡ä»¶æœªè¦æ±‚çš„ä¿¡æ¯ï¼ˆå¦‚æ³¨å†Œèµ„æœ¬ã€åœ°å€ç­‰ï¼‰ï¼Ÿ

---

**ä¸‹æ–¹å°†æä¾›æ‹›æ ‡è¦æ±‚æ¸…å•å’Œæå–æŒ‡å—ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æ‹›æ ‡è¦æ±‚é€æ¡æå–å“åº”ã€‚**
"""


def _generate_targeted_queries(
    requirements: List[Dict[str, Any]], 
    extraction_guide: Dict[str, Any]
) -> Dict[str, str]:
    """
    ç”Ÿæˆé’ˆå¯¹æ€§æ£€ç´¢æŸ¥è¯¢
    
    åªä¸ºrequirementsä¸­å‡ºç°çš„ç»´åº¦ç”ŸæˆæŸ¥è¯¢ï¼Œé¿å…æ— ç”¨æ£€ç´¢
    
    Args:
        requirements: æ‹›æ ‡è¦æ±‚åˆ—è¡¨
        extraction_guide: æå–æŒ‡å—
    
    Returns:
        æŸ¥è¯¢å­—å…¸ {query_key: query_string}
    """
    queries = {}
    
    # 1. ç»Ÿè®¡requirementsä¸­çš„ç»´åº¦
    dimensions_in_requirements = set()
    for req in requirements:
        dim = req.get("dimension", "")
        if dim and dim != "out_of_scope":
            dimensions_in_requirements.add(dim)
    
    logger.info(f"Dimensions in requirements: {dimensions_in_requirements}")
    
    # 2. ä¸ºæ¯ä¸ªç»´åº¦ç”Ÿæˆå¢å¼ºçš„æŸ¥è¯¢
    dimension_focus = extraction_guide.get("dimension_focus", {})
    
    for dimension in dimensions_in_requirements:
        focus = dimension_focus.get(dimension, {})
        keywords = focus.get("focus_keywords", [])
        
        # åŸºç¡€æŸ¥è¯¢è¯
        base_queries = {
            "qualification": "æŠ•æ ‡äººèµ„æ ¼ å…¬å¸èµ„è´¨ è¥ä¸šæ‰§ç…§ èµ„è´¨è¯ä¹¦ ä¸šç»©è¯æ˜ é¡¹ç›®ç»éªŒ äººå‘˜é…ç½® è´¢åŠ¡çŠ¶å†µ",
            "technical": "æŠ€æœ¯å‚æ•° æŠ€æœ¯è§„æ ¼ è®¾å¤‡é…ç½® æ€§èƒ½æŒ‡æ ‡ æŠ€æœ¯æ–¹æ¡ˆ æŠ€æœ¯å“åº”",
            "business": "å•†åŠ¡å“åº” è´¨ä¿æœŸ å”®åæœåŠ¡ ä»˜æ¬¾æ¡ä»¶ éªŒæ”¶æ ‡å‡† åŸ¹è®­è®¡åˆ’",
            "price": "æŠ•æ ‡æŠ¥ä»· æŠ¥ä»·è¡¨ æŠ•æ ‡æ€»ä»· ä»·æ ¼æ˜ç»† æŠ¥ä»·æ±‡æ€» å¼€æ ‡ä¸€è§ˆè¡¨",
            "doc_structure": "æŠ•æ ‡æ–‡ä»¶ æ–‡ä»¶æ ¼å¼ è£…è®¢è¦æ±‚ ç­¾å­—ç›–ç«  æ­£æœ¬å‰¯æœ¬",
            "schedule_quality": "å·¥æœŸæ‰¿è¯º æ–½å·¥è¿›åº¦ è´¨é‡ä¿è¯ éªŒæ”¶æ ‡å‡† é‡Œç¨‹ç¢‘è®¡åˆ’",
            "evaluation": "è¯„åˆ†å“åº” è¯„åˆ†è¯´æ˜",
        }
        
        base_query = base_queries.get(dimension, dimension)
        
        # å¦‚æœæœ‰focuså…³é”®è¯ï¼Œè¿½åŠ åˆ°æŸ¥è¯¢ä¸­
        if keywords:
            enhanced_query = base_query + " " + " ".join(keywords)
        else:
            enhanced_query = base_query
        
        queries[dimension] = enhanced_query
    
    # 3. ä¸ºå¿…é¡»æå–çš„norm_keysæ·»åŠ ä¸“é—¨æŸ¥è¯¢
    must_extract_keys = extraction_guide.get("must_extract_norm_keys", [])
    
    norm_key_queries = {
        "total_price_cny": "æŠ•æ ‡æŠ¥ä»· æŠ•æ ‡æ€»ä»· æŠ¥ä»·è¡¨ å¼€æ ‡ä¸€è§ˆè¡¨ æŠ¥ä»·æ±‡æ€»",
        "duration_days": "å·¥æœŸ å·¥æœŸæ‰¿è¯º æ–½å·¥å‘¨æœŸ å®ŒæˆæœŸé™",
        "warranty_months": "è´¨ä¿æœŸ ä¿ä¿®æœŸ è´¨é‡ä¿è¯æœŸ",
        "bid_security_amount_cny": "æŠ•æ ‡ä¿è¯é‡‘ ä¿è¯é‡‘é‡‘é¢ ä¿è¯é‡‘ç¼´çº³",
        "company_name": "æŠ•æ ‡äºº å…¬å¸åç§° æŠ•æ ‡å•ä½",
    }
    
    for norm_key in must_extract_keys:
        if norm_key in norm_key_queries:
            query_key = f"norm_key_{norm_key}"
            queries[query_key] = norm_key_queries[norm_key]
    
    logger.info(f"Generated {len(queries)} targeted queries")
    
    return queries

