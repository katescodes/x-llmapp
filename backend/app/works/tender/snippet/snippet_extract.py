"""
æ ¼å¼èŒƒæœ¬æå–æœåŠ¡
æ•´åˆæ–‡æ¡£è§£æã€ç« èŠ‚å®šä½ã€LLMè¯†åˆ«ï¼Œå®Œæˆç«¯åˆ°ç«¯æå–
"""
from __future__ import annotations
import logging
import uuid
from typing import List, Dict, Any, Optional

from app.works.tender.snippet.doc_blocks import extract_blocks, blocks_to_text
from app.works.tender.snippet.snippet_locator import locate_format_chapter
from app.works.tender.snippet.snippet_llm import (
    detect_snippets,
    validate_snippet_bounds,
    slice_blocks
)

logger = logging.getLogger(__name__)


async def extract_format_snippets(
    file_path: str,
    project_id: str,
    source_file_id: Optional[str] = None,
    model_id: str = "gpt-oss-120b"
) -> List[Dict[str, Any]]:
    """
    ä»æ‹›æ ‡æ–‡ä»¶ä¸­æå–æ ¼å¼èŒƒæœ¬
    
    å®Œæ•´æµç¨‹ï¼š
    1. æ–‡æ¡£ -> blocks
    2. å®šä½"æ ¼å¼èŒƒæœ¬"ç« èŠ‚
    3. LLM è¯†åˆ«å„ä¸ªèŒƒæœ¬è¾¹ç•Œ
    4. åˆ‡ç‰‡å¹¶è¿”å›
    
    Args:
        file_path: æ‹›æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆ.docx æˆ– .pdfï¼‰
        project_id: é¡¹ç›® ID
        source_file_id: æ¥æºæ–‡ä»¶ ID
        model_id: LLM æ¨¡å‹ ID
        
    Returns:
        æå–çš„èŒƒæœ¬åˆ—è¡¨
    """
    logger.info(f"å¼€å§‹æå–æ ¼å¼èŒƒæœ¬: file={file_path}, project={project_id}")
    
    # 1. æå–æ–‡æ¡£ blocks
    try:
        all_blocks = extract_blocks(file_path)
        logger.info(f"æ–‡æ¡£ blocks æå–å®Œæˆ: {len(all_blocks)} ä¸ªå—")
    except Exception as e:
        logger.error(f"æ–‡æ¡£ blocks æå–å¤±è´¥: {e}")
        raise ValueError(f"æ–‡æ¡£è§£æå¤±è´¥: {str(e)}")
    
    if not all_blocks:
        raise ValueError("æ–‡æ¡£ä¸ºç©ºï¼Œæ— æ³•æå–èŒƒæœ¬")
    
    # 2. ç­–ç•¥ï¼šä¼˜å…ˆå®šä½"æ ¼å¼èŒƒæœ¬"ç« èŠ‚ï¼Œæ‰¾ä¸åˆ°åˆ™å…¨æ–‡æ‰«æ
    chapter_blocks = None
    try:
        chapter_blocks = locate_format_chapter(all_blocks)
        if chapter_blocks and len(chapter_blocks) > 10:  # è‡³å°‘æœ‰10ä¸ªå—æ‰ç®—æœ‰æ•ˆ
            logger.info(f"âœ… å®šä½åˆ°æ ¼å¼ç« èŠ‚: {len(chapter_blocks)} ä¸ªå— ({len(chapter_blocks)/len(all_blocks)*100:.1f}%)")
        else:
            logger.warning(f"âš ï¸ æ ¼å¼ç« èŠ‚å¤ªå°ï¼ˆ{len(chapter_blocks) if chapter_blocks else 0}å—ï¼‰ï¼Œæ”¹ç”¨å…¨æ–‡æ‰«æ")
            chapter_blocks = None
    except Exception as e:
        logger.warning(f"æ ¼å¼ç« èŠ‚å®šä½å¤±è´¥: {e}")
        chapter_blocks = None
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ¼å¼ç« èŠ‚ï¼Œä½¿ç”¨å…¨æ–‡
    if not chapter_blocks:
        logger.info("ğŸ“– ä½¿ç”¨å…¨æ–‡æ‰«ææ¨¡å¼ï¼ˆæ›´å…¨é¢ï¼Œä½†å¯èƒ½è¯†åˆ«åˆ°éèŒƒæ–‡å†…å®¹ï¼‰")
        chapter_blocks = all_blocks
    
    # 3. LLM è¯†åˆ«èŒƒæœ¬è¾¹ç•Œ
    try:
        snippet_spans = detect_snippets(chapter_blocks, model_id=model_id)
        logger.info(f"LLM è¯†åˆ«å®Œæˆ: {len(snippet_spans)} ä¸ªèŒƒæœ¬")
    except Exception as e:
        logger.error(f"LLM è¯†åˆ«å¤±è´¥: {e}")
        raise ValueError(f"èŒƒæœ¬è¯†åˆ«å¤±è´¥: {str(e)}")
    
    if not snippet_spans:
        # å¦‚æœç¬¬ä¸€æ¬¡æ²¡è¯†åˆ«åˆ°ï¼Œä¸”ä¹‹å‰æ˜¯ç”¨æ ¼å¼ç« èŠ‚ï¼Œåˆ™å°è¯•å…¨æ–‡
        if chapter_blocks != all_blocks:
            logger.warning("æ ¼å¼ç« èŠ‚æœªè¯†åˆ«åˆ°èŒƒæœ¬ï¼Œå°è¯•å…¨æ–‡æ‰«æ...")
            try:
                snippet_spans = detect_snippets(all_blocks, model_id=model_id)
                logger.info(f"å…¨æ–‡æ‰«æè¯†åˆ«å®Œæˆ: {len(snippet_spans)} ä¸ªèŒƒæœ¬")
                chapter_blocks = all_blocks  # åˆ‡æ¢åˆ°å…¨æ–‡æ¨¡å¼
            except Exception as e2:
                logger.error(f"å…¨æ–‡æ‰«æä¹Ÿå¤±è´¥: {e2}")
    
    if not snippet_spans:
        raise ValueError("æœªè¯†åˆ«åˆ°ä»»ä½•æ ¼å¼èŒƒæœ¬ï¼Œè¯·æ£€æŸ¥æ–‡æ¡£å†…å®¹")
    
    # 4. éªŒè¯å¹¶åˆ‡ç‰‡
    snippets = []
    for span in snippet_spans:
        # éªŒè¯è¾¹ç•Œ
        if not validate_snippet_bounds(span, chapter_blocks):
            logger.warning(f"è·³è¿‡æ— æ•ˆèŒƒæœ¬: {span.get('title')}")
            continue
        
        # åˆ‡ç‰‡ blocks
        snippet_blocks = slice_blocks(
            chapter_blocks,
            span["startBlockId"],
            span["endBlockId"]
        )
        
        if not snippet_blocks:
            logger.warning(f"èŒƒæœ¬åˆ‡ç‰‡å¤±è´¥: {span.get('title')}")
            continue
        
        # âœ¨ è¿‡æ»¤ç›®å½•é¡¹ï¼šå¦‚æœæ‰€æœ‰å—éƒ½æ˜¯TOCæ ·å¼ï¼Œåˆ™è·³è¿‡
        toc_blocks = [b for b in snippet_blocks if 'toc' in b.get('styleName', '').lower()]
        if len(toc_blocks) == len(snippet_blocks):
            logger.warning(f"è·³è¿‡ç›®å½•é¡¹: {span.get('title')} (å…¨éƒ¨ä¸ºTOCæ ·å¼)")
            continue
        
        # å¦‚æœå¤§éƒ¨åˆ†æ˜¯TOCï¼ˆ>80%ï¼‰ï¼Œä¹Ÿè·³è¿‡
        if len(toc_blocks) > len(snippet_blocks) * 0.8:
            logger.warning(f"è·³è¿‡ç›®å½•é¡¹: {span.get('title')} ({len(toc_blocks)}/{len(snippet_blocks)} ä¸ºTOC)")
            continue
        
        # æ„å»ºèŒƒæœ¬è®°å½•
        # ä½¿ç”¨ project_id + source_file_id + start_block_id + end_block_id ç”Ÿæˆç¡®å®šæ€§ID
        # ç¡®ä¿å³ä½¿åŒä¸€ä¸ªé¡¹ç›®æœ‰å¤šä¸ªç›¸åŒnorm_keyçš„èŒƒæœ¬ï¼Œä¹Ÿä¸ä¼šå†²çª
        import hashlib
        id_string = f"{project_id}_{source_file_id or file_path}_{span['startBlockId']}_{span['endBlockId']}"
        deterministic_id = hashlib.md5(id_string.encode()).hexdigest()[:16]
        
        # æå–çº¯æ–‡æœ¬å†…å®¹
        content_text = blocks_to_text(snippet_blocks, include_tables=True)
        
        snippet = {
            "id": f"snip_{deterministic_id}",
            "project_id": project_id,
            "source_file_id": source_file_id or file_path,
            "norm_key": span["norm_key"],
            "title": span["title"],
            "start_block_id": span["startBlockId"],
            "end_block_id": span["endBlockId"],
            "blocks_json": snippet_blocks,
            "content_text": content_text,
            "suggest_outline_titles": span.get("suggestOutlineTitles", []),
            "confidence": span.get("confidence", 0.5)
        }
        
        snippets.append(snippet)
        logger.info(f"èŒƒæœ¬æå–æˆåŠŸ: {snippet['title']} ({len(snippet_blocks)} blocks, {len(content_text)} chars)")
    
    logger.info(f"æ ¼å¼èŒƒæœ¬æå–å®Œæˆ: {len(snippets)} ä¸ªæœ‰æ•ˆèŒƒæœ¬")
    return snippets


def clean_duplicate_snippets(project_id: str, db_pool) -> int:
    """
    æ¸…ç†é¡¹ç›®ä¸­çš„é‡å¤èŒƒæ–‡ï¼ˆä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„ï¼‰
    
    æŒ‰ (project_id, source_file_id, start_block_id, end_block_id) å»é‡
    åªæœ‰å®Œå…¨ç›¸åŒä½ç½®çš„èŒƒæœ¬æ‰ä¼šè¢«è®¤ä¸ºæ˜¯é‡å¤çš„
    
    Args:
        project_id: é¡¹ç›®ID
        db_pool: æ•°æ®åº“è¿æ¥æ± 
        
    Returns:
        åˆ é™¤çš„é‡å¤èŒƒæ–‡æ•°é‡
    """
    logger.info(f"å¼€å§‹æ¸…ç†é¡¹ç›®é‡å¤èŒƒæ–‡: project={project_id}")
    
    with db_pool.connection() as conn:
        with conn.cursor() as cur:
            # æ‰¾å‡ºé‡å¤çš„èŒƒæ–‡ï¼ˆåŒä¸€æ–‡ä»¶çš„ç›¸åŒä½ç½®ï¼‰
            cur.execute("""
                WITH ranked_snippets AS (
                    SELECT 
                        id,
                        source_file_id,
                        start_block_id,
                        end_block_id,
                        confidence,
                        ROW_NUMBER() OVER (
                            PARTITION BY project_id, source_file_id, start_block_id, end_block_id
                            ORDER BY confidence DESC, created_at DESC
                        ) as rn
                    FROM tender_format_snippets
                    WHERE project_id = %s
                )
                DELETE FROM tender_format_snippets
                WHERE id IN (
                    SELECT id FROM ranked_snippets WHERE rn > 1
                )
            """, (project_id,))
            
            deleted_count = cur.rowcount
            conn.commit()
            
            logger.info(f"æ¸…ç†å®Œæˆ: åˆ é™¤äº† {deleted_count} ä¸ªé‡å¤èŒƒæ–‡")
            return deleted_count


def save_snippets_to_db(snippets: List[Dict[str, Any]], db_pool) -> int:
    """
    å°†èŒƒæœ¬ä¿å­˜åˆ°æ•°æ®åº“
    
    Args:
        snippets: èŒƒæœ¬åˆ—è¡¨
        db_pool: æ•°æ®åº“è¿æ¥æ± 
        
    Returns:
        ä¿å­˜çš„èŒƒæœ¬æ•°é‡
    """
    import json
    import psycopg
    
    if not snippets:
        return 0
    
    logger.info(f"å¼€å§‹ä¿å­˜èŒƒæœ¬åˆ°æ•°æ®åº“: {len(snippets)} ä¸ª")
    
    saved_count = 0
    with db_pool.connection() as conn:
        with conn.cursor() as cur:
            for i, snippet in enumerate(snippets, 1):
                try:
                    logger.info(f"  [{i}/{len(snippets)}] ä¿å­˜: {snippet['title']} (id={snippet['id']}, start={snippet['start_block_id']}, end={snippet['end_block_id']})")
                    
                    # ç¡®ä¿ suggest_outline_titles æ˜¯åˆ—è¡¨
                    suggest_titles = snippet.get("suggest_outline_titles", [])
                    if not isinstance(suggest_titles, list):
                        suggest_titles = []
                    
                    cur.execute(
                        """
                        INSERT INTO tender_format_snippets (
                            id, project_id, source_file_id, norm_key, title,
                            start_block_id, end_block_id, blocks_json, content_text,
                            suggest_outline_titles, confidence
                        ) VALUES (
                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                        )
                        ON CONFLICT (id) DO UPDATE SET
                            content_text = EXCLUDED.content_text,
                            updated_at = CURRENT_TIMESTAMP
                        """,
                        (
                            snippet["id"],
                            snippet["project_id"],
                            snippet["source_file_id"],
                            snippet["norm_key"],
                            snippet["title"],
                            snippet["start_block_id"],
                            snippet["end_block_id"],
                            json.dumps(snippet["blocks_json"], ensure_ascii=False),
                            snippet.get("content_text", ""),
                            suggest_titles,  # PostgreSQL ä¼šè‡ªåŠ¨å¤„ç† Python åˆ—è¡¨åˆ° TEXT[] çš„è½¬æ¢
                            snippet["confidence"]
                        )
                    )
                    saved_count += 1
                except Exception as e:
                    logger.error(f"ä¿å­˜èŒƒæœ¬å¤±è´¥: {snippet['title']}, {e}")
            
            conn.commit()
    
    logger.info(f"èŒƒæœ¬ä¿å­˜å®Œæˆ: {saved_count}/{len(snippets)}")
    return saved_count


def get_snippets_by_project(project_id: str, db_pool) -> List[Dict[str, Any]]:
    """
    è·å–é¡¹ç›®çš„æ‰€æœ‰æ ¼å¼èŒƒæœ¬
    
    Args:
        project_id: é¡¹ç›® ID
        db_pool: æ•°æ®åº“è¿æ¥æ± 
        
    Returns:
        èŒƒæœ¬åˆ—è¡¨
    """
    import json
    
    with db_pool.connection() as conn:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT 
                    id, project_id, source_file_id, norm_key, title,
                    start_block_id, end_block_id, blocks_json, content_text,
                    suggest_outline_titles, confidence, created_at
                FROM tender_format_snippets
                WHERE project_id = %s
                ORDER BY created_at DESC
                """,
                (project_id,)
            )
            
            rows = cur.fetchall()
            
            snippets = []
            for i, row in enumerate(rows):
                try:
                    print(f"Processing row {i}: id={row.get('id')}")
                    
                    # å¤„ç† suggest_outline_titles - PostgreSQL TEXT[] ç›´æ¥è¿”å›ä¸º Python åˆ—è¡¨
                    suggest_titles = row.get('suggest_outline_titles')
                    print(f"  suggest_titles type: {type(suggest_titles)}, value: {suggest_titles}")
                    if suggest_titles is None:
                        suggest_titles = []
                    elif not isinstance(suggest_titles, list):
                        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢
                        if isinstance(suggest_titles, str):
                            try:
                                suggest_titles = json.loads(suggest_titles)
                            except:
                                suggest_titles = []
                        else:
                            suggest_titles = []
                    
                    # å¤„ç† blocks_json - PostgreSQL JSONB ç›´æ¥è¿”å›ä¸º Python å¯¹è±¡
                    blocks = row.get('blocks_json')
                    print(f"  blocks type: {type(blocks)}, len: {len(blocks) if isinstance(blocks, list) else 'N/A'}")
                    if blocks is None:
                        blocks = []
                    elif not isinstance(blocks, list):
                        # å¦‚æœä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢
                        if isinstance(blocks, str):
                            try:
                                blocks = json.loads(blocks)
                            except:
                                blocks = []
                        else:
                            blocks = []
                    
                    # å¤„ç† created_at
                    created_at = row.get('created_at')
                    if created_at:
                        try:
                            if hasattr(created_at, 'isoformat'):
                                created_at = created_at.isoformat()
                            else:
                                created_at = str(created_at)
                        except Exception as e:
                            print(f"Warning: Failed to convert created_at: {e}")
                            created_at = None
                    
                    snippet_dict = {
                    "id": row['id'],
                    "project_id": row['project_id'],
                    "source_file_id": row['source_file_id'],
                    "norm_key": row['norm_key'],
                    "title": row['title'],
                    "start_block_id": row['start_block_id'],
                    "end_block_id": row['end_block_id'],
                        "blocks_json": blocks,
                        "content_text": row.get('content_text', ''),
                        "suggest_outline_titles": suggest_titles,
                    "confidence": row['confidence'],
                        "created_at": created_at
                    }
                    print(f"  Created snippet dict successfully")
                    snippets.append(snippet_dict)
                except Exception as e:
                    print(f"Error processing row {row.get('id')}: {e}")
                    import traceback
                    traceback.print_exc()
                    raise
            
            print(f"Returning {len(snippets)} snippets")
            return snippets


def get_snippet_by_id(snippet_id: str, db_pool) -> Optional[Dict[str, Any]]:
    """
    æ ¹æ® ID è·å–èŒƒæœ¬è¯¦æƒ…
    
    Args:
        snippet_id: èŒƒæœ¬ ID
        db_pool: æ•°æ®åº“è¿æ¥æ± 
        
    Returns:
        èŒƒæœ¬è¯¦æƒ…ï¼ˆåŒ…å«å®Œæ•´ blocks_jsonï¼‰
    """
    import json
    
    with db_pool.connection() as conn:
        with conn.cursor() as cur:
            cur.execute(
                """
                SELECT 
                    id, project_id, source_file_id, norm_key, title,
                    start_block_id, end_block_id, blocks_json, content_text,
                    suggest_outline_titles, confidence, created_at
                FROM tender_format_snippets
                WHERE id = %s
                """,
                (snippet_id,)
            )
            
            row = cur.fetchone()
            if not row:
                return None
            
            # å¤„ç† suggest_outline_titles - PostgreSQL TEXT[] ç›´æ¥è¿”å›ä¸º Python åˆ—è¡¨
            suggest_titles = row.get('suggest_outline_titles')
            if suggest_titles is None:
                suggest_titles = []
            elif not isinstance(suggest_titles, list):
                if isinstance(suggest_titles, str):
                    try:
                        suggest_titles = json.loads(suggest_titles)
                    except:
                        suggest_titles = []
                else:
                    suggest_titles = []
            
            # å¤„ç† blocks_json - PostgreSQL JSONB ç›´æ¥è¿”å›ä¸º Python å¯¹è±¡
            blocks = row.get('blocks_json')
            if blocks is None:
                blocks = []
            elif not isinstance(blocks, list):
                if isinstance(blocks, str):
                    try:
                        blocks = json.loads(blocks)
                    except:
                        blocks = []
                else:
                    blocks = []
            
            return {
                "id": row['id'],
                "project_id": row['project_id'],
                "source_file_id": row['source_file_id'],
                "norm_key": row['norm_key'],
                "title": row['title'],
                "start_block_id": row['start_block_id'],
                "end_block_id": row['end_block_id'],
                "blocks_json": blocks,
                "content_text": row.get('content_text', ''),
                "suggest_outline_titles": suggest_titles,
                "confidence": row['confidence'],
                "created_at": row['created_at'].isoformat() if row.get('created_at') else None
            }

