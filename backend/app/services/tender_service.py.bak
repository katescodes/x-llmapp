"""
招投标应用 - 业务逻辑层 (Service)
包含 LLM 调用、文件解析、规则抽取、审核叠加等核心逻辑
"""
from __future__ import annotations

import hashlib
import json
import os
import re
import uuid
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

from docx import Document
from fastapi import UploadFile

from app.services.dao.tender_dao import TenderDAO


# ==================== 工具函数 ====================

def _safe_mkdir(p: str):
    """安全创建目录"""
    os.makedirs(p, exist_ok=True)


def _sha256(b: bytes) -> str:
    """计算SHA256哈希"""
    return hashlib.sha256(b).hexdigest()


def _extract_json(text: str) -> Any:
    """
    从 LLM 输出中容错提取 JSON
    支持 markdown code fence 包裹的 JSON
    """
    if not text:
        raise ValueError("empty llm output")
    
    # 尝试提取 markdown code fence 中的内容
    m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", text, re.IGNORECASE)
    if m:
        text = m.group(1).strip()
    
    # 尝试提取第一个 JSON 对象或数组
    m2 = re.search(r"(\{[\s\S]*\}|\[[\s\S]*\])", text.strip())
    if m2:
        text = m2.group(1)
    
    return json.loads(text)


def _chunk_text(text: str, max_chars: int = 1200, overlap: int = 150) -> List[str]:
    """
    将文本分块
    
    Args:
        text: 原始文本
        max_chars: 每块最大字符数
        overlap: 重叠字符数
    
    Returns:
        文本块列表
    """
    text = (text or "").strip()
    if not text:
        return []
    
    out = []
    i = 0
    n = len(text)
    while i < n:
        j = min(n, i + max_chars)
        out.append(text[i:j])
        if j >= n:
            break
        i = max(0, j - overlap)
    return out


def _read_text_from_file_bytes(filename: str, data: bytes) -> str:
    """
    从文件字节中读取文本
    支持 txt/md/pdf/docx 格式
    """
    name = (filename or "").lower()
    
    # TXT/MD 文件
    if name.endswith(".txt") or name.endswith(".md"):
        try:
            return data.decode("utf-8", errors="ignore")
        except Exception:
            return data.decode(errors="ignore")
    
    # PDF 文件
    if name.endswith(".pdf"):
        try:
            from pypdf import PdfReader
            import io
            reader = PdfReader(io.BytesIO(data))
            parts = []
            for page in reader.pages:
                parts.append(page.extract_text() or "")
            return "\n".join(parts)
        except Exception:
            return ""
    
    # DOCX 文件
    if name.endswith(".docx"):
        try:
            import io
            from docx import Document as Doc
            d = Doc(io.BytesIO(data))
            return "\n".join([p.text for p in d.paragraphs if p.text])
        except Exception:
            return ""
    
    # 兜底：尝试 UTF-8 解码
    try:
        return data.decode("utf-8", errors="ignore")
    except Exception:
        return ""


def _build_marked_context(chunks: List[Dict[str, Any]]) -> str:
    """
    将 chunks 构建成带标记的上下文
    用于 LLM 能够引用 chunk_id
    """
    parts = []
    for c in chunks:
        parts.append(f"[DOC {c.get('doc_id')} CHUNK {c.get('chunk_id')} POS {c.get('position')}]")
        parts.append(c.get("content") or "")
        parts.append("")  # 空行
    return "\n".join(parts).strip()


# ==================== LLM 调用数据结构 ====================

@dataclass
class LLMCall:
    """LLM 调用参数"""
    model_id: Optional[str]
    messages: List[Dict[str, str]]


# ==================== Service 主类 ====================

class TenderService:
    """招投标业务逻辑服务"""

    def __init__(self, dao: TenderDAO, llm_orchestrator: Any):
        """
        初始化 Service
        
        Args:
            dao: TenderDAO 实例
            llm_orchestrator: LLM 调度器（duck typing）
        """
        self.dao = dao
        self.llm = llm_orchestrator

    # ==================== LLM 调用（Duck Typing） ====================

    async def _llm_text(self, call: LLMCall) -> str:
        """
        调用 LLM 并返回文本
        使用 duck typing 兼容多种 orchestrator 接口
        """
        if not self.llm:
            raise RuntimeError("LLM orchestrator not available")

        # 尝试常见的方法名
        for method_name in ("chat", "complete", "generate", "run", "ask"):
            fn = getattr(self.llm, method_name, None)
            if not fn:
                continue
            
            try:
                # 尝试 (messages, model_id) 签名
                res = await fn(messages=call.messages, model_id=call.model_id)
                
                # 处理返回值
                if isinstance(res, str):
                    return res
                if isinstance(res, dict):
                    # 尝试常见的键
                    for k in ("content", "text", "output"):
                        if k in res and isinstance(res[k], str):
                            return res[k]
                    # OpenAI-like 格式
                    if "choices" in res and res["choices"]:
                        ch = res["choices"][0]
                        if isinstance(ch, dict):
                            msg = ch.get("message") or {}
                            if isinstance(msg, dict) and isinstance(msg.get("content"), str):
                                return msg["content"]
                # 兜底
                return str(res)
            
            except TypeError:
                # 尝试 (prompt, model_id) 签名
                try:
                    prompt = "\n".join([f"{m['role']}: {m['content']}" for m in call.messages])
                    res = await fn(prompt=prompt, model_id=call.model_id)
                    return res if isinstance(res, str) else str(res)
                except Exception:
                    continue
            except Exception:
                continue

        raise RuntimeError("No compatible LLM method found on orchestrator")

    # ==================== LLM Prompts ====================

    PROJECT_INFO_PROMPT = """
你是招投标助手。请从"招标文件原文片段"中抽取项目信息，并输出严格 JSON：
{
  "data": {
    "projectName": "项目名称",
    "ownerName": "招标人/业主",
    "agencyName": "代理机构",
    "bidDeadline": "投标截止时间",
    "bidOpeningTime": "开标时间",
    "budget": "预算金额",
    "maxPrice": "最高限价",
    "bidBond": "投标保证金",
    "schedule": "工期要求",
    "quality": "质量要求",
    "location": "项目地点",
    "contact": "联系方式"
  },
  "evidence_chunk_ids": ["chunk_xxx", "chunk_yyy"]
}

要求：
- data 里的字段可以为空字符串，但必须是对象
- 时间尽量输出 ISO 字符串或原文格式
- evidence_chunk_ids 必须来自上下文标记中的 CHUNK id，且尽量覆盖关键字段的来源
- 不要输出除 JSON 以外的任何文字
"""

    RISK_PROMPT = """
你是招投标助手。请从"招标文件原文片段"中识别风险与注意事项，输出严格 JSON 数组：
[
  {
    "risk_type": "mustReject",  // 或 "other"
    "title": "风险标题",
    "description": "详细描述",
    "suggestion": "建议措施",
    "severity": "critical",  // low, medium, high, critical
    "tags": ["资格", "保证金"],
    "evidence_chunk_ids": ["chunk_xxx"]
  }
]

要求：
- mustReject：缺关键资质/未按要求签章/保证金/格式性废标等"必废标"点
- other：易错点、扣分点、时间节点、装订/份数/密封等注意事项
- evidence_chunk_ids 必须来自上下文 CHUNK id
- 不要输出除 JSON 以外的任何文字
"""

    DIRECTORY_PROMPT = """
你是招投标助手。请根据"招标文件原文片段"生成投标文件目录结构，输出严格 JSON 数组：
[
  {
    "numbering": "1",
    "level": 1,
    "title": "投标函",
    "required": true,
    "notes": "可选备注",
    "evidence_chunk_ids": ["chunk_xxx"]
  },
  {
    "numbering": "1.1",
    "level": 2,
    "title": "投标函附录",
    "required": true,
    "notes": "",
    "evidence_chunk_ids": ["chunk_yyy"]
  }
]

要求：
- numbering 使用 1/1.1/1.1.1 形式
- level 与 numbering 对应（1表示顶级）
- required 表示招标明确要求必须提供
- evidence_chunk_ids 必须来自上下文 CHUNK id
- 不要输出除 JSON 以外的任何文字
"""

    CUSTOM_RULE_PROMPT = """
你是"企业内部招投标审核规则抽取器"。请从"规则文件原文片段"中抽取结构化规则，输出严格 JSON 数组：
[
  {
    "dimension": "资格审查",  // 资格审查|报价审查|技术审查|商务审查|工期与质量|文档结构|其他
    "title": "规则标题",
    "check": "可执行的检查描述（清晰、具体）",
    "rigid": true,  // true表示不满足就应判 fail
    "severity": "high",  // low, medium, high, critical
    "tags": ["资质", "业绩"],
    "evidence_chunk_ids": ["chunk_xxx"]
  }
]

要求：
- rigid=true 表示刚性要求，不满足就应判 fail 或 mustReject
- evidence_chunk_ids 必须来自上下文 CHUNK id
- 不要输出除 JSON 以外的任何文字
"""

    REVIEW_PROMPT = """
你是招投标"投标文件审核员"。你会收到：
1) 招标文件原文片段（带 CHUNK id）
2) 投标文件原文片段（带 CHUNK id）
3) 额外自定义审核规则（JSON 数组，可为空）

请输出严格 JSON 数组：
[
  {
    "dimension": "资格审查",  // 资格审查|报价审查|技术审查|商务审查|工期与质量|文档结构|其他
    "requirement_text": "招标要求（摘要）",
    "response_text": "投标响应（摘要）",
    "result": "pass",  // pass, risk, fail
    "remark": "原因/建议/缺失点/冲突点",
    "rigid": false,  // 是否刚性要求
    "tender_evidence_chunk_ids": ["chunk_xxx"],
    "bid_evidence_chunk_ids": ["chunk_yyy"]
  }
]

规则：
- 结果含义：pass=明确符合；fail=明确不符合；risk=不确定/缺材料/冲突/需要人工确认
- 自定义规则与招标要求"叠加"：也要产出对应的审核项（可合并到同维度）
- evidence_chunk_ids 必须来自上下文 CHUNK id
- 不要输出除 JSON 以外的任何文字
"""

    # ==================== 文件入库 ====================

    async def _ingest_to_kb(
        self,
        kb_id: str,
        filename: str,
        kind: str,
        bidder_name: Optional[str],
        data: bytes,
    ) -> str:
        """
        轻量入库：解析文件 → 分块 → 写入 kb_documents/kb_chunks
        
        Returns:
            kb_doc_id
        """
        # 解析文件内容
        text = _read_text_from_file_bytes(filename, data)
        content_hash = _sha256(data)

        # 创建文档记录
        meta = {"kind": kind, "bidder_name": bidder_name or ""}
        doc_id = await self.dao.create_kb_document(
            kb_id=kb_id,
            filename=filename,
            content_hash=content_hash,
            meta_json=meta,
        )

        # 分块并插入
        chunks = []
        parts = _chunk_text(text, max_chars=1200, overlap=150)
        for i, part in enumerate(parts, start=1):
            chunks.append({
                "title": filename,
                "url": "",
                "position": i,
                "content": part,
            })

        await self.dao.insert_kb_chunks(kb_id=kb_id, doc_id=doc_id, chunks=chunks)
        return doc_id

    async def _load_context_by_assets(
        self,
        project_id: str,
        kinds: List[str],
        bidder_name: Optional[str],
        bid_asset_ids: List[str],
        limit: int,
    ) -> Tuple[List[Dict[str, Any]], List[str]]:
        """
        根据资产条件加载上下文 chunks
        
        Args:
            kinds: 资产类型列表（如 ["tender"] 或 ["bid"]）
            bidder_name: 投标人名称（用于过滤 bid）
            bid_asset_ids: 投标资产ID列表（精确指定）
            limit: 最多加载多少个 chunks
        
        Returns:
            (chunks, doc_ids)
        """
        # 获取所有资产
        assets = await self.dao.list_assets(project_id)
        
        # 过滤资产
        filtered = []
        for a in assets:
            if a.get("kind") not in kinds:
                continue
            
            # 特殊处理 bid 资产
            if a.get("kind") == "bid":
                if bid_asset_ids:
                    # 精确指定
                    if a.get("id") not in bid_asset_ids:
                        continue
                elif bidder_name:
                    # 按投标人名称过滤
                    if (a.get("bidder_name") or "") != bidder_name:
                        continue
            
            filtered.append(a)

        # 提取 doc_ids 并加载 chunks
        doc_ids = [a.get("kb_doc_id") for a in filtered if a.get("kb_doc_id")]
        chunks = await self.dao.load_chunks_by_doc_ids(doc_ids, limit=limit)
        return chunks, doc_ids

    # ==================== 公开 API ====================

    async def import_assets(
        self,
        project_id: str,
        kind: str,
        files: List[UploadFile],
        bidder_name: Optional[str],
    ) -> List[Dict[str, Any]]:
        """
        项目内上传文件并自动绑定
        
        Args:
            project_id: 项目ID
            kind: tender | bid | template | custom_rule
            files: 上传的文件列表
            bidder_name: 投标人名称（kind=bid 时必填）
        
        Returns:
            创建的资产列表
        """
        # 获取项目信息
        proj = await self.dao.get_project(project_id)
        if not proj:
            raise ValueError("project not found")

        kb_id = proj["kb_id"]
        assets_out = []

        # 创建存储目录
        base_dir = os.path.join("data", "tender_assets", project_id)
        _safe_mkdir(base_dir)

        for f in files:
            b = await f.read()
            filename = f.filename or "file"
            mime = getattr(f, "content_type", None)
            size = len(b)

            kb_doc_id = None
            storage_path = None

            if kind == "template":
                # 模板文件：保存到磁盘
                storage_path = os.path.join(base_dir, f"tpl_{uuid.uuid4().hex}_{filename}")
                with open(storage_path, "wb") as w:
                    w.write(b)
            else:
                # tender/bid/custom_rule：入库到 KB
                kb_doc_id = await self._ingest_to_kb(
                    kb_id=kb_id,
                    filename=filename,
                    kind=kind,
                    bidder_name=bidder_name,
                    data=b,
                )

                # 兼容旧 API：tender/bid 也写入 tender_project_documents
                if kind in ("tender", "bid"):
                    role = "tender" if kind == "tender" else "bid"
                    await self.dao.create_project_document_binding(
                        project_id, role, kb_doc_id, bidder_name, filename
                    )

            # 创建资产记录
            asset = await self.dao.create_asset(
                project_id=project_id,
                kind=kind,
                filename=filename,
                mime_type=mime,
                size_bytes=size,
                kb_doc_id=kb_doc_id,
                storage_path=storage_path,
                bidder_name=bidder_name,
                meta_json={},
            )
            assets_out.append(asset)

        return assets_out

    async def list_assets(self, project_id: str) -> List[Dict[str, Any]]:
        """列出项目的所有资产"""
        return await self.dao.list_assets(project_id)

    async def extract_project_info(
        self,
        project_id: str,
        model_id: Optional[str],
        run_id: Optional[str] = None,
    ):
        """抽取项目信息"""
        # 加载招标文件的 chunks
        chunks, _ = await self._load_context_by_assets(
            project_id,
            kinds=["tender"],
            bidder_name=None,
            bid_asset_ids=[],
            limit=180,
        )
        ctx = _build_marked_context(chunks)

        # 调用 LLM
        messages = [
            {"role": "system", "content": self.PROJECT_INFO_PROMPT.strip()},
            {"role": "user", "content": f"招标文件原文片段：\n{ctx}"},
        ]
        out_text = await self._llm_text(LLMCall(model_id=model_id, messages=messages))
        obj = _extract_json(out_text)

        # 保存结果
        data = obj.get("data") or {}
        eids = obj.get("evidence_chunk_ids") or []
        await self.dao.upsert_project_info(project_id, data_json=data, evidence_chunk_ids=eids)

        # 更新运行状态
        if run_id:
            await self.dao.update_run(run_id, "success", progress=1.0, message="ok", result_json=obj)

    async def extract_risks(
        self,
        project_id: str,
        model_id: Optional[str],
        run_id: Optional[str] = None,
    ):
        """识别风险"""
        chunks, _ = await self._load_context_by_assets(
            project_id,
            kinds=["tender"],
            bidder_name=None,
            bid_asset_ids=[],
            limit=220,
        )
        ctx = _build_marked_context(chunks)

        messages = [
            {"role": "system", "content": self.RISK_PROMPT.strip()},
            {"role": "user", "content": f"招标文件原文片段：\n{ctx}"},
        ]
        out_text = await self._llm_text(LLMCall(model_id=model_id, messages=messages))
        arr = _extract_json(out_text)
        
        if not isinstance(arr, list):
            raise ValueError("risk output not list")
        
        await self.dao.replace_risks(project_id, arr)
        
        if run_id:
            await self.dao.update_run(run_id, "success", progress=1.0, message="ok", result_json=arr)

    async def generate_directory(
        self,
        project_id: str,
        model_id: Optional[str],
        run_id: Optional[str] = None,
    ):
        """生成目录"""
        chunks, _ = await self._load_context_by_assets(
            project_id,
            kinds=["tender"],
            bidder_name=None,
            bid_asset_ids=[],
            limit=220,
        )
        ctx = _build_marked_context(chunks)

        messages = [
            {"role": "system", "content": self.DIRECTORY_PROMPT.strip()},
            {"role": "user", "content": f"招标文件原文片段：\n{ctx}"},
        ]
        out_text = await self._llm_text(LLMCall(model_id=model_id, messages=messages))
        arr = _extract_json(out_text)
        
        if not isinstance(arr, list):
            raise ValueError("directory output not list")
        
        await self.dao.replace_directory(project_id, arr)
        
        if run_id:
            await self.dao.update_run(run_id, "success", progress=1.0, message="ok", result_json=arr)

    async def save_directory(self, project_id: str, nodes: List[Dict[str, Any]]):
        """保存目录（用户编辑后）"""
        await self.dao.replace_directory(project_id, nodes)

    async def extract_rule_set(
        self,
        project_id: str,
        name: str,
        description: Optional[str],
        source_asset_ids: List[str],
        model_id: Optional[str],
        run_id: Optional[str] = None,
    ):
        """从自定义规则文件抽取规则集"""
        # 获取规则文件资产
        assets = await self.dao.get_assets_by_ids(project_id, source_asset_ids)
        doc_ids = [a.get("kb_doc_id") for a in assets if a.get("kb_doc_id")]
        chunks = await self.dao.load_chunks_by_doc_ids(doc_ids, limit=240)
        ctx = _build_marked_context(chunks)

        # 调用 LLM
        messages = [
            {"role": "system", "content": self.CUSTOM_RULE_PROMPT.strip()},
            {"role": "user", "content": f"规则文件原文片段：\n{ctx}"},
        ]
        out_text = await self._llm_text(LLMCall(model_id=model_id, messages=messages))
        arr = _extract_json(out_text)
        
        if not isinstance(arr, list):
            raise ValueError("rule set output not list")

        # 保存规则集
        rs = await self.dao.create_rule_set(project_id, name, description, source_asset_ids, arr)
        
        if run_id:
            await self.dao.update_run(run_id, "success", progress=1.0, message="ok", result_json=rs)

    async def run_review(
        self,
        project_id: str,
        model_id: Optional[str],
        custom_rule_set_ids: List[str],
        bidder_name: Optional[str],
        bid_asset_ids: List[str],
        run_id: Optional[str] = None,
    ):
        """
        运行审核（招标规则 + 自定义规则集叠加）
        
        Args:
            custom_rule_set_ids: 自定义规则集ID列表（多选）
            bidder_name: 投标人名称（选择投标人）
            bid_asset_ids: 投标资产ID列表（精确指定文件）
        """
        # 加载招标文件 chunks
        tender_chunks, _ = await self._load_context_by_assets(
            project_id,
            kinds=["tender"],
            bidder_name=None,
            bid_asset_ids=[],
            limit=220,
        )
        tender_ctx = _build_marked_context(tender_chunks)

        # 加载投标文件 chunks
        bid_chunks, _ = await self._load_context_by_assets(
            project_id,
            kinds=["bid"],
            bidder_name=bidder_name,
            bid_asset_ids=bid_asset_ids,
            limit=220,
        )
        bid_ctx = _build_marked_context(bid_chunks)

        # 加载自定义规则集
        rule_sets = await self.dao.get_rule_sets_by_ids(project_id, custom_rule_set_ids)
        merged_rules = []
        for rs in rule_sets:
            # 提取 rules_json
            rj = rs.get("rules_json")
            if isinstance(rj, list):
                merged_rules.extend(rj)

        # 调用 LLM
        messages = [
            {"role": "system", "content": self.REVIEW_PROMPT.strip()},
            {
                "role": "user",
                "content": f"招标文件原文片段：\n{tender_ctx}\n\n投标文件原文片段：\n{bid_ctx}\n\n额外自定义审核规则（JSON 数组）：\n{json.dumps(merged_rules, ensure_ascii=False)}",
            },
        ]
        out_text = await self._llm_text(LLMCall(model_id=model_id, messages=messages))
        arr = _extract_json(out_text)
        
        if not isinstance(arr, list):
            raise ValueError("review output not list")

        # 保存审核项
        await self.dao.replace_review_items(project_id, arr)
        
        if run_id:
            await self.dao.update_run(
                run_id, "success", progress=1.0, message="ok", result_json={"count": len(arr)}
            )

    async def generate_docx(
        self,
        project_id: str,
        template_asset_id: Optional[str],
    ) -> bytes:
        """
        生成 Word 文档
        
        Args:
            template_asset_id: 模板资产ID（可选）
        
        Returns:
            Word 文档字节
        """
        # 加载目录节点
        nodes = await self.dao.list_directory(project_id)

        # 加载模板（如果指定）
        tpl_doc = None
        if template_asset_id:
            assets = await self.dao.get_assets_by_ids(project_id, [template_asset_id])
            if assets:
                path = assets[0].get("storage_path")
                if path and os.path.exists(path):
                    tpl_doc = Document(path)

        # 创建文档
        doc = tpl_doc or Document()

        # 根据目录生成骨架
        for n in nodes:
            title = n.get("title") or ""
            level = int(n.get("level") or 1)
            # docx heading level 1..9
            h = min(max(level, 1), 9)
            doc.add_heading(title, level=h)
            notes = n.get("notes") or ""
            if notes:
                doc.add_paragraph(notes)

        # 保存到内存
        import io
        buf = io.BytesIO()
        doc.save(buf)
        return buf.getvalue()

    async def list_rule_sets(self, project_id: str) -> List[Dict[str, Any]]:
        """列出规则集"""
        return await self.dao.list_rule_sets(project_id)

    async def lookup_chunks(self, chunk_ids: List[str]) -> List[Dict[str, Any]]:
        """查询 chunks（证据回溯）"""
        return await self.dao.lookup_chunks(chunk_ids)
