# PDFèŒƒæœ¬æå–å¢å¼ºæ–¹æ¡ˆ - æ”¯æŒè¡¨æ ¼+æ–‡å­—æ··åˆæå–

**ç›®æ ‡**: æå–èŒƒæœ¬çš„å®Œæ•´åŸæ–‡ï¼ˆåŒ…æ‹¬è¡¨æ ¼å’Œæ–‡å­—ï¼‰ï¼Œå¹¶å¡«å……åˆ°ç›®å½•æ­£æ–‡

---

## ğŸ¯ æ ¸å¿ƒæ€è·¯

### å½“å‰é—®é¢˜

1. **æ ‡é¢˜è¯†åˆ«ä¸å®Œæ•´**
   - æ ‡é¢˜å¯èƒ½åœ¨æ®µè½ä¸­ï¼ˆæ®µè½æ–‡æœ¬ï¼‰
   - æ ‡é¢˜ä¹Ÿå¯èƒ½åœ¨è¡¨æ ¼ä¸­ï¼ˆè¡¨æ ¼ç¬¬ä¸€è¡Œï¼‰
   - å½“å‰åªæ£€æµ‹æ®µè½ï¼Œé—æ¼è¡¨æ ¼ä¸­çš„æ ‡é¢˜

2. **å†…å®¹æå–ä¸å®Œæ•´**
   - åªè®°å½•äº†start_indexå’Œend_index
   - æ²¡æœ‰æå–å®é™…çš„å†…å®¹ï¼ˆæ–‡å­—ã€è¡¨æ ¼ï¼‰
   - ç›®å½•æ­£æ–‡æ˜¯ç©ºçš„

3. **æ ¼å¼ä¸¢å¤±**
   - è¡¨æ ¼åº”è¯¥ä¿æŒè¡¨æ ¼æ ¼å¼
   - æ–‡å­—åº”è¯¥ä¿æŒæ®µè½æ ¼å¼
   - å½“å‰åªæ˜¯çº¯æ–‡æœ¬

---

## ğŸ› ï¸ å¢å¼ºæ–¹æ¡ˆ

### Phase 1: å¢å¼ºæ ‡é¢˜è¯†åˆ«ï¼ˆæ”¯æŒè¡¨æ ¼+æ®µè½ï¼‰

#### 1.1 ä»æ®µè½ä¸­è¯†åˆ«æ ‡é¢˜ï¼ˆç°æœ‰é€»è¾‘ï¼‰

```python
# å·²æœ‰é€»è¾‘ï¼Œç»§ç»­ä¿ç•™
for it in seg:
    if it.get("type") == "paragraph":
        text = it.get("text", "").strip()
        if H1.match(text) or _has_kw(text, SAMPLE_KW):
            heads.append((idx, title, ftype, score))
```

#### 1.2 ä»è¡¨æ ¼ä¸­è¯†åˆ«æ ‡é¢˜ï¼ˆæ–°å¢ï¼‰

```python
# âœ… æ–°å¢ï¼šä»è¡¨æ ¼ä¸­è¯†åˆ«æ ‡é¢˜
for it in seg:
    if it.get("type") == "table":
        table_text = it.get("text", "")
        
        # å°è¯•å¤šç§æ–¹å¼æå–æ ‡é¢˜ï¼š
        # æ–¹å¼1: è¡¨æ ¼ç¬¬ä¸€è¡Œ
        first_line = table_text.split("\n")[0].strip()
        
        # æ–¹å¼2: è¡¨æ ¼ç¬¬ä¸€åˆ—ï¼ˆå¦‚æœæ˜¯ç›®å½•è¡¨æ ¼ï¼‰
        # ä¾‹å¦‚ï¼š
        # | ä¸€ã€å¼€æ ‡ä¸€è§ˆè¡¨ | ï¼ˆé¡µç ï¼‰ |
        # | äºŒã€æŠ•æ ‡å‡½     | ï¼ˆé¡µç ï¼‰ |
        
        # æ–¹å¼3: è¡¨æ ¼å•å…ƒæ ¼ï¼ˆæ‰«ææ‰€æœ‰å•å…ƒæ ¼ï¼‰
        all_lines = table_text.split("\n")
        
        for line in all_lines[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
            line_clean = _clean_title(line)  # å»é™¤ç‚¹å·ã€æ‹¬å·
            
            if H1.match(line_clean) or _has_kw(line_clean, SAMPLE_KW):
                # æ‰¾åˆ°æ ‡é¢˜
                heads.append((idx, line_clean, ftype, 8.0))
                break  # æ¯ä¸ªè¡¨æ ¼åªå–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ ‡é¢˜
```

#### 1.3 æ ‡é¢˜æ¸…ç†å‡½æ•°

```python
def _clean_title(text: str) -> str:
    """
    æ¸…ç†æ ‡é¢˜æ–‡æœ¬ï¼š
    - å»é™¤å°¾éƒ¨çš„ç‚¹å·ï¼ˆâ€¦â€¦ï¼‰
    - å»é™¤å°¾éƒ¨çš„æ‹¬å·å†…å®¹ï¼ˆé¡µç ï¼‰
    - å»é™¤è¡¨æ ¼åˆ†éš”ç¬¦ï¼ˆ|ï¼‰
    """
    text = text.strip()
    
    # å»é™¤è¡¨æ ¼åˆ†éš”ç¬¦
    text = text.replace("|", "").strip()
    
    # å»é™¤å°¾éƒ¨çš„"â€¦â€¦â€¦â€¦â€¦â€¦ï¼ˆé¡µç ï¼‰"
    text = re.sub(r'[â€¦\.]+\s*[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]\s*$', '', text)
    
    # å»é™¤å°¾éƒ¨çš„"â€¦â€¦â€¦â€¦â€¦â€¦"
    text = re.sub(r'[â€¦\.]+\s*$', '', text)
    
    # å»é™¤å°¾éƒ¨çš„ç©ºç™½å’Œç‰¹æ®Šå­—ç¬¦
    text = text.strip()
    
    return text
```

---

### Phase 2: å¢å¼ºå†…å®¹æå–ï¼ˆæå–åŸæ–‡ï¼‰

#### 2.1 Fragmentæ•°æ®ç»“æ„å¢å¼º

```python
# å½“å‰Fragmentç»“æ„ï¼š
fragment = {
    "title": "ä¸€ã€å¼€æ ‡ä¸€è§ˆè¡¨",
    "start_body_index": 10,
    "end_body_index": 15,
    "confidence": 0.85,
    "strategy": "rule_based"
}

# âœ… å¢å¼ºåçš„Fragmentç»“æ„ï¼š
fragment = {
    "title": "ä¸€ã€å¼€æ ‡ä¸€è§ˆè¡¨",
    "start_body_index": 10,
    "end_body_index": 15,
    "confidence": 0.85,
    "strategy": "rule_based",
    
    # âœ… æ–°å¢ï¼šåŸæ–‡å†…å®¹
    "content": {
        "type": "mixed",  # "text" | "table" | "mixed"
        "items": [
            {
                "type": "paragraph",
                "text": "...",
                "html": "<p>...</p>"
            },
            {
                "type": "table",
                "text": "...",
                "html": "<table>...</table>",
                "rows": 5,
                "cols": 3
            }
        ],
        "html": "<div>...</div>",  # å®Œæ•´çš„HTMLï¼ˆç”¨äºå‰ç«¯æ¸²æŸ“ï¼‰
        "text": "..."  # çº¯æ–‡æœ¬ï¼ˆç”¨äºæœç´¢ï¼‰
    }
}
```

#### 2.2 å†…å®¹æå–é€»è¾‘

```python
def extract_fragment_content(
    items: List[Dict[str, Any]], 
    start_idx: int, 
    end_idx: int
) -> Dict[str, Any]:
    """
    æå–fragmentçš„å®Œæ•´å†…å®¹ï¼ˆåŒ…æ‹¬è¡¨æ ¼å’Œæ–‡å­—ï¼‰
    
    Args:
        items: PDFçš„æ‰€æœ‰items
        start_idx: fragmentèµ·å§‹ç´¢å¼•
        end_idx: fragmentç»“æŸç´¢å¼•
    
    Returns:
        {
            "type": "mixed",
            "items": [...],
            "html": "...",
            "text": "..."
        }
    """
    content_items = []
    text_parts = []
    html_parts = []
    
    # æå–start_idxåˆ°end_idxä¹‹é—´çš„æ‰€æœ‰items
    for it in items[start_idx:end_idx]:
        item_type = it.get("type")
        
        if item_type == "paragraph":
            # æ®µè½æ–‡æœ¬
            text = it.get("text", "").strip()
            if text:
                content_items.append({
                    "type": "paragraph",
                    "text": text,
                    "html": f"<p>{text}</p>"
                })
                text_parts.append(text)
                html_parts.append(f"<p>{text}</p>")
        
        elif item_type == "table":
            # è¡¨æ ¼
            table_text = it.get("text", "").strip()
            table_html = _convert_table_to_html(it)  # è½¬æ¢ä¸ºHTMLè¡¨æ ¼
            
            if table_text:
                content_items.append({
                    "type": "table",
                    "text": table_text,
                    "html": table_html,
                    "rows": table_text.count("\n") + 1,
                    "cols": len(table_text.split("\n")[0].split("|")) if "|" in table_text else 1
                })
                text_parts.append(table_text)
                html_parts.append(table_html)
    
    # åˆ¤æ–­å†…å®¹ç±»å‹
    has_table = any(it["type"] == "table" for it in content_items)
    has_text = any(it["type"] == "paragraph" for it in content_items)
    
    if has_table and has_text:
        content_type = "mixed"
    elif has_table:
        content_type = "table"
    else:
        content_type = "text"
    
    return {
        "type": content_type,
        "items": content_items,
        "html": "\n".join(html_parts),
        "text": "\n\n".join(text_parts)
    }

def _convert_table_to_html(table_item: Dict[str, Any]) -> str:
    """
    å°†PDFè¡¨æ ¼è½¬æ¢ä¸ºHTMLè¡¨æ ¼
    
    ç®€å•ç‰ˆæœ¬ï¼šå°†æ–‡æœ¬æŒ‰è¡Œåˆ—åˆ†å‰²åç”ŸæˆHTML
    å®Œæ•´ç‰ˆæœ¬ï¼šä½¿ç”¨pdfplumberæˆ–å…¶ä»–åº“æå–è¡¨æ ¼ç»“æ„
    """
    table_text = table_item.get("text", "")
    lines = table_text.split("\n")
    
    html = ['<table border="1" style="border-collapse: collapse; width: 100%;">']
    
    for i, line in enumerate(lines):
        if not line.strip():
            continue
        
        # æŒ‰ | åˆ†å‰²å•å…ƒæ ¼ï¼ˆå¦‚æœæœ‰ï¼‰
        cells = [c.strip() for c in line.split("|") if c.strip()]
        
        # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
        if i == 0 and cells:
            html.append("<thead><tr>")
            for cell in cells:
                html.append(f"<th>{cell}</th>")
            html.append("</tr></thead>")
        else:
            html.append("<tr>")
            for cell in cells:
                html.append(f"<td>{cell}</td>")
            html.append("</tr>")
    
    html.append("</table>")
    return "".join(html)
```

---

### Phase 3: æ•°æ®åº“å­˜å‚¨å¢å¼º

#### 3.1 tender_sample_fragmentsè¡¨æ‰©å±•

```sql
-- å½“å‰ç»“æ„
CREATE TABLE tender_sample_fragments (
    id VARCHAR PRIMARY KEY,
    project_id VARCHAR NOT NULL,
    title VARCHAR NOT NULL,
    start_body_index INTEGER NOT NULL,
    end_body_index INTEGER NOT NULL,
    confidence FLOAT,
    strategy VARCHAR
);

-- âœ… å¢å¼ºåçš„ç»“æ„
ALTER TABLE tender_sample_fragments 
ADD COLUMN content_type VARCHAR(20);  -- "text" | "table" | "mixed"

ADD COLUMN content_html TEXT;  -- å¯Œæ–‡æœ¬HTMLï¼ˆç”¨äºæ¸²æŸ“ï¼‰

ADD COLUMN content_text TEXT;  -- çº¯æ–‡æœ¬ï¼ˆç”¨äºæœç´¢ï¼‰

ADD COLUMN content_items JSONB;  -- è¯¦ç»†çš„itemsç»“æ„
```

#### 3.2 å­˜å‚¨é€»è¾‘

```python
def upsert_fragment_with_content(
    dao: TenderDAO,
    project_id: str,
    fragment: Dict[str, Any],
    items: List[Dict[str, Any]]
) -> str:
    """
    å­˜å‚¨fragmentï¼ŒåŒ…æ‹¬å®Œæ•´å†…å®¹
    """
    # æå–å†…å®¹
    content = extract_fragment_content(
        items,
        fragment["start_body_index"],
        fragment["end_body_index"]
    )
    
    # å­˜å‚¨åˆ°æ•°æ®åº“
    fragment_id = dao.upsert_tender_sample_fragment(
        project_id=project_id,
        title=fragment["title"],
        start_body_index=fragment["start_body_index"],
        end_body_index=fragment["end_body_index"],
        confidence=fragment["confidence"],
        strategy=fragment["strategy"],
        
        # âœ… æ–°å¢å­—æ®µ
        content_type=content["type"],
        content_html=content["html"],
        content_text=content["text"],
        content_items=json.dumps(content["items"], ensure_ascii=False)
    )
    
    return fragment_id
```

---

### Phase 4: ç›®å½•æ­£æ–‡å¡«å……å¢å¼º

#### 4.1 OutlineSampleAttacherå¢å¼º

```python
class OutlineSampleAttacher:
    def attach_fragment_to_node(
        self,
        node_id: str,
        fragment: Dict[str, Any]
    ):
        """
        å°†fragmentçš„å†…å®¹å¡«å……åˆ°ç›®å½•èŠ‚ç‚¹çš„æ­£æ–‡
        """
        # è·å–fragmentçš„å®Œæ•´å†…å®¹
        content_html = fragment.get("content_html", "")
        content_text = fragment.get("content_text", "")
        content_type = fragment.get("content_type", "text")
        
        # æ›´æ–°èŠ‚ç‚¹çš„body
        self.dao.update_directory_node_body(
            node_id=node_id,
            body_html=content_html,  # HTMLæ ¼å¼ï¼ˆç”¨äºå‰ç«¯æ¸²æŸ“ï¼‰
            body_text=content_text,  # çº¯æ–‡æœ¬ï¼ˆç”¨äºç¼–è¾‘ï¼‰
            body_source="EXTRACTED_FRAGMENT",
            fragment_id=fragment["id"]
        )
        
        # æ›´æ–°èŠ‚ç‚¹çš„bodyMeta
        self.dao.update_directory_node_meta(
            node_id=node_id,
            meta={
                "source": "EXTRACTED_FRAGMENT",
                "fragmentId": fragment["id"],
                "hasContent": True,
                "contentType": content_type,  # "text" | "table" | "mixed"
                "extractedAt": datetime.now().isoformat()
            }
        )
```

---

### Phase 5: å‰ç«¯æ¸²æŸ“å¢å¼º

#### 5.1 ç›®å½•èŠ‚ç‚¹æ˜¾ç¤º

```tsx
// TenderWorkspace.tsx
function DirectoryNodeBody({ node }: { node: DirectoryNode }) {
  const contentType = node.bodyMeta?.contentType || "text";
  
  if (contentType === "table" || contentType === "mixed") {
    // æ¸²æŸ“HTMLï¼ˆåŒ…å«è¡¨æ ¼ï¼‰
    return (
      <div 
        className="node-body-html"
        dangerouslySetInnerHTML={{ __html: node.bodyHtml || "" }}
      />
    );
  } else {
    // æ¸²æŸ“çº¯æ–‡æœ¬
    return (
      <pre className="node-body-text">
        {node.bodyText || ""}
      </pre>
    );
  }
}
```

#### 5.2 æ ·å¼ä¼˜åŒ–

```css
/* è¡¨æ ¼æ ·å¼ */
.node-body-html table {
  width: 100%;
  border-collapse: collapse;
  margin: 10px 0;
}

.node-body-html th,
.node-body-html td {
  border: 1px solid #ddd;
  padding: 8px;
  text-align: left;
}

.node-body-html th {
  background-color: #f5f5f5;
  font-weight: bold;
}

/* æ–‡æœ¬æ ·å¼ */
.node-body-text {
  white-space: pre-wrap;
  font-family: monospace;
  padding: 10px;
  background: #f9f9f9;
  border-radius: 4px;
}
```

---

## ğŸ“Š å®æ–½è®¡åˆ’

### Step 1: å¢å¼ºæ ‡é¢˜è¯†åˆ«ï¼ˆ1å°æ—¶ï¼‰

**æ–‡ä»¶**: `backend/app/services/fragment/pdf_sample_detector.py`

1. æ·»åŠ `_clean_title()`å‡½æ•°
2. ä¿®æ”¹`detect_pdf_fragments()`ï¼Œå¢åŠ è¡¨æ ¼æ ‡é¢˜è¯†åˆ«
3. æµ‹è¯•ï¼šèƒ½è¯†åˆ«è¡¨æ ¼ä¸­çš„æ ‡é¢˜

**é¢„æœŸç»“æœ**:
```python
# æµ‹è¯•1é¡¹ç›®åº”è¯¥è¯†åˆ«åˆ°8ä¸ªæ ‡é¢˜
fragments = detect_pdf_fragments(items, ...)
assert len(fragments) == 8
```

---

### Step 2: å¢å¼ºå†…å®¹æå–ï¼ˆ1.5å°æ—¶ï¼‰

**æ–‡ä»¶**: `backend/app/services/fragment/pdf_content_extractor.py` (æ–°æ–‡ä»¶)

1. åˆ›å»º`extract_fragment_content()`å‡½æ•°
2. åˆ›å»º`_convert_table_to_html()`å‡½æ•°
3. æµ‹è¯•ï¼šèƒ½æå–è¡¨æ ¼å’Œæ–‡å­—

**é¢„æœŸç»“æœ**:
```python
content = extract_fragment_content(items, 10, 15)
assert content["type"] in ["text", "table", "mixed"]
assert content["html"]  # æœ‰HTMLå†…å®¹
assert content["text"]  # æœ‰çº¯æ–‡æœ¬å†…å®¹
```

---

### Step 3: æ•°æ®åº“æ‰©å±•ï¼ˆ30åˆ†é’Ÿï¼‰

**æ–‡ä»¶**: `backend/app/migrations/xxx_add_fragment_content.sql` (æ–°æ–‡ä»¶)

1. ç¼–å†™è¿ç§»è„šæœ¬
2. æ·»åŠ æ–°å­—æ®µï¼ˆcontent_type, content_html, content_text, content_itemsï¼‰
3. æ‰§è¡Œè¿ç§»

**æ‰§è¡Œ**:
```bash
# åº”ç”¨è¿ç§»
docker-compose exec backend alembic upgrade head

# æˆ–æ‰‹åŠ¨æ‰§è¡ŒSQL
docker-compose exec postgres psql -U localgpt -d localgpt < migration.sql
```

---

### Step 4: å­˜å‚¨é€»è¾‘æ›´æ–°ï¼ˆ1å°æ—¶ï¼‰

**æ–‡ä»¶**: 
- `backend/app/services/fragment/fragment_extractor.py`
- `backend/app/services/dao/tender_dao.py`

1. ä¿®æ”¹`extract_and_upsert_summary()`ï¼Œè°ƒç”¨å†…å®¹æå–
2. ä¿®æ”¹`upsert_tender_sample_fragment()`ï¼Œæ”¯æŒæ–°å­—æ®µ
3. æµ‹è¯•ï¼šfragmentsèƒ½æ­£ç¡®å­˜å‚¨

---

### Step 5: ç›®å½•å¡«å……æ›´æ–°ï¼ˆ1å°æ—¶ï¼‰

**æ–‡ä»¶**: `backend/app/services/fragment/outline_attacher.py`

1. ä¿®æ”¹`attach_fragment_to_node()`ï¼Œå¡«å……HTMLå†…å®¹
2. ä¿®æ”¹`_attach_fragment_body()`ï¼Œæ”¯æŒæ–°å­—æ®µ
3. æµ‹è¯•ï¼šç›®å½•èŠ‚ç‚¹èƒ½æ˜¾ç¤ºè¡¨æ ¼

---

### Step 6: å‰ç«¯æ¸²æŸ“æ›´æ–°ï¼ˆ1å°æ—¶ï¼‰

**æ–‡ä»¶**: `frontend/src/components/TenderWorkspace.tsx`

1. ä¿®æ”¹ç›®å½•èŠ‚ç‚¹æ¸²æŸ“é€»è¾‘
2. æ”¯æŒHTMLæ¸²æŸ“ï¼ˆè¡¨æ ¼ï¼‰
3. æ·»åŠ CSSæ ·å¼
4. æµ‹è¯•ï¼šå‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºè¡¨æ ¼

---

### Step 7: é›†æˆæµ‹è¯•ï¼ˆ30åˆ†é’Ÿï¼‰

1. é‡å¯åç«¯ï¼š`docker-compose restart backend`
2. è§¦å‘æå–ï¼šè°ƒç”¨`auto_fill_samples` API
3. éªŒè¯ç»“æœï¼š
   - âœ… è¯†åˆ«8ä¸ªfragments
   - âœ… æ¯ä¸ªfragmentæœ‰å®Œæ•´å†…å®¹
   - âœ… ç›®å½•èŠ‚ç‚¹æ˜¾ç¤ºè¡¨æ ¼/æ–‡å­—
   - âœ… å‰ç«¯æ¸²æŸ“æ­£ç¡®

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

### ä¿®å¤å‰

```json
{
  "fragments_detected": 0,
  "attached_sections": 4,
  "nodes": [
    {
      "title": "å¼€æ ‡ä¸€è§ˆè¡¨",
      "bodyMeta": {
        "source": "BUILTIN_SAMPLE",
        "hasContent": true
      },
      "bodyText": "å›ºå®šçš„å†…ç½®æ¨¡æ¿å†…å®¹"
    }
  ]
}
```

### ä¿®å¤å

```json
{
  "fragments_detected": 8,
  "attached_sections": 8,
  "nodes": [
    {
      "title": "å¼€æ ‡ä¸€è§ˆè¡¨",
      "bodyMeta": {
        "source": "EXTRACTED_FRAGMENT",
        "contentType": "table",
        "hasContent": true
      },
      "bodyHtml": "<table><tr><th>é¡¹ç›®</th><th>é‡‘é¢</th></tr>...</table>",
      "bodyText": "é¡¹ç›® | é‡‘é¢\nè®¾å¤‡é‡‡è´­ | 100ä¸‡\n..."
    },
    {
      "title": "æŠ•æ ‡å‡½",
      "bodyMeta": {
        "source": "EXTRACTED_FRAGMENT",
        "contentType": "text",
        "hasContent": true
      },
      "bodyHtml": "<p>è‡´ï¼šXXXé‡‡è´­äºº</p><p>æˆ‘æ–¹...</p>",
      "bodyText": "è‡´ï¼šXXXé‡‡è´­äºº\næˆ‘æ–¹..."
    }
  ]
}
```

---

## ğŸ“ æŠ€æœ¯è¦ç‚¹

### 1. è¡¨æ ¼è¯†åˆ«çš„æŒ‘æˆ˜

- PDFè¡¨æ ¼å¯èƒ½æœ‰è¾¹æ¡†ï¼Œä¹Ÿå¯èƒ½æ— è¾¹æ¡†
- è¡¨æ ¼å•å…ƒæ ¼å¯èƒ½åˆå¹¶
- è¡¨æ ¼å¯èƒ½è·¨é¡µ

**è§£å†³æ–¹æ¡ˆ**: 
- ä½¿ç”¨pdfplumberçš„è¡¨æ ¼è¯†åˆ«ï¼ˆæ›´å‡†ç¡®ï¼‰
- æˆ–ä½¿ç”¨ç®€å•çš„æ–‡æœ¬è§£æï¼ˆå¿«é€Ÿï¼‰

### 2. HTMLå®‰å…¨æ€§

- ç”¨æˆ·å¯èƒ½ä¸Šä¼ æ¶æ„PDF
- HTMLæ³¨å…¥é£é™©

**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨`bleach`åº“æ¸…ç†HTML
- åªå…è®¸ç™½åå•æ ‡ç­¾ï¼ˆtable, tr, td, th, pç­‰ï¼‰

```python
import bleach

ALLOWED_TAGS = ['table', 'tr', 'td', 'th', 'thead', 'tbody', 'p', 'br', 'strong', 'em']
ALLOWED_ATTRS = {'table': ['border', 'style'], 'td': ['colspan', 'rowspan']}

def sanitize_html(html: str) -> str:
    return bleach.clean(html, tags=ALLOWED_TAGS, attributes=ALLOWED_ATTRS)
```

### 3. æ€§èƒ½ä¼˜åŒ–

- å†…å®¹æå–å¯èƒ½å¾ˆæ…¢ï¼ˆå¤§è¡¨æ ¼ï¼‰
- HTMLç”Ÿæˆå ç”¨å†…å­˜

**è§£å†³æ–¹æ¡ˆ**:
- é™åˆ¶å•ä¸ªfragmentçš„æœ€å¤§sizeï¼ˆå¦‚ï¼š100KBï¼‰
- å¼‚æ­¥å¤„ç†ï¼ˆåå°ä»»åŠ¡ï¼‰
- ç¼“å­˜æå–ç»“æœ

---

## ğŸš€ æ€»ç»“

**æ ¸å¿ƒæ”¹è¿›**:
1. âœ… æ”¯æŒä»è¡¨æ ¼å’Œæ®µè½ä¸­è¯†åˆ«æ ‡é¢˜
2. âœ… æå–fragmentçš„å®Œæ•´åŸæ–‡ï¼ˆè¡¨æ ¼+æ–‡å­—ï¼‰
3. âœ… å­˜å‚¨ä¸ºå¯Œæ–‡æœ¬ï¼ˆHTMLï¼‰
4. âœ… å‰ç«¯æ¸²æŸ“è¡¨æ ¼

**é¢„è®¡å·¥ä½œé‡**: 6-7å°æ—¶

**ä¼˜å…ˆçº§**: â­â­â­â­â­ é«˜ï¼ˆç”¨æˆ·æ˜ç¡®éœ€æ±‚ï¼‰

**é£é™©**: ä½ï¼ˆé€»è¾‘æ¸…æ™°ï¼ŒæŠ€æœ¯å¯è¡Œï¼‰

